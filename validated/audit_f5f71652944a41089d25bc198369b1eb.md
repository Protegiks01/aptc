# Audit Report

## Title
Byzantine Validators Can Break Consensus Safety Through Leader Reputation Desynchronization

## Summary
Byzantine validators can manipulate message timing to cause honest validators to have different `BoundedVecDeque` contents in their leader reputation tracking, leading to divergent anchor elections and permanent consensus safety violations in the DAG consensus protocol.

## Finding Description

The DAG consensus implementation uses a local, non-consensus-validated `BoundedVecDeque<CommitEvent>` to track commit history for leader reputation-based anchor election. This creates a critical vulnerability where Byzantine validators can cause honest validators to have different queue contents, leading to different anchor elections for the same round.

**Technical Evidence:**

The vulnerability exists in the leader reputation adapter where commit events are stored in a bounded queue: [1](#0-0) 

When anchors are ordered, commit events are immediately pushed to this local queue without consensus validation: [2](#0-1) 

The commit events are created locally during anchor ordering: [3](#0-2) 

**Critical Flaw:** The hash value that should provide cryptographic commitment to the history is unimplemented and always returns `HashValue::zero()`: [4](#0-3) 

This hash is intended to be used in the reputation calculation to ensure all validators have the same view of history: [5](#0-4) 

The anchor election directly depends on these local queue contents: [6](#0-5) 

**Attack Execution:**

1. Byzantine validator B delays consensus messages to honest validator H1 while sending them normally to H2
2. H2 receives certified nodes faster and orders anchors 1-100, filling its `BoundedVecDeque` with events [1-100]
3. H1 is delayed and only orders anchors 1-50, queue contains events [1-50]
4. At round 101, both validators call `get_anchor(101)`:
   - Both receive `HashValue::zero()` (same seed)
   - H2 calculates reputation weights from events [1-100]
   - H1 calculates reputation weights from events [1-50]
   - Different weights with same seed lead to different `choose_index` results [7](#0-6) 
5. H1 elects validator A as anchor, H2 elects validator B as anchor
6. They order different anchors for round 101 using the order rule logic: [8](#0-7) 
7. Different anchors create different `CommitEvent` objects, causing permanent divergence

**Why This is Critical:** The LeaderReputation mode is the **default configuration** for DAG consensus: [9](#0-8) 

This breaks the fundamental **Consensus Safety Invariant**: "AptosBFT must prevent double-spending and chain splits under < 1/3 Byzantine validators."

## Impact Explanation

**Severity: CRITICAL** - Consensus/Safety Violation (up to $1,000,000)

This vulnerability allows Byzantine validators (< f = n/3) to cause honest validators to permanently fork the blockchain by electing different anchors for the same round. This leads to:

1. **Chain Split**: Different validators commit different blocks for the same height, creating parallel forks
2. **Double-Spending**: Transactions can be committed on one fork but not the other, enabling double-spending attacks
3. **Non-Recoverable State**: Once divergence occurs in the `BoundedVecDeque` contents, it propagates through all future anchor elections, requiring manual intervention or hardfork to resolve
4. **Complete Consensus Failure**: The fundamental safety guarantee of BFT consensus (< 1/3 Byzantine tolerance) is violated

The attack requires only standard Byzantine behavior (message timing manipulation) without requiring > f Byzantine validators or cryptographic breaks. This aligns with the Aptos bug bounty category "Consensus/Safety Violations (Critical)".

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability is highly likely to be exploited because:

1. **Low Attack Complexity**: Byzantine validators only need to delay messages selectively to different peers - standard network message control
2. **No Special Resources Required**: Standard Byzantine validator capabilities suffice
3. **Undetectable**: Message delays appear as normal network latency variation, making the attack indistinguishable from benign network conditions
4. **Persistent Effect**: Once divergence occurs, it propagates and amplifies over time as future elections depend on divergent histories
5. **Incomplete Implementation**: The TODO comment at line 100-101 explicitly indicates the hash-based safety mechanism was never implemented
6. **Default Configuration**: The vulnerable LeaderReputation mode is the default for DAG consensus

The `BoundedVecDeque`'s FIFO eviction policy combined with timing manipulation creates a deterministic path to consensus divergence.

## Recommendation

Implement the hash-based cryptographic commitment to ensure all validators have the same view of history:

1. **Calculate proper hash value** in `MetadataBackendAdapter::get_block_metadata()`:
   - Hash the entire `BoundedVecDeque` contents 
   - Return this hash instead of `HashValue::zero()`

2. **Exchange and validate hashes** between validators:
   - Include the history hash in consensus messages
   - Validators should verify they have the same history hash before anchor election
   - If hashes don't match, trigger a reconciliation protocol

3. **Alternative: Use consensus-validated state**:
   - Store `CommitEvent` history in the blockchain state rather than local memory
   - Query from the database like `AptosDBBackend` does
   - This ensures all validators have the same consensus-validated history

Example fix for the immediate issue:
```rust
fn get_block_metadata(&self, ...) -> (Vec<NewBlockEvent>, HashValue) {
    let events: Vec<_> = self.sliding_window.lock().clone().into_iter()
        .map(|event| self.convert(event)).collect();
    
    // Calculate hash of the queue contents
    let hash = if events.is_empty() {
        HashValue::zero()
    } else {
        HashValue::sha3_256_of(&bcs::to_bytes(&events).unwrap())
    };
    
    (events, hash)
}
```

## Proof of Concept

A complete PoC would require setting up a DAG consensus network with multiple validators. The attack scenario can be demonstrated as follows:

**Setup:**
- 4 validators: V1, V2, V3 (honest), V4 (Byzantine)
- DAG consensus with LeaderReputation mode (default)
- V4 controls message timing to V1

**Attack Steps:**
1. V4 delays all consensus messages to V1 by 2 seconds
2. V2, V3, V4 rapidly order anchors for rounds 2, 4, 6, ..., 100
3. V1 is delayed and only orders anchors for rounds 2, 4, 6, ..., 50
4. At round 102:
   - V1's `BoundedVecDeque` contains events from rounds [2-50]
   - V2's `BoundedVecDeque` contains events from rounds [52-100] (evicted earlier events due to bounded size)
   - They calculate different reputation weights
   - They elect different validators as anchor for round 102
5. V1 orders validator A's node at round 102
6. V2 orders validator B's node at round 102
7. Consensus safety is permanently violated

**Expected Result:** V1 and V2 commit different blocks for the same height, creating a permanent chain split that requires manual intervention to resolve.

## Notes

This vulnerability is specific to the **LeaderReputation** anchor election mode in DAG consensus. The **RoundRobin** mode is not vulnerable as it uses deterministic anchor selection that doesn't depend on local history. [10](#0-9) 

The vulnerability demonstrates a critical gap between the intended design (hash-based validation) and the actual implementation (hash always zero), creating a consensus safety violation under Byzantine conditions within the threat model.

### Citations

**File:** consensus/src/dag/anchor_election/leader_reputation_adapter.rs (L25-29)
```rust
pub struct MetadataBackendAdapter {
    epoch_to_validators: HashMap<u64, HashMap<Author, usize>>,
    window_size: usize,
    sliding_window: Mutex<BoundedVecDeque<CommitEvent>>,
}
```

**File:** consensus/src/dag/anchor_election/leader_reputation_adapter.rs (L43-48)
```rust
    pub fn push(&self, event: CommitEvent) {
        if !self.epoch_to_validators.contains_key(&event.epoch()) {
            return;
        }
        self.sliding_window.lock().push_front(event);
    }
```

**File:** consensus/src/dag/anchor_election/leader_reputation_adapter.rs (L85-103)
```rust
impl MetadataBackend for MetadataBackendAdapter {
    fn get_block_metadata(
        &self,
        _target_epoch: u64,
        _target_round: Round,
    ) -> (Vec<NewBlockEvent>, HashValue) {
        let events: Vec<_> = self
            .sliding_window
            .lock()
            .clone()
            .into_iter()
            .map(|event| self.convert(event))
            .collect();
        (
            events,
            // TODO: fill in the hash value
            HashValue::zero(),
        )
    }
```

**File:** consensus/src/dag/anchor_election/leader_reputation_adapter.rs (L136-139)
```rust
impl AnchorElection for LeaderReputationAdapter {
    fn get_anchor(&self, round: Round) -> Author {
        self.reputation.get_valid_proposer(round)
    }
```

**File:** consensus/src/dag/order_rule.rs (L104-131)
```rust
    fn find_first_anchor_with_enough_votes(
        &self,
        mut start_round: Round,
        target_round: Round,
    ) -> Option<Arc<CertifiedNode>> {
        let dag_reader = self.dag.read();
        while start_round < target_round {
            let anchor_author = self.anchor_election.get_anchor(start_round);
            // I "think" it's impossible to get ordered/committed node here but to double check
            if let Some(anchor_node) =
                dag_reader.get_node_by_round_author(start_round, &anchor_author)
            {
                // f+1 or 2f+1?
                if dag_reader
                    .check_votes_for_node(anchor_node.metadata(), &self.epoch_state.verifier)
                {
                    return Some(anchor_node.clone());
                }
            } else {
                debug!(
                    anchor = anchor_author,
                    "Anchor not found for round {}", start_round
                );
            }
            start_round += 2;
        }
        None
    }
```

**File:** consensus/src/dag/order_rule.rs (L186-194)
```rust
        let event = CommitEvent::new(
            anchor.id(),
            parents,
            failed_authors_and_rounds
                .iter()
                .map(|(_, author)| *author)
                .collect(),
        );
        self.anchor_election.update_reputation(event);
```

**File:** consensus/src/liveness/leader_reputation.rs (L717-730)
```rust
        let state = if self.use_root_hash {
            [
                root_hash.to_vec(),
                self.epoch.to_le_bytes().to_vec(),
                round.to_le_bytes().to_vec(),
            ]
            .concat()
        } else {
            [
                self.epoch.to_le_bytes().to_vec(),
                round.to_le_bytes().to_vec(),
            ]
            .concat()
        };
```

**File:** consensus/src/liveness/proposer_election.rs (L49-69)
```rust
pub(crate) fn choose_index(mut weights: Vec<u128>, state: Vec<u8>) -> usize {
    let mut total_weight = 0;
    // Create cumulative weights vector
    // Since we own the vector, we can safely modify it in place
    for w in &mut weights {
        total_weight = total_weight
            .checked_add(w)
            .expect("Total stake shouldn't exceed u128::MAX");
        *w = total_weight;
    }
    let chosen_weight = next_in_range(state, total_weight);
    weights
        .binary_search_by(|w| {
            if *w <= chosen_weight {
                Ordering::Less
            } else {
                Ordering::Greater
            }
        })
        .expect_err("Comparison never returns equals, so it's always guaranteed to be error")
}
```

**File:** types/src/on_chain_config/consensus_config.rs (L590-608)
```rust
impl Default for DagConsensusConfigV1 {
    /// It is primarily used as `default_if_missing()`.
    fn default() -> Self {
        Self {
            dag_ordering_causal_history_window: 10,
            anchor_election_mode: AnchorElectionMode::LeaderReputation(
                LeaderReputationType::ProposerAndVoterV2(ProposerAndVoterConfig {
                    active_weight: 1000,
                    inactive_weight: 10,
                    failed_weight: 1,
                    failure_threshold_percent: 10,
                    proposer_window_num_validators_multiplier: 10,
                    voter_window_num_validators_multiplier: 1,
                    weight_by_voting_power: true,
                    use_history_from_previous_epoch_max_count: 5,
                }),
            ),
        }
    }
```

**File:** consensus/src/dag/anchor_election/round_robin.rs (L21-24)
```rust
impl AnchorElection for RoundRobinAnchorElection {
    fn get_anchor(&self, round: Round) -> Author {
        self.validators[(round / 2) as usize % self.validators.len()]
    }
```
