# Audit Report

## Title
Byzantine Validators Can Exhaust Tokio Blocking Thread Pool Through Unbounded Randomness Aggregation

## Summary
The randomness generation subsystem spawns unbounded blocking tasks for cryptographic aggregation, allowing Byzantine validators (< 1/3 stake) to exhaust the global 64-thread blocking pool by pre-positioning shares for up to 200 future rounds and triggering simultaneous aggregation when blocks arrive in batches during catch-up or state sync scenarios.

## Finding Description

The vulnerability exists in the randomness aggregation flow where `ShareAggregator::try_aggregate` directly calls `tokio::task::spawn_blocking` without bounded execution controls.

**Verified Attack Flow:**

1. **Share Pre-positioning**: Byzantine validators send randomness shares for up to 200 future rounds. The system accepts shares where `share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT` [1](#0-0) , with `FUTURE_ROUNDS_TO_ACCEPT` configured as 200 [2](#0-1) . Shares are stored in the `rand_map` for aggregation [3](#0-2) .

2. **Threshold Requirements**: The aggregation threshold is set to 2/3 of total validator stake [4](#0-3) [5](#0-4) . While Byzantine validators (< 1/3) cannot meet threshold alone, when combined with honest validator shares during normal operation, threshold is reached [6](#0-5) .

3. **Batch Metadata Arrival**: When consensus produces blocks in batches (default 10, maximum 100 with quorum store override) [7](#0-6) , the `process_incoming_blocks` method iterates through all blocks and calls `process_incoming_metadata` for each [8](#0-7) .

4. **Unbounded Spawning**: For each block, `add_rand_metadata` is called [9](#0-8) , which invokes `try_aggregate` on both slow and fast paths when enabled [10](#0-9) . The `try_aggregate` method spawns blocking tasks directly via `tokio::task::spawn_blocking` [11](#0-10)  without using any bounded executor.

5. **Thread Pool Exhaustion**: The Aptos runtime configures tokio with a maximum of 64 blocking threads globally [12](#0-11) [13](#0-12) . With fast randomness path enabled, each round triggers 2 blocking tasks. Processing 32+ blocks with ready aggregations spawns 64+ tasks simultaneously, exhausting the global limit.

**Critical Code Path:**

While message verification uses a `BoundedExecutor` [14](#0-13) [15](#0-14) , the actual cryptographic aggregation bypasses this protection. The aggregation performs expensive multi-pairing operations for WVUF derivation [16](#0-15) , which are computationally intensive and block the tokio runtime threads.

**Root Cause:**

The `try_aggregate` method lacks resource bounds, creating an unbounded resource consumption path that Byzantine validators can exploit by pre-positioning shares and triggering simultaneous aggregation during batch processing scenarios.

## Impact Explanation

**Severity: High (Validator Node Slowdowns)**

This qualifies as **High Severity** per the Aptos bug bounty program's "Validator node slowdowns" category.

**Concrete Impact:**

1. **Blocking Thread Pool Exhaustion**: The global tokio blocking pool services ALL blocking operations across the validator node, including storage I/O, network operations, and other consensus subsystems. Exhaustion causes queuing delays for all blocking tasks.

2. **Consensus Performance Degradation**: Validators experiencing thread pool exhaustion will have delayed responses to consensus messages, block processing, and vote submissions, potentially causing increased round timeouts, failed consensus participation, reduced network throughput, and possible exclusion from the active validator set.

3. **Cascading Resource Exhaustion**: Other components relying on `spawn_blocking` become unresponsive, compounding performance issues.

4. **Sustained Attack**: Byzantine validators can repeat this attack during any batch processing event (catch-up, state sync, partition recovery), maintaining continuous pressure on honest validators.

The attack does NOT cause total liveness failure (validators can still process blocks once threads become available), but creates significant operational degradation affecting consensus quality and network performance.

## Likelihood Explanation

**Likelihood: Medium-High**

**Attacker Requirements:**
- Byzantine validators with < 1/3 total stake (realistic under BFT assumptions)
- Coordination to send shares for future rounds (trivial via automated scripts)
- No special privileges beyond validator status

**Attack Complexity: Low**
- Pre-sending shares for 100+ rounds requires minimal coordination
- Attack triggers automatically during batch processing (catch-up, state sync)
- Repeatable across epochs without detection

**Detection Difficulty:**
- Appears as legitimate share submissions (all messages verified)
- Thread pool exhaustion manifests as general performance degradation
- Root cause attribution challenging without monitoring spawn_blocking queue depths

**Realistic Scenarios:**
1. **State sync/catchup**: Nodes processing historical blocks in large batches trigger simultaneous aggregation when shares from multiple validators (honest + Byzantine) are already present
2. **Network partition recovery**: Validators rejoining process accumulated blocks while shares have accumulated
3. **Deliberate Byzantine coordination**: Malicious validators intentionally pre-position shares and wait for batch processing events

## Recommendation

Implement bounded execution for randomness aggregation:

1. **Use BoundedExecutor for Aggregation**: Replace direct `tokio::task::spawn_blocking` calls with a `BoundedExecutor` similar to message verification, limiting concurrent aggregation tasks.

2. **Rate Limiting**: Implement per-round aggregation rate limits to prevent simultaneous spawning across multiple rounds.

3. **Aggregation Queue**: Introduce a bounded queue for pending aggregations with FIFO or priority-based processing.

4. **Monitoring**: Add metrics for spawn_blocking queue depths and aggregation task counts to detect resource exhaustion attacks.

## Proof of Concept

A PoC would demonstrate:
1. Configure a test network with Byzantine validators (< 1/3 stake)
2. Pre-send shares for 100 future rounds from Byzantine validators
3. Trigger batch block processing (e.g., simulated catch-up scenario)
4. Monitor blocking thread pool saturation via tokio runtime metrics
5. Observe consensus performance degradation and increased round timeouts

The PoC requires Rust test infrastructure with tokio runtime monitoring and consensus simulation framework.

## Notes

This vulnerability is distinct from network-layer DoS attacks. It exploits protocol-level mechanics (future share acceptance + batch processing + unbounded task spawning) using valid, verified protocol messages. The attack surface exists because the implementation assumes aggregation rate naturally limits itself through consensus progress, but Byzantine actors can artificially create conditions for simultaneous aggregation across many rounds during batch processing events that occur during normal network operations (catch-up, state sync, partition recovery).

### Citations

**File:** consensus/src/rand/rand_gen/rand_store.rs (L47-47)
```rust
        if self.total_weight < rand_config.threshold() {
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L69-69)
```rust
        tokio::task::spawn_blocking(move || {
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L261-277)
```rust
    pub fn add_rand_metadata(&mut self, rand_metadata: FullRandMetadata) {
        let rand_item = self
            .rand_map
            .entry(rand_metadata.round())
            .or_insert_with(|| RandItem::new(self.author, PathType::Slow));
        rand_item.add_metadata(&self.rand_config, rand_metadata.clone());
        rand_item.try_aggregate(&self.rand_config, self.decision_tx.clone());
        // fast path
        if let (Some(fast_rand_map), Some(fast_rand_config)) =
            (self.fast_rand_map.as_mut(), self.fast_rand_config.as_ref())
        {
            let fast_rand_item = fast_rand_map
                .entry(rand_metadata.round())
                .or_insert_with(|| RandItem::new(self.author, PathType::Fast));
            fast_rand_item.add_metadata(fast_rand_config, rand_metadata.clone());
            fast_rand_item.try_aggregate(fast_rand_config, self.decision_tx.clone());
        }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L286-286)
```rust
            share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L304-310)
```rust
                self.rand_map
                    .entry(rand_metadata.round)
                    .or_insert_with(|| RandItem::new(self.author, PathType::Slow)),
            )
        };

        rand_item.add_share(share, rand_config)?;
```

**File:** consensus/src/rand/rand_gen/types.rs (L26-26)
```rust
pub const FUTURE_ROUNDS_TO_ACCEPT: u64 = 200;
```

**File:** consensus/src/rand/rand_gen/types.rs (L134-142)
```rust
        let eval = WVUF::derive_eval(
            &rand_config.wconfig,
            &rand_config.vuf_pp,
            metadata_serialized.as_slice(),
            &rand_config.get_all_certified_apk(),
            &proof,
            THREAD_MANAGER.get_exe_cpu_pool(),
        )
        .map_err(|e| anyhow!("Share::aggregate failed with WVUF derive_eval error: {e}"))?;
```

**File:** consensus/src/rand/rand_gen/types.rs (L683-685)
```rust
    pub fn threshold(&self) -> u64 {
        self.wconfig.get_threshold_weight() as u64
    }
```

**File:** types/src/on_chain_config/randomness_config.rs (L34-36)
```rust
            reconstruction_threshold: FixedPoint64MoveStruct::from_u64f64(
                U64F64::from_num(2) / U64F64::from_num(3),
            ),
```

**File:** config/src/config/consensus_config.rs (L366-370)
```rust
            max_blocks_per_sending_request: 10,
            // TODO: this is for release compatibility, after release we can configure it to match the receiving max
            max_blocks_per_sending_request_quorum_store_override: 10,
            max_blocks_per_receiving_request: 10,
            max_blocks_per_receiving_request_quorum_store_override: 100,
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L132-143)
```rust
    fn process_incoming_blocks(&mut self, blocks: OrderedBlocks) {
        let rounds: Vec<u64> = blocks.ordered_blocks.iter().map(|b| b.round()).collect();
        info!(rounds = rounds, "Processing incoming blocks.");
        let broadcast_handles: Vec<_> = blocks
            .ordered_blocks
            .iter()
            .map(|block| FullRandMetadata::from(block.block()))
            .map(|metadata| self.process_incoming_metadata(metadata))
            .collect();
        let queue_item = QueueItem::new(blocks, Some(broadcast_handles));
        self.block_queue.push_back(queue_item);
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L165-165)
```rust
        rand_store.add_rand_metadata(metadata.clone());
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L227-227)
```rust
        bounded_executor: BoundedExecutor,
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L234-234)
```rust
            bounded_executor
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-27)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;
```

**File:** crates/aptos-runtimes/src/lib.rs (L50-50)
```rust
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```
