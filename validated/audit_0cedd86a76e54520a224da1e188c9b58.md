# Audit Report

## Title
Cross-Epoch Payload Retention Allows Memory Exhaustion DoS in Consensus Observer

## Summary
The consensus observer's payload store incorrectly retains block payloads from future epochs during cleanup operations. A malicious consensus publisher can exploit this by sending payloads for distant future epochs, causing memory exhaustion that prevents legitimate payload processing and disrupts consensus observer functionality.

## Finding Description

The vulnerability exists in the payload cleanup logic during epoch transitions and block commits. The core issue is in `remove_blocks_for_epoch_round()`: [1](#0-0) 

This function uses `BTreeMap::split_off()` with tuple key `(epoch, split_off_round)`. Due to lexicographic tuple comparison, `split_off` returns all entries where `(entry_epoch, entry_round) >= (epoch, split_off_round)`. This correctly removes past epoch payloads but **retains all future epoch payloads**.

**Attack Path:**

1. **Subscription Establishment**: A consensus observer subscribes to a consensus publisher. While observers prefer validators, they may subscribe to fullnode publishers when validators are unavailable or during specific network conditions. [2](#0-1) 

2. **Malicious Payload Injection**: The subscribed malicious publisher sends BlockPayload messages for future epochs (e.g., epochs 100, 200, 300) while the network is at epoch 10. The `process_block_payload_message()` function accepts these: [3](#0-2) 

There is no upper bound check on epoch numbers—only verification that the payload is ahead of the last ordered block.

3. **Unverified Storage**: Future epoch payloads are stored as unverified: [4](#0-3) 

4. **Incomplete Cleanup on Commit**: When blocks are committed, `handle_committed_blocks()` calls `remove_blocks_for_epoch_round()` with the committed epoch: [5](#0-4) 

This only removes payloads up to the committed epoch, leaving future epoch payloads intact.

5. **Incomplete Cleanup on Epoch Transition**: During epoch transitions, `process_commit_sync_notification()` only calls `verify_payload_signatures()`: [6](#0-5) 

The `verify_payload_signatures()` function explicitly skips future epoch payloads: [7](#0-6) 

6. **Store Saturation**: A `handle_reconfig_epoch_change()` function exists that would clear all payloads, but it is never called during epoch transitions. As epochs progress (10→11→12...), malicious payloads from epochs 100+ remain indefinitely. Eventually, the store reaches `max_num_pending_blocks`: [8](#0-7) 

Once full, legitimate payloads are dropped, breaking consensus observer functionality.

## Impact Explanation

This is a **HIGH severity** vulnerability based on Aptos bug bounty criteria:

1. **Validator Node Slowdowns**: When the payload store fills with malicious entries, legitimate payloads cannot be stored. Consensus observers cannot process blocks, disrupting the consensus observer protocol which is designed to improve network efficiency and light client support.

2. **Memory Exhaustion**: Each payload contains transaction data and proof-of-store information. An attacker can fill the store with thousands of malicious payloads (up to `max_num_pending_blocks`), consuming significant memory resources.

3. **Consensus Observer DoS**: The consensus observer becomes unable to fulfill its purpose of receiving and verifying consensus data, effectively rendering it non-functional for the duration of the attack.

This aligns with the **"Validator Node Slowdowns"** HIGH severity category, as it causes performance degradation and DoS through resource exhaustion.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

The attack requires:

1. **Attacker Capabilities**: The attacker must operate a consensus publisher (fullnode with `publisher_enabled=true`). Fullnode operators are not listed as trusted roles in the Aptos threat model.

2. **Subscription Requirement**: The victim observer must subscribe to the attacker's publisher. While observers prefer validators (distance 0), they will subscribe to fullnode publishers when:
   - Validators are unavailable or unreachable
   - Network conditions favor the malicious publisher (low latency, good position)
   - In testnets or edge network topologies [9](#0-8) 

3. **Attack Execution**: Once subscribed, the attack is trivial—simply send BlockPayload messages with arbitrarily high epoch numbers. These pass digest verification and are stored without upper bound validation.

4. **Detection Difficulty**: The attack is stealthy as malicious payloads appear as legitimate future blocks in logs and metrics.

The attack is more complex than arbitrary network peers sending unsolicited messages (prevented by subscription checks), but is realistic under the threat model where fullnode operators are untrusted actors.

## Recommendation

Implement an upper bound check in `process_block_payload_message()` to reject payloads for epochs too far in the future:

```rust
// Add after line 364 in consensus_observer.rs
let epoch_state = self.get_epoch_state();
let max_future_epoch = epoch_state.epoch.saturating_add(2); // Allow max 2 epochs ahead
if block_epoch > max_future_epoch {
    warn!(
        LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
            "Rejecting payload for epoch {} too far in future (current: {})",
            block_epoch, epoch_state.epoch
        ))
    );
    increment_invalid_message_counter(&peer_network_id, metrics::BLOCK_PAYLOAD_LABEL);
    return;
}
```

Alternatively, ensure `handle_reconfig_epoch_change()` is called during epoch transitions to clear all payloads: [10](#0-9) 

## Proof of Concept

A malicious fullnode publisher can exploit this by:
1. Advertising consensus observer protocol support
2. Waiting for observer subscription
3. Sending BlockPayload messages for epochs 100, 200, 300, etc.
4. Monitoring as the payload store fills to `max_num_pending_blocks`
5. Observing legitimate payload drops when observers attempt to store new blocks

The vulnerability can be demonstrated by modifying consensus observer integration tests to inject future epoch payloads and verify they persist across epoch transitions without cleanup.

## Notes

This vulnerability demonstrates a logic flaw in cross-epoch resource management. While subscription checks prevent arbitrary network peers from exploiting this, malicious fullnode publishers (untrusted actors) can trigger the vulnerability once subscribed. The key insight is that `remove_blocks_for_epoch_round()` uses lexicographic comparison on `(epoch, round)` tuples, which mathematically guarantees retention of future epoch entries regardless of cleanup attempts at lower epochs.

### Citations

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L84-95)
```rust
        // Verify that the number of payloads doesn't exceed the maximum
        let max_num_pending_blocks = self.consensus_observer_config.max_num_pending_blocks as usize;
        if self.block_payloads.lock().len() >= max_num_pending_blocks {
            warn!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Exceeded the maximum number of payloads: {:?}. Dropping block: {:?}!",
                    max_num_pending_blocks,
                    block_payload.block(),
                ))
            );
            return; // Drop the block if we've exceeded the maximum
        }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L112-119)
```rust
    pub fn remove_blocks_for_epoch_round(&self, epoch: u64, round: Round) {
        // Determine the round to split off
        let split_off_round = round.saturating_add(1);

        // Remove the blocks from the payload store
        let mut block_payloads = self.block_payloads.lock();
        *block_payloads = block_payloads.split_off(&(epoch, split_off_round));
    }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L227-231)
```rust
        for (epoch, round) in payload_epochs_and_rounds {
            // Check if we can break early (BtreeMaps are sorted by key)
            if epoch > current_epoch {
                break;
            }
```

**File:** consensus/src/consensus_observer/observer/subscription_manager.rs (L363-385)
```rust
    pub fn verify_message_for_subscription(
        &mut self,
        message_sender: PeerNetworkId,
    ) -> Result<(), Error> {
        // Check if the message is from an active subscription
        if let Some(active_subscription) = self
            .active_observer_subscriptions
            .lock()
            .get_mut(&message_sender)
        {
            // Update the last message receive time and return early
            active_subscription.update_last_message_receive_time();
            return Ok(());
        }

        // Otherwise, the message is not from an active subscription.
        // Send another unsubscribe request, and return an error.
        self.unsubscribe_from_peer(message_sender);
        Err(Error::InvalidMessageError(format!(
            "Received message from unexpected peer, and not an active subscription: {}!",
            message_sender
        )))
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L366-380)
```rust
        // Determine if the payload is behind the last ordered block, or if it already exists
        let last_ordered_block = self.observer_block_data.lock().get_last_ordered_block();
        let payload_out_of_date =
            (block_epoch, block_round) <= (last_ordered_block.epoch(), last_ordered_block.round());
        let payload_exists = self
            .observer_block_data
            .lock()
            .existing_payload_entry(&block_payload);

        // If the payload is out of date or already exists, ignore it
        if payload_out_of_date || payload_exists {
            // Update the metrics for the dropped block payload
            update_metrics_for_dropped_block_payload_message(peer_network_id, &block_payload);
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L399-418)
```rust
        // If the payload is for the current epoch, verify the proof signatures
        let epoch_state = self.get_epoch_state();
        let verified_payload = if block_epoch == epoch_state.epoch {
            // Verify the block proof signatures
            if let Err(error) = block_payload.verify_payload_signatures(&epoch_state) {
                // Log the error and update the invalid message counter
                error!(
                    LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                        "Failed to verify block payload signatures! Ignoring block: {:?}, from peer: {:?}. Error: {:?}",
                        block_payload.block(), peer_network_id, error
                    ))
                );
                increment_invalid_message_counter(&peer_network_id, metrics::BLOCK_PAYLOAD_LABEL);
                return;
            }

            true // We have successfully verified the signatures
        } else {
            false // We can't verify the signatures yet
        };
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L1033-1044)
```rust
            // Verify the block payloads for the new epoch
            let new_epoch_state = self.get_epoch_state();
            let verified_payload_rounds = self
                .observer_block_data
                .lock()
                .verify_payload_signatures(&new_epoch_state);

            // Order all the pending blocks that are now ready (these were buffered during state sync)
            for payload_round in verified_payload_rounds {
                self.order_ready_pending_block(new_epoch_state.epoch, payload_round)
                    .await;
            }
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L182-189)
```rust
    fn handle_committed_blocks(&mut self, ledger_info: LedgerInfoWithSignatures) {
        // Remove the committed blocks from the payload and ordered block stores
        self.block_payload_store.remove_blocks_for_epoch_round(
            ledger_info.commit_info().epoch(),
            ledger_info.commit_info().round(),
        );
        self.ordered_block_store
            .remove_blocks_for_commit(&ledger_info);
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L282-286)
```rust
        self.update_root(commit_proof.clone());

        // Update the block payload store
        self.block_payload_store
            .remove_blocks_for_epoch_round(commit_epoch, commit_round);
```

**File:** consensus/src/consensus_observer/observer/subscription_utils.rs (L283-300)
```rust
pub fn sort_peers_by_subscription_optimality(
    peers_and_metadata: &HashMap<PeerNetworkId, PeerMetadata>,
) -> Vec<PeerNetworkId> {
    // Group peers and latencies by validator distance, i.e., distance -> [(peer, latency)]
    let mut unsupported_peers = Vec::new();
    let mut peers_and_latencies_by_distance = BTreeMap::new();
    for (peer_network_id, peer_metadata) in peers_and_metadata {
        // Verify that the peer supports consensus observer
        if !supports_consensus_observer(peer_metadata) {
            unsupported_peers.push(*peer_network_id);
            continue; // Skip the peer
        }

        // Get the distance and latency for the peer
        let distance = get_distance_for_peer(peer_network_id, peer_metadata);
        let latency = get_latency_for_peer(peer_network_id, peer_metadata);

        // If the distance is not found, use the maximum distance
```
