# Audit Report

## Title
V2 Batch Storage Leak: Orphaned Records in batch_v2 Column Family Cause Storage Exhaustion

## Summary
The quorum store batch cleanup logic contains two critical bugs that prevent V2 batches from being deleted from the database. When `enable_batch_v2` is enabled, expired V2 batches accumulate indefinitely in the `batch_v2` column family, causing unbounded storage growth and eventual disk exhaustion on validator nodes.

## Finding Description

The Aptos consensus quorum store uses two separate column families to store batches: `BATCH_CF_NAME` ("batch") for V1 batches and `BATCH_V2_CF_NAME` ("batch_v2") for V2 batches. [1](#0-0) 

The database correctly implements separate schemas: `BatchSchema` uses the "batch" column family, while `BatchV2Schema` uses the "batch_v2" column family. [2](#0-1) 

When batches are persisted, the code correctly routes them to the appropriate column family based on batch version. [3](#0-2) 

However, there are **two critical bugs** in the cleanup logic:

**Bug #1: Epoch-based cleanup for V2 batches deletes from wrong column family**

The `gc_previous_epoch_batches_from_db_v2()` function reads V2 batches from the database using `get_all_batches_v2()` but then incorrectly calls `delete_batches()` which targets the V1 column family instead of `delete_batches_v2()`. [4](#0-3) 

The `delete_batches()` method exclusively operates on the `BatchSchema` (V1) column family: [5](#0-4) 

While `delete_batches_v2()` correctly targets `BatchV2Schema` (V2): [6](#0-5) 

**Bug #2: Regular expiration cleanup only targets V1 column family**

The `update_certified_timestamp()` function, which is called regularly during consensus when blocks are committed, only deletes from the V1 column family. [7](#0-6) 

This function is triggered on every block commit via the consensus payload manager: [8](#0-7) 

The `clear_expired_payload()` function removes expired entries from the unified in-memory cache (`db_cache: DashMap<HashValue, PersistedValue<BatchInfoExt>>`) which stores both V1 and V2 batches together. [9](#0-8) 

However, the subsequent delete operation only calls `delete_batches()`, leaving V2 batch records orphaned in the `batch_v2` column family.

**Attack Path:**

1. A validator enables V2 batches by setting `enable_batch_v2 = true` in the quorum store configuration (defaults to false). [10](#0-9) 

2. The batch generator creates V2 batches when this flag is enabled, storing them via `save_batch_v2()`. [11](#0-10) 

3. During normal consensus operation, `notify_commit()` triggers `update_certified_timestamp()` on every block commit.

4. Expired V2 batches are removed from the in-memory cache but never deleted from disk because `delete_batches()` targets only the V1 column family.

5. V2 batches accumulate indefinitely in the `batch_v2` column family until storage is exhausted.

## Impact Explanation

**Severity: Medium**

This vulnerability causes storage exhaustion on validator nodes running with V2 batches enabled. The impact includes:

1. **Unbounded Storage Growth**: Every V2 batch created remains in the database forever, consuming disk space indefinitely
2. **Node Failure**: When disk space is exhausted, the validator node will crash or become unable to write new data
3. **Consensus Degradation**: Failed validators reduce network resilience and could impact consensus if enough nodes are affected
4. **Operational Overhead**: Requires manual intervention to clean up orphaned records or restore from backup

This meets the **Medium severity** criterion ($10,000 in the Aptos bug bounty program) for "State inconsistencies requiring manual intervention." It does not reach High severity because:
- It doesn't cause immediate consensus violation
- It doesn't directly enable fund theft
- Recovery is possible through disk cleanup and node restart
- The feature defaults to disabled

## Likelihood Explanation

**Likelihood: High** (when V2 batches are enabled)

The vulnerability will automatically occur on any validator that:
1. Enables `enable_batch_v2 = true` in their configuration (a single config change)
2. Runs for an extended period (days to weeks depending on batch creation rate)

No attacker action is required - Bug #2 triggers on every block commit during normal consensus operation, causing rapid accumulation of orphaned V2 batches. The default configuration disables V2 batches, limiting real-world impact to validators who explicitly enable this experimental feature for testing or deployment.

## Recommendation

**Fix for Bug #1:** Change line 241 in `batch_store.rs` to call the correct deletion method:

```rust
db.delete_batches_v2(expired_keys)  // Changed from delete_batches
    .expect("Deletion of expired keys should not fail");
```

**Fix for Bug #2:** Modify `update_certified_timestamp()` to delete from both column families. The function should check which batches are V2 and route deletions appropriately, or maintain separate expired key lists for V1 and V2 batches.

## Proof of Concept

The vulnerability can be reproduced as follows:

1. Configure a validator node with `enable_batch_v2 = true` in the quorum store configuration
2. Start the validator and allow it to participate in consensus
3. Monitor the `batch_v2` column family size over time using RocksDB statistics
4. Observe that expired V2 batches are never deleted from persistent storage
5. After sufficient time (days/weeks), the disk will fill with orphaned batch records

The cleanup functions `gc_previous_epoch_batches_from_db_v2` and `update_certified_timestamp` can be traced to confirm they never invoke `delete_batches_v2()` for removing expired V2 batches from the database.

## Notes

- This vulnerability affects only validators who explicitly enable the `enable_batch_v2` configuration flag, which defaults to `false`
- The V2 batch format appears to be an experimental or newer feature not yet widely deployed
- The correct cleanup pattern is demonstrated in `populate_cache_and_gc_expired_batches_v2()` which properly calls `delete_batches_v2()`: [12](#0-11) 

- Both cleanup bugs result in the same outcome: V2 batches remain in the database indefinitely after expiration
- Bug #2 is more severe as it triggers multiple times per second during normal operation, while Bug #1 only triggers during epoch transitions

### Citations

**File:** consensus/src/quorum_store/schema.rs (L14-16)
```rust
pub(crate) const BATCH_CF_NAME: ColumnFamilyName = "batch";
pub(crate) const BATCH_ID_CF_NAME: ColumnFamilyName = "batch_ID";
pub(crate) const BATCH_V2_CF_NAME: ColumnFamilyName = "batch_v2";
```

**File:** consensus/src/quorum_store/schema.rs (L18-56)
```rust
#[derive(Debug)]
pub(crate) struct BatchSchema;

impl Schema for BatchSchema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfo>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_CF_NAME;
}

impl KeyCodec<BatchSchema> for HashValue {
    fn encode_key(&self) -> Result<Vec<u8>> {
        Ok(self.to_vec())
    }

    fn decode_key(data: &[u8]) -> Result<Self> {
        Ok(HashValue::from_slice(data)?)
    }
}

impl ValueCodec<BatchSchema> for PersistedValue<BatchInfo> {
    fn encode_value(&self) -> Result<Vec<u8>> {
        Ok(bcs::to_bytes(&self)?)
    }

    fn decode_value(data: &[u8]) -> Result<Self> {
        Ok(bcs::from_bytes(data)?)
    }
}

#[derive(Debug)]
pub(crate) struct BatchV2Schema;

impl Schema for BatchV2Schema {
    type Key = HashValue;
    type Value = PersistedValue<BatchInfoExt>;

    const COLUMN_FAMILY_NAME: aptos_schemadb::ColumnFamilyName = BATCH_V2_CF_NAME;
}
```

**File:** consensus/src/quorum_store/batch_store.rs (L113-116)
```rust
pub struct BatchStore {
    epoch: OnceCell<u64>,
    last_certified_time: AtomicU64,
    db_cache: DashMap<HashValue, PersistedValue<BatchInfoExt>>,
```

**File:** consensus/src/quorum_store/batch_store.rs (L212-243)
```rust
    fn gc_previous_epoch_batches_from_db_v2(db: Arc<dyn QuorumStoreStorage>, current_epoch: u64) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read data from db");
        info!(
            epoch = current_epoch,
            "QS: Read batches from storage. Len: {}",
            db_content.len(),
        );

        let mut expired_keys = Vec::new();
        for (digest, value) in db_content {
            let epoch = value.epoch();

            trace!(
                "QS: Batchreader recovery content epoch {:?}, digest {}",
                epoch,
                digest
            );

            if epoch < current_epoch {
                expired_keys.push(digest);
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        db.delete_batches(expired_keys)
            .expect("Deletion of expired keys should not fail");
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L292-336)
```rust
    fn populate_cache_and_gc_expired_batches_v2(
        db: Arc<dyn QuorumStoreStorage>,
        current_epoch: u64,
        last_certified_time: u64,
        expiration_buffer_usecs: u64,
        batch_store: &BatchStore,
    ) {
        let db_content = db
            .get_all_batches_v2()
            .expect("failed to read v1 data from db");
        info!(
            epoch = current_epoch,
            "QS: Read v1 batches from storage. Len: {}, Last Cerified Time: {}",
            db_content.len(),
            last_certified_time
        );

        let mut expired_keys = Vec::new();
        let gc_timestamp = last_certified_time.saturating_sub(expiration_buffer_usecs);
        for (digest, value) in db_content {
            let expiration = value.expiration();
            trace!(
                "QS: Batchreader recovery content exp {:?}, digest {}",
                expiration,
                digest
            );

            if expiration < gc_timestamp {
                expired_keys.push(digest);
            } else {
                batch_store
                    .insert_to_cache(&value)
                    .expect("Storage limit exceeded upon BatchReader construction");
            }
        }

        info!(
            "QS: Batch store bootstrap expired keys len {}",
            expired_keys.len()
        );
        tokio::task::spawn_blocking(move || {
            db.delete_batches_v2(expired_keys)
                .expect("Deletion of expired keys should not fail");
        });
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L501-513)
```rust
                    if !batch_info.is_v2() {
                        let persist_request =
                            persist_request.try_into().expect("Must be a V1 batch");
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L530-539)
```rust
    pub fn update_certified_timestamp(&self, certified_time: u64) {
        trace!("QS: batch reader updating time {:?}", certified_time);
        self.last_certified_time
            .fetch_max(certified_time, Ordering::SeqCst);

        let expired_keys = self.clear_expired_payload(certified_time);
        if let Err(e) = self.db.delete_batches(expired_keys) {
            debug!("Error deleting batches: {:?}", e)
        }
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L93-101)
```rust
    fn delete_batches(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchSchema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L123-131)
```rust
    fn delete_batches_v2(&self, digests: Vec<HashValue>) -> Result<(), DbError> {
        let mut batch = SchemaBatch::new();
        for digest in digests.iter() {
            trace!("QS: db delete digest {}", digest);
            batch.delete::<BatchV2Schema>(digest)?;
        }
        self.db.write_schemas_relaxed(batch)?;
        Ok(())
    }
```

**File:** consensus/src/quorum_store/quorum_store_db.rs (L140-147)
```rust
    fn save_batch_v2(&self, batch: PersistedValue<BatchInfoExt>) -> Result<(), DbError> {
        trace!(
            "QS: db persists digest {} expiration {:?}",
            batch.digest(),
            batch.expiration()
        );
        self.put::<BatchV2Schema>(batch.digest(), &batch)
    }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L168-170)
```rust
    fn notify_commit(&self, block_timestamp: u64, payloads: Vec<Payload>) {
        self.batch_reader
            .update_certified_timestamp(block_timestamp);
```

**File:** config/src/config/quorum_store_config.rs (L102-144)
```rust
    pub enable_batch_v2: bool,
}

impl Default for QuorumStoreConfig {
    fn default() -> QuorumStoreConfig {
        QuorumStoreConfig {
            channel_size: 1000,
            proof_timeout_ms: 10000,
            batch_generation_poll_interval_ms: 25,
            batch_generation_min_non_empty_interval_ms: 50,
            batch_generation_max_interval_ms: 250,
            sender_max_batch_txns: DEFEAULT_MAX_BATCH_TXNS,
            // TODO: on next release, remove BATCH_PADDING_BYTES
            sender_max_batch_bytes: 1024 * 1024 - BATCH_PADDING_BYTES,
            sender_max_num_batches: DEFAULT_MAX_NUM_BATCHES,
            sender_max_total_txns: 1500,
            // TODO: on next release, remove DEFAULT_MAX_NUM_BATCHES * BATCH_PADDING_BYTES
            sender_max_total_bytes: 4 * 1024 * 1024 - DEFAULT_MAX_NUM_BATCHES * BATCH_PADDING_BYTES,
            receiver_max_batch_txns: 100,
            receiver_max_batch_bytes: 1024 * 1024 + BATCH_PADDING_BYTES,
            receiver_max_num_batches: 20,
            receiver_max_total_txns: 2000,
            receiver_max_total_bytes: 4 * 1024 * 1024
                + DEFAULT_MAX_NUM_BATCHES
                + BATCH_PADDING_BYTES,
            batch_request_num_peers: 5,
            batch_request_retry_limit: 10,
            batch_request_retry_interval_ms: 500,
            batch_request_rpc_timeout_ms: 5000,
            batch_expiry_gap_when_init_usecs: Duration::from_secs(60).as_micros() as u64,
            remote_batch_expiry_gap_when_init_usecs: Duration::from_millis(500).as_micros() as u64,
            memory_quota: 120_000_000,
            db_quota: 300_000_000,
            batch_quota: 300_000,
            back_pressure: QuorumStoreBackPressureConfig::default(),
            // number of batch coordinators to handle QS batch messages, should be >= 1
            num_workers_for_remote_batches: 10,
            batch_buckets: DEFAULT_BUCKETS.to_vec(),
            allow_batches_without_pos_in_proposal: true,
            enable_opt_quorum_store: true,
            opt_qs_minimum_batch_age_usecs: Duration::from_millis(50).as_micros() as u64,
            enable_payload_v2: false,
            enable_batch_v2: false,
```
