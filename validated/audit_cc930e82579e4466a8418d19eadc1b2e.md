# Audit Report

## Title
Memory Ordering Vulnerability in DelayedFieldID Serialization Causes Non-Deterministic State Roots Across Validators

## Summary
The `VersionedDelayedFields::read_latest_predicted_value()` method uses `Ordering::Relaxed` when loading the `next_idx_to_commit` atomic counter, which can cause different validators to observe different delayed field values during transaction materialization. This memory ordering bug violates deterministic execution guarantees and can trigger consensus failures across the Aptos network.

## Finding Description

The vulnerability exists in the delayed field value resolution mechanism during post-commit transaction materialization. When BlockSTMv2 commits transaction i, it calls `try_commit(i)` which increments `next_idx_to_commit` from i to i+1 using `Ordering::SeqCst`. [1](#0-0) 

Subsequently, when a worker thread materializes transaction i via `materialize_txn_commit()`, it needs to convert `DelayedFieldID` identifiers in the write set to concrete values for serialization. [2](#0-1) 

This materialization process calls `identifier_to_value()` [3](#0-2)  which invokes `read_latest_predicted_value()` with `ReadPosition::AfterCurrentTxn` to read values including transaction i's committed changes.

**The critical vulnerability is on line 763**: The method loads `next_idx_to_commit` using `Ordering::Relaxed`, which provides zero synchronization guarantees. [4](#0-3) 

The `read_latest_predicted_value()` implementation uses `range(0..next_idx_to_commit).next_back()` to find the latest committed value. [5](#0-4)  When materializing transaction i:

- **Correct behavior**: `next_idx_to_commit = i+1`, range is `[0..i+1)`, reads index i (transaction i's value)
- **Buggy behavior**: If the Relaxed load observes stale value i, range is `[0..i)`, reads index i-1 (transaction i-1's value)

This causes transaction i to serialize with incorrect delayed field values, producing different state roots across validators if the race manifests differently due to CPU cache timing or memory reordering on weak memory architectures.

The execution flow shows that post-commit materialization runs in parallel with sequential commit hooks on different worker threads. [6](#0-5)  While the ConcurrentQueue operations provide acquire-release ordering, the explicit `Ordering::Relaxed` bypasses this synchronization, allowing the compiler and CPU to reorder operations or use stale cached values.

## Impact Explanation

This is a **Critical Severity** vulnerability under the Aptos Bug Bounty criteria for "Consensus/Safety Violations". 

The bug breaks the fundamental **Deterministic Execution** invariant that all validators must produce identical state roots for identical blocks. When the memory ordering race manifests differently across validators:

1. **Consensus failure**: Validators compute different state roots and cannot reach agreement on block validity
2. **Network partition risk**: Without consensus on state transitions, the network splits into incompatible forks
3. **Liveness loss**: Transaction processing halts as validators cannot make progress on divergent states
4. **Recovery difficulty**: The non-deterministic nature makes debugging extremely difficult, potentially requiring emergency hard forks

This directly maps to the Critical impact category: "Different validators commit different blocks" and "Chain splits without hardfork requirement."

## Likelihood Explanation

**Likelihood: Medium** - Architecture and workload dependent.

The vulnerability manifests when:
1. Transactions contain delayed fields (aggregators, snapshots, derived values)
2. Post-commit materialization executes concurrently with subsequent commits
3. CPU memory reordering or cache effects cause the Relaxed load to observe stale values

**Triggering factors:**
- **High on ARM architectures**: Weak memory models allow extensive reordering, making the bug much more likely to manifest
- **Low on x86 architectures**: Strong memory model masks many ordering issues, but future compiler optimizations could still expose the bug
- **Depends on workload**: Higher transaction throughput with more delayed fields increases parallel processing and race window

The bug is triggerable during normal network operation without attacker action - any user submitting transactions with delayed fields can unknowingly trigger the race condition. The non-deterministic nature makes it particularly dangerous as intermittent consensus failures are difficult to diagnose.

## Recommendation

**Fix**: Change the memory ordering from `Ordering::Relaxed` to at least `Ordering::Acquire` on line 763.

```rust
.min(self.next_idx_to_commit.load(Ordering::Acquire))
```

`Ordering::Acquire` ensures that all writes that happened-before the corresponding `SeqCst` store in `try_commit()` are visible when the value is loaded. This maintains the synchronization guarantee needed for deterministic execution.

Alternatively, use `Ordering::SeqCst` for both load and store to provide the strongest consistency guarantees, though `Acquire` is sufficient here since we only need to observe prior committed values.

## Proof of Concept

Due to the non-deterministic and architecture-dependent nature of memory ordering bugs, a deterministic PoC is not feasible. The vulnerability requires specific CPU cache timing and memory reordering patterns that vary across hardware.

**Evidence of vulnerability:**
- Line 763 uses `Ordering::Relaxed` for a load that must observe sequentially consistent stores [7](#0-6) 
- The commit phase uses `Ordering::SeqCst` expecting proper synchronization [8](#0-7) 
- Parallel materialization can race with sequential commits [9](#0-8) 

The bug violates Rust's memory model guarantees and would be caught by tools like ThreadSanitizer or Loom under the right conditions. Testing on ARM hardware with high transaction throughput involving delayed fields would likely expose consensus divergence.

## Notes

This vulnerability affects the core parallel execution engine (BlockSTMv2) and impacts all transactions using delayed fields (aggregators v2). The fix is straightforward but critical - proper memory ordering is essential for maintaining consensus in distributed systems. The bug demonstrates why memory ordering must be carefully considered in consensus-critical code paths, especially in systems that execute on diverse hardware architectures.

### Citations

**File:** aptos-move/mvhashmap/src/versioned_delayed_fields.rs (L231-233)
```rust
        self.versioned_map
            .range(0..next_idx_to_commit)
            .next_back()
```

**File:** aptos-move/mvhashmap/src/versioned_delayed_fields.rs (L680-684)
```rust
        // Need to assert, because if not matching we are in an inconsistent state.
        assert_eq!(
            idx_to_commit,
            self.next_idx_to_commit.fetch_add(1, Ordering::SeqCst)
        );
```

**File:** aptos-move/mvhashmap/src/versioned_delayed_fields.rs (L758-764)
```rust
                v.read_latest_predicted_value(
                    match read_position {
                        ReadPosition::BeforeCurrentTxn => current_txn_idx,
                        ReadPosition::AfterCurrentTxn => current_txn_idx + 1,
                    }
                    .min(self.next_idx_to_commit.load(Ordering::Relaxed)),
                )
```

**File:** aptos-move/block-executor/src/executor.rs (L1209-1210)
```rust
        let materialized_resource_write_set =
            map_id_to_values_in_write_set(resource_writes_to_materialize, &latest_view)?;
```

**File:** aptos-move/block-executor/src/executor.rs (L1455-1515)
```rust
            while scheduler.commit_hooks_try_lock() {
                // Perform sequential commit hooks.
                while let Some((txn_idx, incarnation)) = scheduler.start_commit()? {
                    self.prepare_and_queue_commit_ready_txn(
                        txn_idx,
                        incarnation,
                        num_txns,
                        executor,
                        block,
                        num_workers as usize,
                        runtime_environment,
                        scheduler_wrapper,
                        shared_sync_params,
                    )?;
                }

                scheduler.commit_hooks_unlock();
            }

            match scheduler.next_task(worker_id)? {
                TaskKind::Execute(txn_idx, incarnation) => {
                    if incarnation > num_workers.pow(2) + num_txns + 30 {
                        // Something is wrong if we observe high incarnations (e.g. a bug
                        // might manifest as an execution-invalidation cycle). Break out
                        // to fallback to sequential execution.
                        error!("Observed incarnation {} of txn {txn_idx}", incarnation);
                        return Err(PanicOr::Or(ParallelBlockExecutionError::IncarnationTooHigh));
                    }

                    Self::execute_v2(
                        worker_id,
                        txn_idx,
                        incarnation,
                        block.get_txn(txn_idx),
                        &block.get_auxiliary_info(txn_idx),
                        last_input_output,
                        versioned_cache,
                        executor,
                        base_view,
                        shared_sync_params.global_module_cache,
                        runtime_environment,
                        ParallelState::new(
                            versioned_cache,
                            scheduler_wrapper,
                            shared_sync_params.start_shared_counter,
                            shared_sync_params.delayed_field_id_counter,
                            incarnation,
                        ),
                        scheduler,
                        &self.config.onchain.block_gas_limit_type,
                    )?;
                },
                TaskKind::PostCommitProcessing(txn_idx) => {
                    self.materialize_txn_commit(
                        txn_idx,
                        scheduler_wrapper,
                        environment,
                        shared_sync_params,
                    )?;
                    self.record_finalized_output(txn_idx, txn_idx, shared_sync_params)?;
                },
```

**File:** aptos-move/block-executor/src/value_exchange.rs (L86-107)
```rust
    fn identifier_to_value(
        &self,
        layout: &MoveTypeLayout,
        identifier: DelayedFieldID,
    ) -> PartialVMResult<Value> {
        self.delayed_field_ids.borrow_mut().insert(identifier);
        let delayed_field = match &self.latest_view.latest_view {
            ViewState::Sync(state) => state
                .versioned_map
                .delayed_fields()
                .read_latest_predicted_value(
                    &identifier,
                    self.txn_idx,
                    ReadPosition::AfterCurrentTxn,
                )
                .expect("Committed value for ID must always exist"),
            ViewState::Unsync(state) => state
                .read_delayed_field(identifier)
                .expect("Delayed field value for ID must always exist in sequential execution"),
        };
        delayed_field.try_into_move_value(layout, identifier.extract_width())
    }
```
