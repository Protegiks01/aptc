# Audit Report

## Title
Resource Exhaustion via False Data Advertisement in State Sync Bootstrap Process

## Summary
Malicious peers can advertise epoch ending ledger infos and other sync data they don't actually possess, causing validators to waste significant resources (up to ~9.5 minutes per malicious peer) through repeated retry attempts with exponential backoff before the peer is eventually ignored. This creates a resource exhaustion attack vector during the critical bootstrapping phase.

## Finding Description

The state sync system relies on trust-based data advertisement where peers broadcast their available data ranges via `StorageServerSummary` without cryptographic proof of possession. Storage summaries are accepted and stored without verification: [1](#0-0) 

When validators bootstrap, they query the network for advertised data and create data streams to fetch epoch ending ledger infos: [2](#0-1) 

The vulnerability manifests in the following attack flow:

**1. Advertisement Without Verification**: Malicious peers advertise fake data ranges that don't exist in their storage. The system validates requests against advertised ranges but doesn't verify actual data possession at advertisement time.

**2. Trust-Based Request Routing**: The data client checks if peers claim to have data via `can_service_request()` before routing requests, but this only validates against advertised summaries: [3](#0-2) 

**3. Retry Mechanism Exploitation**: When requests fail (malicious peer doesn't actually have the data), the system retries with exponential backoff. The retry timeout calculation uses exponential growth bounded by a maximum: [4](#0-3) 

With configuration defaults of `response_timeout_ms: 10_000` and `max_response_timeout_ms: 60_000`: [5](#0-4) 

The timeout progression is: 10s + 20s + 40s + 60s + 60s = 190 seconds per stream.

The maximum retry count before stream termination is configured as: [6](#0-5) [7](#0-6) 

**4. Gradual Peer Scoring**: When a peer returns errors (because it doesn't have the advertised data), the client scores down the peer gradually: [8](#0-7) [9](#0-8) 

The scoring multiplier for non-useful responses is: [10](#0-9) 

Starting from score 50.0, it takes approximately 14 bad responses (50.0 × 0.95^14 ≈ 24.4) to reach the ignore threshold: [11](#0-10) 

With 5 retries per stream and ~14 bad responses needed, this equals approximately 3 stream cycles, totaling ~9.5 minutes (190s × 3 = 570s) of wasted resources per malicious peer.

## Impact Explanation

This vulnerability meets **Medium Severity** criteria per Aptos bug bounty guidelines, specifically "Temporary liveness issues":

- **Validator Bootstrap Delays**: During bootstrapping, validators waste ~9.5 minutes per malicious peer attempting to sync fake data, significantly delaying their ability to participate in consensus.

- **Resource Exhaustion**: The repeated retry attempts with exponential backoff consume CPU cycles, network bandwidth, and delay critical bootstrap operations.

- **Amplification through Coordination**: Multiple malicious peers can multiply the impact linearly. With 10 coordinated attackers, a validator could waste ~95 minutes during bootstrap.

- **Attack Surface**: The vulnerability affects any validator undergoing bootstrap - new validators, recovering validators, or validators rejoining after downtime.

While the system does automatically recover through peer scoring (peers are eventually ignored), the substantial delay during the critical bootstrap phase constitutes a temporary liveness issue affecting validator participation.

## Likelihood Explanation

**High Likelihood** - The attack requires minimal sophistication:

1. **Low Barrier to Entry**: Attacker only needs to run a modified storage service node that advertises false data ranges. No validator keys, stake, or consensus participation required.

2. **No Upfront Verification**: The system accepts peer advertisements without cryptographic proof of data possession.

3. **Predictable Exploitation**: The ~9.5 minute exploitation window per peer is deterministic and guaranteed by the retry configuration.

4. **Network Reachability**: Any peer that can establish P2P connections can execute this attack.

5. **Frequent Attack Opportunities**: Bootstrapping is common for new validators, recovering validators, and validators rejoining after downtime.

## Recommendation

Implement cryptographic proof-of-possession for advertised data:

1. **Challenge-Response Protocol**: When peers advertise data ranges, require them to provide cryptographic proofs (e.g., Merkle proofs) for random samples within the advertised ranges during the advertisement phase.

2. **Faster Peer Filtering**: Reduce the peer scoring multiplier for clearly malicious behavior (e.g., 0.8x instead of 0.95x for peers that consistently fail to provide advertised data).

3. **Reduce Retry Backoff**: Decrease the maximum retry count or reduce exponential backoff growth rate to limit resource waste per malicious peer.

4. **Parallel Verification**: Query multiple peers simultaneously for the same data range and compare responses to identify malicious peers faster.

## Proof of Concept

A malicious peer can implement the following behavior:

1. Run a modified storage service that advertises extensive data ranges in `StorageServerSummary`
2. When receiving actual data requests, the server-side validation will detect the peer doesn't have the data
3. Return errors for all requests
4. Client will retry with exponential backoff 5 times per stream
5. After ~14 failed requests across ~3 stream cycles, the peer is finally ignored
6. Total resource waste: ~9.5 minutes per bootstrapping validator

The attack exploits the trust-based advertisement system where `update_storage_summary` accepts summaries without verification, and `can_service_request` only validates against claimed capabilities rather than actual data possession.

## Notes

The vulnerability is particularly impactful during network-wide events (hard forks, mass restarts) when many validators simultaneously bootstrap. While individual validators eventually recover through the peer scoring mechanism, coordinated attacks with multiple malicious peers can significantly delay network recovery. The core issue is the lack of upfront verification when peers advertise data capabilities, combined with generous retry policies that assume peer honesty.

### Citations

**File:** state-sync/aptos-data-client/src/peer_states.rs (L35-43)
```rust
const STARTING_SCORE: f64 = 50.0;
/// Add this score on a successful response.
const SUCCESSFUL_RESPONSE_DELTA: f64 = 1.0;
/// Not necessarily a malicious response, but not super useful.
const NOT_USEFUL_MULTIPLIER: f64 = 0.95;
/// Likely to be a malicious response.
const MALICIOUS_MULTIPLIER: f64 = 0.8;
/// Ignore a peer when their score dips below this threshold.
const IGNORE_PEER_THRESHOLD: f64 = 25.0;
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L177-179)
```rust
    fn update_storage_summary(&mut self, storage_summary: StorageServerSummary) {
        self.storage_summary = Some(storage_summary);
    }
```

**File:** state-sync/aptos-data-client/src/peer_states.rs (L200-227)
```rust
    pub fn can_service_request(
        &self,
        peer: &PeerNetworkId,
        time_service: TimeService,
        request: &StorageServiceRequest,
    ) -> bool {
        // Storage services can always respond to data advertisement requests.
        // We need this outer check, since we need to be able to send data summary
        // requests to new peers (who don't have a peer state yet).
        if request.data_request.is_storage_summary_request()
            || request.data_request.is_protocol_version_request()
        {
            return true;
        }

        // Check if the peer can service the request
        if let Some(peer_state) = self.peer_to_state.get(peer) {
            return match peer_state.get_storage_summary_if_not_ignored() {
                Some(storage_summary) => {
                    storage_summary.can_service(&self.data_client_config, time_service, request)
                },
                None => false, // The peer is temporarily ignored
            };
        }

        // Otherwise, the request cannot be serviced
        false
    }
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L822-829)
```rust
        let highest_advertised_epoch_end = global_data_summary
            .advertised_data
            .highest_epoch_ending_ledger_info()
            .ok_or_else(|| {
                Error::AdvertisedDataError(
                    "No highest advertised epoch end found in the network!".into(),
                )
            })?;
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L351-378)
```rust
            let response_timeout_ms = self.data_client_config.response_timeout_ms;
            let max_response_timeout_ms = self.data_client_config.max_response_timeout_ms;

            // Exponentially increase the timeout based on the number of
            // previous failures (but bounded by the max timeout).
            let request_timeout_ms = min(
                max_response_timeout_ms,
                response_timeout_ms * (u32::pow(2, self.request_failure_count as u32) as u64),
            );

            // Update the retry counter and log the request
            increment_counter_multiple_labels(
                &metrics::RETRIED_DATA_REQUESTS,
                data_client_request.get_label(),
                &request_timeout_ms.to_string(),
            );
            info!(
                (LogSchema::new(LogEntry::RetryDataRequest)
                    .stream_id(self.data_stream_id)
                    .message(&format!(
                        "Retrying data request type: {:?}, with new timeout: {:?} (ms)",
                        data_client_request.get_label(),
                        request_timeout_ms.to_string()
                    )))
            );

            request_timeout_ms
        };
```

**File:** config/src/config/state_sync_config.rs (L256-257)
```rust
    pub max_request_retry: u64,

```

**File:** config/src/config/state_sync_config.rs (L277-277)
```rust
            max_request_retry: 5,
```

**File:** config/src/config/state_sync_config.rs (L473-481)
```rust
            max_response_timeout_ms: 60_000, // 60 seconds
            max_state_chunk_size: MAX_STATE_CHUNK_SIZE,
            max_subscription_lag_secs: 20, // 20 seconds
            max_transaction_chunk_size: MAX_TRANSACTION_CHUNK_SIZE,
            max_transaction_output_chunk_size: MAX_TRANSACTION_OUTPUT_CHUNK_SIZE,
            optimistic_fetch_timeout_ms: 5000,         // 5 seconds
            progress_check_max_stall_time_secs: 86400, // 24 hours (long enough to debug any issues at runtime)
            response_timeout_ms: 10_000,               // 10 seconds
            subscription_response_timeout_ms: 15_000, // 15 seconds (longer than a regular timeout because of prefetching)
```

**File:** state-sync/aptos-data-client/src/client.rs (L865-866)
```rust
                self.notify_bad_response(id, peer, &request, ErrorType::NotUseful);
                Err(client_error)
```

**File:** state-sync/aptos-data-client/src/client.rs (L879-879)
```rust
        self.peer_states.update_score_error(peer, error_type);
```
