# Audit Report

## Title
Critical Error Handling Flaw in Consensus Pipeline Allows State Divergence When Database Commit Fails

## Summary
The `notify_state_sync` function in the consensus pipeline contains a critical pattern matching flaw that fails to catch errors from `commit_ledger` when they are wrapped in `TaskError::PropagatedError`. This causes validators to notify state sync of committed transactions that were never persisted to storage, leading to consensus state divergence.

## Finding Description

The vulnerability exists in the error propagation chain between `commit_ledger` and `notify_state_sync` functions in the consensus pipeline.

**Error Propagation Chain:**

When `commit_ledger` executes the database write operation, any failure is converted through the following chain:

1. Database write fails in `AptosDB::commit_ledger` [1](#0-0) 

2. Error propagates to `BlockExecutorInner::commit_ledger` which returns `ExecutorResult<()>` [2](#0-1) 

3. In `PipelineBuilder::commit_ledger`, the error is converted to `anyhow::Error` [3](#0-2) 

4. The `From<Error> for TaskError` trait converts it to `TaskError::InternalError` [4](#0-3) 

5. However, `commit_ledger` is spawned via `spawn_shared_fut` [5](#0-4) 

6. The `spawn_shared_fut` function wraps `InternalError` into `PropagatedError` [6](#0-5) 

**The Critical Flaw:**

In `notify_state_sync`, the error check only matches direct `InternalError`, not `PropagatedError` [7](#0-6) 

The pattern `Err(e @ TaskError::InternalError(_))` only matches direct `InternalError`, not `PropagatedError(Box::new(InternalError(...)))`. When the pattern fails to match, execution falls through to line 1164 and proceeds to notify state sync of transactions that were never committed to storage [8](#0-7) 

**Invariant Violations:**
- **State Consistency**: Validators diverge on committed state - some have the block in storage, others don't
- **Consensus Safety**: Different validators believe different blocks are committed  
- **Storage Integrity**: In-memory state diverges from persistent storage state

**Attack Scenario:**
1. Validator V1 successfully executes and pre-commits block B
2. `commit_ledger` attempts database write but fails (disk full/I/O error)
3. Error conversion chain: `ExecutorError` → `anyhow::Error` → `TaskError::InternalError` → `TaskError::PropagatedError(InternalError(...))`
4. `notify_state_sync` pattern match fails to catch `PropagatedError`
5. Execution continues, state sync is notified block B is committed
6. Block B is NOT in V1's storage
7. V1 has divergent state from validators that successfully committed block B

## Impact Explanation

**Critical Severity** - Consensus/Safety Violation

This vulnerability breaks the fundamental consensus safety guarantee that all honest validators maintain consistent committed state. The impact qualifies as **Critical** under the Aptos bug bounty program because it enables:

**Consensus/Safety Violations:**
- Different validators have different ledger states for the same block height
- The failing validator cannot serve valid Merkle proofs for blocks it claims are committed
- State sync operates on incorrect information, potentially propagating bad state
- Violates the core consensus invariant that all honest validators agree on committed blocks

**State Inconsistencies:**
- In-memory consensus state diverges from persistent storage state
- The validator believes it has committed blocks that don't exist in storage
- Recovery mechanisms may fail due to inconsistent state assumptions

**Potential Network Partition:**
- The affected validator effectively detaches from consensus due to state divergence
- Subsequent block processing may fail when building on non-existent committed state
- Could require manual intervention or hardfork to recover

This falls under the explicit "Consensus/Safety Violations" category in the Aptos bug bounty: "Different validators commit different blocks" and "Chain splits without hardfork requirement."

## Likelihood Explanation

**High Likelihood** - Natural System Failures

This vulnerability can be triggered through common production failure scenarios:

**Natural Triggers:**
- **Disk exhaustion**: Validators processing high transaction volumes can fill disk space
- **I/O errors**: Hardware failures, disk corruption, bad sectors  
- **Database write failures**: Lock contention, corruption, filesystem issues
- **Permission errors**: Misconfigured filesystem permissions

**Frequency Assessment:**
- Production blockchain validators are long-running systems that inevitably encounter storage issues
- Disk space management is a common operational challenge in blockchain networks
- Hardware failures occur naturally in distributed validator infrastructure
- The bug is latent in every single block commit operation

**No Attacker Required:**
- This is a robustness bug, not an exploit
- Does not require any malicious actor to trigger
- Occurs naturally under system stress or hardware failure
- Cannot be prevented by validator operators through normal security practices

The likelihood is HIGH because:
1. The trigger condition (storage failure) is common in production
2. The bug affects every block commit operation
3. No special circumstances or timing is required
4. The error path is a normal code execution path when storage fails

## Recommendation

Fix the pattern matching in `notify_state_sync` to catch both `InternalError` and `PropagatedError`:

```rust
// Change line 1160 from:
if let Err(e @ TaskError::InternalError(_)) = commit_ledger_fut.await {
    return Err(TaskError::PropagatedError(Box::new(e)));
}

// To:
match commit_ledger_fut.await {
    Err(TaskError::InternalError(e)) => {
        return Err(TaskError::PropagatedError(Box::new(TaskError::InternalError(e))));
    }
    Err(TaskError::PropagatedError(inner)) => {
        // Check if the inner error is an InternalError
        if matches!(&*inner, TaskError::InternalError(_)) {
            return Err(TaskError::PropagatedError(inner));
        }
    }
    _ => {}
}
```

Alternatively, add a helper method to unwrap `PropagatedError` chains to check for `InternalError` at any depth.

## Proof of Concept

The vulnerability can be demonstrated by simulating a database failure during `commit_ledger`:

1. Set up a test validator with limited disk space
2. Process blocks until disk space exhausts during commit_ledger
3. Observe that `notify_state_sync` is called despite commit failure
4. Verify state sync records transactions that are not in persistent storage
5. Confirm validator state divergence from other validators

A Rust test would use fail points to inject commit failures and verify the erroneous state sync notification occurs.

## Notes

This is a **logic vulnerability** in error handling that breaks consensus safety guarantees. The bug is triggered by natural system failures, not malicious input, making it a high-likelihood critical issue in production environments. The pattern matching flaw represents a subtle but dangerous mismatch between the error propagation mechanism (`spawn_shared_fut` wrapping errors) and the error handling logic (`notify_state_sync` expecting unwrapped errors).

### Citations

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L107-107)
```rust
            self.ledger_db.metadata_db().write_schemas(ledger_batch)?;
```

**File:** execution/executor/src/block_executor/mod.rs (L388-390)
```rust
        self.db
            .writer
            .commit_ledger(target_version, Some(&ledger_info_with_sigs), None)?;
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L159-160)
```rust
            Ok(Err(e @ TaskError::InternalError(_) | e @ TaskError::JoinError(_))) => {
                Err(TaskError::PropagatedError(Box::new(e)))
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L547-556)
```rust
        let commit_ledger_fut = spawn_shared_fut(
            Self::commit_ledger(
                pre_commit_fut.clone(),
                commit_proof_fut,
                parent.commit_ledger_fut.clone(),
                self.executor.clone(),
                block.clone(),
            ),
            None,
        );
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L1098-1104)
```rust
        tokio::task::spawn_blocking(move || {
            executor
                .commit_ledger(ledger_info_with_sigs_clone)
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L1160-1162)
```rust
        if let Err(e @ TaskError::InternalError(_)) = commit_ledger_fut.await {
            return Err(TaskError::PropagatedError(Box::new(e)));
        }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L1164-1174)
```rust
        tracker.start_working();
        let txns = compute_result.transactions_to_commit().to_vec();
        let subscribable_events = compute_result.subscribable_events().to_vec();
        if let Err(e) = monitor!(
            "notify_state_sync",
            state_sync_notifier
                .notify_new_commit(txns, subscribable_events)
                .await
        ) {
            error!(error = ?e, "Failed to notify state synchronizer");
        }
```

**File:** consensus/consensus-types/src/pipelined_block.rs (L63-66)
```rust
impl From<Error> for TaskError {
    fn from(value: Error) -> Self {
        Self::InternalError(Arc::new(value))
    }
```
