# Audit Report

## Title
Cache Coherency Vulnerability: Layout Cache Missing Module Version Validation in Parallel Block Execution

## Summary
A critical race condition exists in the global layout cache system where Move type layouts cached from old module versions can be incorrectly used with new module versions during parallel transaction execution. This breaks deterministic execution guarantees and can cause consensus failures across validators.

## Finding Description

The vulnerability arises from three architectural components interacting incorrectly during parallel transaction execution:

**1. Global Layout Cache Without Version Information**

The system uses a global `DashMap<StructKey, LayoutCacheEntry>` to cache struct layouts across transactions. [1](#0-0) 

The cache key `StructKey` contains only a struct name index and type arguments, with no module version or bytecode hash: [2](#0-1) 

The `StructNameIndex` is merely a `u32` interned identifier that maps to module address and name without any version information: [3](#0-2) 

**2. Transaction-Level Module Caching**

During execution, transactions cache module reads in `CapturedReads` to maintain consistency within a single execution. The `get_module_or_build_with` method checks `CapturedReads` first before checking global or per-block caches: [4](#0-3) 

**3. Incomplete Layout Cache Validation**

When layouts are retrieved from cache, the `load_layout_from_cache` function re-reads modules only for gas charging, not for version validation: [5](#0-4) 

The `DefiningModules` structure tracks which modules were used to construct a layout but stores only `ModuleId` (address + name) without versions: [6](#0-5) 

**The Attack Sequence:**

1. Transaction T₂ begins parallel execution and reads module M version 1, storing it in `CapturedReads`
2. T₂ computes and globally caches a layout L₁ for struct S from M v1
3. Transaction T₁₀ commits and publishes M version 2 with modified struct layout
4. The `publish_module_write_set` function flushes the layout cache and marks M as overridden: [7](#0-6) 

5. T₂ is still executing (hasn't been validated yet) and needs another layout from M
6. T₂'s `get_module_or_build_with` checks `CapturedReads` first (line 151), retrieves M v1, computes a new layout, and caches it globally
7. Transaction T₁₁ starts execution and finds the cached layout
8. T₁₁'s `load_layout_from_cache` re-reads M (now gets v2) to charge gas, but uses the cached layout computed from M v1
9. T₁₁ uses layout L₁ (from M v1) while operating on values from M v2

**Why Existing Protections Fail:**

The module validation system checks module version consistency but not layout cache coherency: [8](#0-7) 

This validation only ensures that module reads are consistent (GlobalCache not overridden, PerBlockCache versions match), but does NOT validate that cached layouts correspond to the correct module versions. A transaction can pass validation with correct module reads while using an incorrect cached layout.

**Invariant Violation:**

This breaks deterministic execution guarantees. Different validators executing the same block in parallel may have different layouts cached due to timing variations in when transactions execute relative to module publications, leading to:
- Different serialization/deserialization results
- Different transaction execution outcomes
- Different state roots across validators
- Consensus safety violation

## Impact Explanation

This is a **Critical Severity** vulnerability under the Aptos Bug Bounty "Consensus/Safety Violations" category because:

1. **Consensus Breaking**: Different validators will compute different state roots for identical blocks, breaking Byzantine Fault Tolerant consensus guarantees. Validators with different cached layouts will produce different execution results for the same transactions.

2. **Non-Deterministic Execution**: The same transaction can produce different results depending on which layouts are cached, violating blockchain determinism requirements. This is timing-dependent and unpredictable.

3. **No Detection Mechanism**: Module validation validates module version consistency but not layout-module version coherency. Transactions using incorrect cached layouts will pass validation if they correctly recorded their module reads.

4. **Network-Wide Impact**: All validators running parallel execution (default configuration with `concurrency_level > 1`) are affected. The layout cache is enabled by default with a size of 4 million entries. [9](#0-8) 

5. **Silent Failure**: No warnings or errors are generated when stale layouts are used, making detection extremely difficult without forensic state root analysis.

## Likelihood Explanation

**High Likelihood** due to:

1. **Common Trigger**: Module upgrades are a standard Aptos feature used frequently in production. Any module upgrade during parallel execution can trigger this race condition.

2. **Natural Occurrence**: The race condition requires no attacker coordination - it occurs naturally during normal parallel execution when modules are upgraded. The timing window exists from when a module is published until all in-flight transactions are validated.

3. **Default Configuration**: Layout caching is enabled by default with a large cache size. Parallel execution is standard for validators to achieve high throughput.

4. **No Attacker Required**: This is not an attack scenario but a fundamental architectural issue that manifests during legitimate operations.

5. **Silent Failure**: Detection is extremely difficult, as the system provides no indication that stale layouts are being used. Consensus divergence would only be noticed when validators fail to reach agreement on state roots.

## Recommendation

Implement version tracking in the layout cache system:

1. **Extend StructKey**: Include module version information (transaction index or bytecode hash) in the cache key structure.

2. **Validate on Cache Hit**: In `load_layout_from_cache`, after re-reading modules, verify that the cached layout's defining module versions match the currently read module versions. If they don't match, treat it as a cache miss and recompute the layout.

3. **Atomic Cache Updates**: Ensure that layout cache updates are atomic with respect to module publishing. Consider using a versioned cache where each module publication increments a global version counter, and layouts are tagged with the version they were computed from.

4. **Enhanced DefiningModules**: Extend `DefiningModules` to store module versions (transaction indices or hashes) alongside `ModuleId`, enabling validation that cached layouts match current module versions.

## Proof of Concept

A complete PoC would require setting up parallel block execution with module publishing, but the vulnerability can be demonstrated conceptually:

```rust
// Transaction T2 executing in parallel:
// 1. Reads module M v1 -> cached in CapturedReads
// 2. Computes layout L1 from M v1 -> stored in global cache with key (M.name, type_args)

// Transaction T10 commits:
// 3. Publishes M v2 -> flushes layout cache, marks M as overridden

// Transaction T2 still executing:
// 4. Needs another layout from M
// 5. Reads M -> CapturedReads returns M v1 (line 151 check)
// 6. Computes layout L1' from M v1 -> stores in global cache

// Transaction T11 starts:
// 7. Finds cached layout L1' in global cache
// 8. load_layout_from_cache:
//    - charge_module reads M v2 for gas
//    - Returns layout L1' (from M v1)
// 9. Uses layout from M v1 with data from M v2 -> MISMATCH

// Validation:
// T2 fails validation (module overridden)
// T11 PASSES validation (correctly read M v2, but layout is wrong)
```

The key issue is that `validate_module_reads` only checks module version consistency, not layout-module version coherency.

## Notes

This vulnerability affects all validators running parallel execution, regardless of the `blockstm_v2` flag setting. The issue exists in the fundamental architecture of how layout caching interacts with module versioning during parallel transaction execution. The TODO comment in the code acknowledges that layout cache flushing is needed for enums, but doesn't address the broader race condition issue with module versioning: [10](#0-9)

### Citations

**File:** aptos-move/block-executor/src/code_cache_global.rs (L96-96)
```rust
    struct_layouts: DashMap<StructKey, LayoutCacheEntry>,
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L162-168)
```rust
    /// Flushes only layout caches.
    pub fn flush_layout_cache(&self) {
        // TODO(layouts):
        //   Flushing is only needed because of enums. Once we refactor layouts to store a single
        //   variant instead, this can be removed.
        self.struct_layouts.clear();
    }
```

**File:** third_party/move/move-vm/runtime/src/storage/layout_cache.rs (L29-57)
```rust
#[derive(Debug, Default)]
pub struct DefiningModules {
    modules: HashSet<ModuleId>,
    seen_modules: Vec<ModuleId>,
}

impl DefiningModules {
    /// Returns a new empty set of modules.
    pub fn new() -> Self {
        Self {
            modules: HashSet::new(),
            seen_modules: vec![],
        }
    }

    /// If module is not in the set, adds it.
    pub fn insert(&mut self, module_id: &ModuleId) {
        if !self.modules.contains(module_id) {
            self.modules.insert(module_id.clone());
            // Preserve the visited order: later traversal over the module set is deterministic.
            self.seen_modules.push(module_id.clone())
        }
    }

    /// Returns an iterator over modules in their insertion order.
    pub fn iter(&self) -> impl Iterator<Item = &ModuleId> {
        self.seen_modules.iter()
    }
}
```

**File:** third_party/move/move-vm/runtime/src/storage/layout_cache.rs (L79-83)
```rust
#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]
pub struct StructKey {
    pub idx: StructNameIndex,
    pub ty_args_id: TypeVecId,
}
```

**File:** third_party/move/move-vm/types/src/loaded_data/struct_name_indexing.rs (L20-23)
```rust
/// Represents a unique identifier for the struct name. Note that this index has no public
/// constructor - the only way to construct it is via [StructNameIndexMap].
#[derive(Debug, Copy, Clone, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct StructNameIndex(u32);
```

**File:** aptos-move/block-executor/src/code_cache.rs (L148-174)
```rust
        match &self.latest_view {
            ViewState::Sync(state) => {
                // Check the transaction-level cache with already read modules first.
                if let CacheRead::Hit(read) = state.captured_reads.borrow().get_module_read(key) {
                    return Ok(read);
                }

                // Otherwise, it is a miss. Check global cache.
                if let Some(module) = self.global_module_cache.get(key) {
                    state
                        .captured_reads
                        .borrow_mut()
                        .capture_global_cache_read(key.clone(), module.clone());
                    return Ok(Some((module, Self::Version::default())));
                }

                // If not global cache, check per-block cache.
                let _timer = GLOBAL_MODULE_CACHE_MISS_SECONDS.start_timer();
                let read = state
                    .versioned_map
                    .module_cache()
                    .get_module_or_build_with(key, builder)?;
                state
                    .captured_reads
                    .borrow_mut()
                    .capture_per_block_cache_read(key.clone(), read.clone());
                Ok(read)
```

**File:** third_party/move/move-vm/runtime/src/storage/loader/lazy.rs (L203-221)
```rust
    fn load_layout_from_cache(
        &self,
        gas_meter: &mut impl DependencyGasMeter,
        traversal_context: &mut TraversalContext,
        key: &StructKey,
    ) -> Option<PartialVMResult<LayoutWithDelayedFields>> {
        let entry = self.module_storage.get_struct_layout(key)?;
        let (layout, modules) = entry.unpack();
        for module_id in modules.iter() {
            // Re-read all modules for this layout, so that transaction gets invalidated
            // on module publish. Also, we re-read them in exactly the same way as they
            // were traversed during layout construction, so gas charging should be exactly
            // the same as on the cache miss.
            if let Err(err) = self.charge_module(gas_meter, traversal_context, module_id) {
                return Some(Err(err));
            }
        }
        Some(Ok(layout))
    }
```

**File:** aptos-move/block-executor/src/txn_last_input_output.rs (L539-578)
```rust
    pub(crate) fn publish_module_write_set(
        &self,
        txn_idx: TxnIndex,
        global_module_cache: &GlobalModuleCache<
            ModuleId,
            CompiledModule,
            Module,
            AptosModuleExtension,
        >,
        versioned_cache: &MVHashMap<T::Key, T::Tag, T::Value, DelayedFieldID>,
        runtime_environment: &RuntimeEnvironment,
        scheduler: &SchedulerWrapper<'_>,
    ) -> Result<bool, PanicError> {
        let output_wrapper = self.output_wrappers[txn_idx as usize].lock();
        let output_before_guard = output_wrapper
            .check_success_or_skip_status()?
            .before_materialization()?;

        let mut published = false;
        let mut module_ids_for_v2 = BTreeSet::new();
        for write in output_before_guard.module_write_set().values() {
            published = true;
            if scheduler.is_v2() {
                module_ids_for_v2.insert(write.module_id().clone());
            }
            add_module_write_to_module_cache::<T>(
                write,
                txn_idx,
                runtime_environment,
                global_module_cache,
                versioned_cache.module_cache(),
            )?;
        }
        if published {
            // Record validation requirements after the modules are published.
            global_module_cache.flush_layout_cache();
            scheduler.record_validation_requirements(txn_idx, module_ids_for_v2)?;
        }
        Ok(published)
    }
```

**File:** aptos-move/block-executor/src/captured_reads.rs (L1042-1089)
```rust
    /// For every module read that was captured, checks if the reads are still the same:
    ///   1. Entries read from the global module cache are not overridden.
    ///   2. Entries that were not in per-block cache before are still not there.
    ///   3. Entries that were in per-block cache have the same commit index.
    ///
    /// maybe_updated_module_keys set to None in BlockSTMv1, in which case all module reads
    /// are validated. BlockSTMv2 provides a set of module keys that were updated, and
    /// validation simply checks for an intersection with the captured module reads.
    pub(crate) fn validate_module_reads(
        &self,
        global_module_cache: &GlobalModuleCache<K, DC, VC, S>,
        per_block_module_cache: &SyncModuleCache<K, DC, VC, S, Option<TxnIndex>>,
        maybe_updated_module_keys: Option<&BTreeSet<K>>,
    ) -> bool {
        if self.non_delayed_field_speculative_failure {
            return false;
        }

        let validate = |key: &K, read: &ModuleRead<DC, VC, S>| match read {
            ModuleRead::GlobalCache(_) => global_module_cache.contains_not_overridden(key),
            ModuleRead::PerBlockCache(previous) => {
                let current_version = per_block_module_cache.get_module_version(key);
                let previous_version = previous.as_ref().map(|(_, version)| *version);
                current_version == previous_version
            },
        };

        match maybe_updated_module_keys {
            Some(updated_module_keys) if updated_module_keys.len() <= self.module_reads.len() => {
                // When updated_module_keys is smaller, iterate over it and lookup in module_reads
                updated_module_keys
                    .iter()
                    .filter(|&k| self.module_reads.contains_key(k))
                    .all(|key| validate(key, self.module_reads.get(key).unwrap()))
            },
            Some(updated_module_keys) => {
                // When module_reads is smaller, iterate over it and filter by updated_module_keys
                self.module_reads
                    .iter()
                    .filter(|(k, _)| updated_module_keys.contains(k))
                    .all(|(key, read)| validate(key, read))
            },
            None => self
                .module_reads
                .iter()
                .all(|(key, read)| validate(key, read)),
        }
    }
```

**File:** types/src/block_executor/config.rs (L43-44)
```rust
            // Maximum number of cached layouts.
            max_layout_cache_size: 4_000_000,
```
