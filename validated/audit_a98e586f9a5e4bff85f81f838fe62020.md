# Audit Report

## Title
Critical Race Condition in Global Struct Layout Cache Enables Consensus Safety Violation via Stale Layout Poisoning

## Summary
A race condition exists between module publishing and struct layout caching in BlockSTM parallel execution that allows aborted transactions to poison the global layout cache with stale layouts. When different validators experience different race timing, they compute different state roots for identical blocks, causing a consensus safety violation requiring a hardfork to resolve.

## Finding Description

The vulnerability exists in the interaction between three critical components in the Aptos block executor:

**1. StructKey Lacks Module Version Tracking**

The global layout cache uses `StructKey` as the cache key, which only contains struct name index and type arguments, with no module version information: [1](#0-0) 

This means layouts computed from different module versions share the same cache key, preventing proper invalidation when modules are upgraded.

**2. Vacant-Entry Pattern Prevents Cache Entry Overwriting**

The global cache implementation uses a vacant-entry pattern that prevents overwriting existing entries: [2](#0-1) 

Once a stale layout is cached, subsequent attempts to store the correct layout for the same StructKey will be silently ignored.

**3. Layout Cache Flush Occurs During Commit After Module Publishing**

When modules are published, the layout cache is flushed during the commit phase: [3](#0-2) 

This flush happens during the sequential commit process in `prepare_and_queue_commit_ready_txn`: [4](#0-3) 

**Attack Scenario**

In BlockSTM's parallel execution model, transactions execute out-of-order but commit in-order. The race condition occurs as follows:

1. Transaction T3 (index 15) starts executing with module M version V1
2. During execution, T3 computes struct layout L1 based on V1's definition
3. Transaction T2 (index 10) commits and publishes module M version V2
4. T2's commit calls `flush_layout_cache()` clearing the global cache
5. **Critical Race Window**: T3 stores layout L1 to the now-empty cache AFTER the flush
6. T3's module validation detects stale module reads and aborts T3
7. T3 re-executes as incarnation 1, now with module V2 available
8. T3 checks cache for layout → **CACHE HIT** finds stale L1 (computed from V1)
9. T3 uses cached layout L1 with module V2 → incorrect struct interpretation

Layout storage happens during execution at: [5](#0-4) 

**Why This Causes Consensus Splits**

The race timing depends on CPU execution speed, thread scheduling, cache performance, and number of worker threads. Different validators will experience different race outcomes:

- **Fast Validator**: T3's stale write occurs BEFORE T2's flush → cache cleaned by flush → T3 re-execution computes and caches correct layout L2
- **Slow Validator**: T3's stale write occurs AFTER T2's flush → cache poisoned with L1 → T3 re-execution uses stale cached L1

Both validators execute identical transactions in identical order, but produce different state roots due to different cached layouts being used for value serialization/deserialization. Wrong layouts cause incorrect field offsets, wrong memory access patterns, and different serialized output → different state roots → consensus split.

The module read validation mechanism [6](#0-5)  correctly detects and aborts transactions with stale module reads, but this occurs AFTER the layout has already been stored in the global cache. There is no mechanism to roll back layout cache entries written by aborted incarnations, and no version tracking to prevent re-execution from using stale cached layouts.

## Impact Explanation

**CRITICAL SEVERITY** - This vulnerability qualifies for the highest severity category per the Aptos bug bounty program:

**1. Consensus Safety Violation**: Different validators produce different state roots for identical blocks, violating the fundamental consensus invariant that all honest validators must agree on state transitions. This directly maps to the "Consensus/Safety violations" category in the bug bounty.

**2. Non-Recoverable Network Partition**: Once validators diverge on cached layouts, all subsequent blocks using those struct types will compute different state roots. The network permanently forks into incompatible chains requiring a hardfork to resolve, as the poisoned cache persists across blocks. This directly maps to "Non-recoverable network partition (requires hardfork)" in the bug bounty.

**3. Memory Corruption**: Using struct layouts with incorrect field counts, types, or sizes causes the Move VM to read/write memory at wrong offsets during value serialization/deserialization, potentially causing crashes, data corruption, or undefined behavior.

**4. Deterministic Execution Violation**: Breaks Aptos's core invariant that block execution must be deterministic - the same input block must always produce the same output state on all validators.

## Likelihood Explanation

**MEDIUM-HIGH Likelihood**

**Enabling Factors:**
- Module publishing occurs regularly on Aptos mainnet (framework upgrades, governance proposals, user module deployments)
- BlockSTM parallel execution creates natural race condition windows during every module publish
- No special permissions required - any account can publish modules and trigger the race
- Race window exists for every transaction executing concurrently with module publishing commits
- Framework module upgrades (most critical) access shared structs heavily, maximizing exposure

**Realistic Trigger:**
1. During a framework upgrade or module deployment, multiple transactions execute in parallel
2. Some transactions are mid-execution using the old module version when the new version commits
3. Module publish commits and flushes layout cache
4. Concurrent transactions complete their layout computations and store to the now-empty cache
5. Different validators experience different timing based on hardware differences → consensus split

**Mitigating Factors:**
- Requires precise timing alignment between execution and commit phases
- Race window is small (microseconds to milliseconds)
- More likely under heavy load when parallel execution is most active

Even without malicious intent, this can occur naturally during framework upgrades with normal transaction volume, as validator hardware differences and load variations create non-deterministic race outcomes.

## Recommendation

**Immediate Fix**: Add module version tracking to `StructKey` by including the transaction index or module hash that was used to compute each layout. Modify the cache key to:

```rust
pub struct StructKey {
    pub idx: StructNameIndex,
    pub ty_args_id: TypeVecId,
    pub module_version: Option<TxnIndex>, // Track which module version was used
}
```

**Alternative Approaches**:
1. Clear layout cache entries per-transaction when a transaction aborts due to module validation failures
2. Implement versioned layout caching where each module version has its own layout cache namespace
3. Perform layout computation and caching only after successful commit (no speculative caching)
4. Add validation during cache retrieval that re-checks if the modules used to compute the layout are still current

The TODO comment at [7](#0-6)  suggests future refactoring, but this does not address the race condition vulnerability.

## Proof of Concept

A complete PoC would require:
1. Deploy module M v1 with struct Foo
2. Submit transaction T3 that uses Foo while T3 starts executing
3. Concurrently publish module M v2 with modified Foo layout in transaction T2
4. Ensure T3's layout computation happens after T2's cache flush
5. Observe T3's re-execution using stale cached layout
6. Verify different validators compute different state roots based on race timing

Due to the non-deterministic nature of the race condition, a reliable PoC requires instrumentation to control thread scheduling and precise timing, which is beyond the scope of a standard test. However, the vulnerability is evident from the code structure and lack of version tracking in the layout cache system.

## Notes

The existing test at [8](#0-7)  verifies that aborted transactions don't leak speculative type layouts, but it executes transactions sequentially within a single block and does not test for concurrent race conditions during parallel execution.

### Citations

**File:** third_party/move/move-vm/runtime/src/storage/layout_cache.rs (L79-83)
```rust
#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]
pub struct StructKey {
    pub idx: StructNameIndex,
    pub ty_args_id: TypeVecId,
}
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L164-167)
```rust
        // TODO(layouts):
        //   Flushing is only needed because of enums. Once we refactor layouts to store a single
        //   variant instead, this can be removed.
        self.struct_layouts.clear();
```

**File:** aptos-move/block-executor/src/code_cache_global.rs (L181-190)
```rust
    pub(crate) fn store_struct_layout_entry(
        &self,
        key: &StructKey,
        entry: LayoutCacheEntry,
    ) -> PartialVMResult<()> {
        if let dashmap::Entry::Vacant(e) = self.struct_layouts.entry(*key) {
            e.insert(entry);
        }
        Ok(())
    }
```

**File:** aptos-move/block-executor/src/txn_last_input_output.rs (L572-576)
```rust
        if published {
            // Record validation requirements after the modules are published.
            global_module_cache.flush_layout_cache();
            scheduler.record_validation_requirements(txn_idx, module_ids_for_v2)?;
        }
```

**File:** aptos-move/block-executor/src/executor.rs (L1043-1053)
```rust
        // Publish modules before we decrease validation index (in V1) so that validations observe
        // the new module writes as well.
        if last_input_output.publish_module_write_set(
            txn_idx,
            global_module_cache,
            versioned_cache,
            runtime_environment,
            &scheduler,
        )? {
            side_effect_at_commit = true;
        }
```

**File:** third_party/move/move-vm/runtime/src/storage/ty_layout_converter.rs (L126-129)
```rust
                let cache_entry = LayoutCacheEntry::new(layout.clone(), modules);
                self.struct_definition_loader
                    .store_layout_to_cache(&key, cache_entry)?;
                return Ok(layout);
```

**File:** aptos-move/block-executor/src/captured_reads.rs (L1050-1089)
```rust
    pub(crate) fn validate_module_reads(
        &self,
        global_module_cache: &GlobalModuleCache<K, DC, VC, S>,
        per_block_module_cache: &SyncModuleCache<K, DC, VC, S, Option<TxnIndex>>,
        maybe_updated_module_keys: Option<&BTreeSet<K>>,
    ) -> bool {
        if self.non_delayed_field_speculative_failure {
            return false;
        }

        let validate = |key: &K, read: &ModuleRead<DC, VC, S>| match read {
            ModuleRead::GlobalCache(_) => global_module_cache.contains_not_overridden(key),
            ModuleRead::PerBlockCache(previous) => {
                let current_version = per_block_module_cache.get_module_version(key);
                let previous_version = previous.as_ref().map(|(_, version)| *version);
                current_version == previous_version
            },
        };

        match maybe_updated_module_keys {
            Some(updated_module_keys) if updated_module_keys.len() <= self.module_reads.len() => {
                // When updated_module_keys is smaller, iterate over it and lookup in module_reads
                updated_module_keys
                    .iter()
                    .filter(|&k| self.module_reads.contains_key(k))
                    .all(|key| validate(key, self.module_reads.get(key).unwrap()))
            },
            Some(updated_module_keys) => {
                // When module_reads is smaller, iterate over it and filter by updated_module_keys
                self.module_reads
                    .iter()
                    .filter(|(k, _)| updated_module_keys.contains(k))
                    .all(|(key, read)| validate(key, read))
            },
            None => self
                .module_reads
                .iter()
                .all(|(key, read)| validate(key, read)),
        }
    }
```

**File:** aptos-move/e2e-move-tests/src/tests/code_publishing.rs (L524-581)
```rust
fn test_module_publishing_does_not_leak_speculative_information() {
    let mut executor = FakeExecutor::from_head_genesis().set_parallel();
    executor.disable_block_executor_fallback();

    let mut h = MoveHarness::new_with_executor(executor);
    let addr = AccountAddress::random();
    let account = h.new_account_at(addr);

    let tys_with_abort_codes = [
        ("u8", Some(1)),
        ("u16", Some(2)),
        ("u32", Some(3)),
        ("u128", Some(4)),
        ("u256", Some(5)),
        ("u64", None),
    ];

    let mut txns = vec![];
    let mut expected_abort_codes: Vec<Option<u64>> = vec![];

    for (ty, maybe_abort_code) in tys_with_abort_codes {
        expected_abort_codes.push(maybe_abort_code);

        // Create module to be published that uses the same type name but different layout. For
        // the first few modules, run 'init_module' to ensure the type is used and then abort the
        // transaction. This ensures that the struct name re-indexing cache and publishing works as
        // expected - not caching type layouts for the struct until it is actually committed.
        let struct_def = format!("struct Foo has key, store {{ data: {}, }}", ty);
        let init_module = if let Some(abort_code) = maybe_abort_code {
            format!("fun init_module(sender: &signer) {{ move_to(sender, Foo {{ data: 0 }}); abort {} }}", abort_code)
        } else {
            "fun init_module(sender: &signer) { move_to(sender, Foo { data: 77 }) }".to_string()
        };
        let source = format!("module {}::foo {{ {} {} }}", addr, struct_def, init_module);

        let txn = h.create_transaction_payload(&account, publish_module_txn(source, "foo"));
        txns.push(txn);
    }

    for (output, maybe_abort_code) in h
        .run_block_get_output(txns)
        .into_iter()
        .zip(expected_abort_codes.into_iter())
    {
        let status = output.status().clone();
        match maybe_abort_code {
            Some(abort_code) => {
                assert_move_abort(status, abort_code);
            },
            None => {
                assert_success!(status);
                let struct_tag = parse_struct_tag(&format!("{}::foo::Foo", addr)).unwrap();
                let data = h.read_resource::<Foo>(&addr, struct_tag).unwrap().data;
                assert_eq!(data, 77);
            },
        }
    }
}
```
