# Audit Report

## Title
Unbounded Batch Size in State KV Shard Pruner Recovery Causes Node Unrecoverability After Crash

## Summary
The state KV pruner's crash recovery mechanism in sharded mode attempts to catch up arbitrarily large version gaps in a single atomic transaction without batching, potentially causing memory exhaustion, extremely long startup times, or infinite crash loops that render a node unrecoverable.

## Finding Description

The state KV pruner in sharded mode uses a two-phase pruning approach that creates a critical vulnerability during crash recovery.

**Normal Operation Flow:**

During normal pruning, the system processes in configurable batches with a default of 5,000 versions. [1](#0-0) 

The batching loop in normal operation limits processing to max_versions per iteration. [2](#0-1) 

**The Critical Flaw:**

In sharded mode, the metadata pruner only iterates through entries to verify them but does NOT delete any data. [3](#0-2) 

It only commits the global progress marker. [4](#0-3) 

The actual deletions are performed by shard pruners in parallel. If a crash occurs after the metadata progress is committed but before all shards complete, the global progress becomes ahead of individual shard progress.

**Recovery Mechanism Vulnerability:**

During recovery, each shard attempts to catch up by calling prune() with the entire version gap. [5](#0-4) 

The critical vulnerability is that StateKvShardPruner::prune() operates on the ENTIRE gap without any internal batching. It iterates through all stale entries and adds ALL deletions to a single SchemaBatch before committing atomically. [6](#0-5) 

**Contrast with StateMerkleShardPruner:**

The state merkle shard pruner has internal batching protection via a loop that processes chunks. [7](#0-6) 

StateKvShardPruner lacks this protection.

**No Size Limits on SchemaBatch:**

SchemaBatch is simply a HashMap that grows unbounded with no size limits. [8](#0-7) 

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty criteria:

1. **Validator Node Slowdowns/Crashes**: Attempting to build a batch with hundreds of thousands of delete operations can exhaust memory (OOM), causing immediate crash, block node startup for extended periods, or create infinite crash loops if recovery repeatedly fails.

2. **Node Unrecoverability**: If the version gap is sufficiently large (e.g., millions of versions from extended downtime), the node may become permanently unable to restart without manual intervention (disabling pruning, manual database repair, or full resync).

3. **Network Availability Impact**: If multiple validators experience simultaneous crashes during active pruning, the network could experience reduced validator participation, affecting liveness.

This meets the HIGH severity category for "Validator Node Slowdowns" with potential escalation to node unrecoverability.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability has high likelihood because:

1. **Natural Trigger**: Requires only a crash during normal pruning operationsâ€”no malicious actor needed. Validator nodes can crash due to hardware failures, OOM from other operations, software bugs, or network partitions.

2. **Active Pruning is Default**: Production nodes enable pruning by default to manage disk space. [9](#0-8) 

3. **Growing Gap Probability**: The longer a node remains down after a crash during pruning, the larger the version gap becomes. For high-throughput chains, gaps can reach millions of versions.

4. **Cascading Failures**: If the first recovery attempt causes OOM and crashes again, the node enters an infinite loop where each restart attempt fails.

## Recommendation

Implement internal batching within `StateKvShardPruner::prune()` similar to `StateMerkleShardPruner::prune()`. The fix should:

1. Add a `max_entries_to_prune` parameter to limit batch size during recovery
2. Use a loop that processes entries in chunks
3. Commit each chunk before continuing
4. Only update progress metadata when fully caught up

This ensures recovery operations respect the same memory bounds as normal pruning operations.

## Proof of Concept

The vulnerability can be demonstrated by:

1. Starting a validator node with sharded state KV pruning enabled
2. Allow pruning to progress to version N (e.g., 1,000,000)
3. Crash the node during pruning after metadata progress is committed but before shard completion
4. The shard pruner will be at version N-X where X is the uncommitted gap
5. On restart, `StateKvShardPruner::new()` will call `prune(N-X, N)` attempting to process X versions in a single batch
6. If X is sufficiently large (e.g., 100,000+ versions with multiple state values per version), the SchemaBatch HashMap will grow to consume gigabytes of memory, causing OOM

**Notes**

The architectural difference between StateKvShardPruner and StateMerkleShardPruner is clear: the merkle shard pruner correctly implements batching protection for recovery scenarios, while the KV shard pruner does not. This creates an asymmetric vulnerability where only the KV pruner is susceptible to unbounded memory growth during recovery.

### Citations

**File:** config/src/config/storage_config.rs (L390-390)
```rust
            enable: true,
```

**File:** config/src/config/storage_config.rs (L392-392)
```rust
            batch_size: 5_000,
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L55-57)
```rust
        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L35-50)
```rust
        if self.state_kv_db.enabled_sharding() {
            let num_shards = self.state_kv_db.num_shards();
            // NOTE: This can be done in parallel if it becomes the bottleneck.
            for shard_id in 0..num_shards {
                let mut iter = self
                    .state_kv_db
                    .db_shard(shard_id)
                    .iter::<StaleStateValueIndexByKeyHashSchema>()?;
                iter.seek(&current_progress)?;
                for item in iter {
                    let (index, _) = item?;
                    if index.stale_since_version > target_version {
                        break;
                    }
                }
            }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L67-72)
```rust
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;

        self.state_kv_db.metadata_db().write_schemas(batch)
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L42-42)
```rust
        myself.prune(progress, metadata_progress)?;
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L47-72)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
    ) -> Result<()> {
        let mut batch = SchemaBatch::new();

        let mut iter = self
            .db_shard
            .iter::<StaleStateValueIndexByKeyHashSchema>()?;
        iter.seek(&current_progress)?;
        for item in iter {
            let (index, _) = item?;
            if index.stale_since_version > target_version {
                break;
            }
            batch.delete::<StaleStateValueIndexByKeyHashSchema>(&index)?;
            batch.delete::<StateValueByKeyHashSchema>(&(index.state_key_hash, index.version))?;
        }
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvShardPrunerProgress(self.shard_id),
            &DbMetadataValue::Version(target_version),
        )?;

        self.db_shard.write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L64-97)
```rust
        loop {
            let mut batch = SchemaBatch::new();
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;

            indices.into_iter().try_for_each(|index| {
                batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
                batch.delete::<S>(&index)
            })?;

            let mut done = true;
            if let Some(next_version) = next_version {
                if next_version <= target_version {
                    done = false;
                }
            }

            if done {
                batch.put::<DbMetadataSchema>(
                    &S::progress_metadata_key(Some(self.shard_id)),
                    &DbMetadataValue::Version(target_version),
                )?;
            }

            self.db_shard.write_schemas(batch)?;

            if done {
                break;
            }
        }
```

**File:** storage/schemadb/src/batch.rs (L130-133)
```rust
pub struct SchemaBatch {
    rows: DropHelper<HashMap<ColumnFamilyName, Vec<WriteOp>>>,
    stats: SampledBatchStats,
}
```
