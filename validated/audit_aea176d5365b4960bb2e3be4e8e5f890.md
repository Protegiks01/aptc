# Audit Report

## Title
Unbounded Empty Proof Accumulation in Batch Proof Queue Bypasses Resource Limits

## Summary
The `insert_proof()` function in `BatchProofQueue` accepts proofs with zero transactions without validation. When pulling proofs for block construction via `pull_internal()`, empty batches bypass all size limits since they contribute zero to transaction counts and byte sizes. This allows a malicious validator to flood the proof queue with empty batches, causing unbounded memory growth in the result vector and validator resource exhaustion.

## Finding Description

The vulnerability exists across the batch creation, validation, and proof pulling pipeline:

**1. No Validation Against Empty Batches:**

The `BatchInfo` constructor accepts `num_txns = 0` without any validation [1](#0-0) . The `ensure_max_limits()` function only validates upper bounds with `<=` comparisons, allowing `num_txns = 0` to pass all checks [2](#0-1) .

**2. Empty Proofs Bypass Insert Validation:**

When `insert_proof()` is called with a proof where `num_txns()` returns 0, the proof is accepted without any validation check for non-empty batches [3](#0-2) . The accounting increments the proof count but adds zero to transaction counts [4](#0-3) .

**3. Empty Batches Bypass Pull Limits:**

In `pull_internal()`, the critical limit checks compare accumulated sizes against maximums [5](#0-4) . For empty batches, `batch.size()` returns `PayloadTxnsSize::zero()` [6](#0-5) , which when added to `cur_all_txns` produces no change due to zero addition semantics [7](#0-6) . The unique transaction count calculation also returns the unchanged value for empty batches [8](#0-7) .

**4. Unbounded Loop Iteration:**

The `pull_internal()` loop continues processing until all iterators are exhausted [9](#0-8) . Since empty batches never trigger the `full` flag, they are continuously added to the result vector [10](#0-9)  without any bound, limited only by the number of empty batches in the queue. The result vector is initialized without capacity limits [11](#0-10) .

**Attack Execution Path:**

1. A malicious validator creates batches with empty transaction vectors using the `Batch::new` constructor
2. These batches pass `Batch::verify()` checks because the validation loop does not execute for empty transaction vectors [12](#0-11) 
3. Other validators receive these batches and automatically generate signed batch info via the `persist()` flow [13](#0-12) 
4. The `ProofCoordinator` aggregates signatures without validating batch content [14](#0-13) 
5. ProofOfStore objects are created and broadcast for empty batches
6. These proofs are inserted into other validators' `BatchProofQueue` via `insert_proof()`
7. When consensus requests proofs via `pull_proofs()`, empty batches fill the result vector without triggering size limits
8. Validators experience resource exhaustion and processing overhead

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty program category of "Validator Node Slowdowns":

- **Resource exhaustion**: The unbounded result vector causes memory consumption to grow linearly with the number of empty proofs in the queue
- **Processing overhead**: Validators waste CPU cycles iterating through and processing empty proofs on every block proposal
- **Consensus performance degradation**: Block construction is delayed as consensus must process an unbounded number of empty proof objects

The vulnerability breaks the resource limits invariant that all operations must respect computational and memory bounds. The size-based limits in `pull_internal()` are designed to prevent unbounded resource consumption, but empty batches completely bypass these protections.

While this does not cause complete network halt (which would be Critical severity), it significantly degrades validator performance and consensus efficiency, aligning with the High severity "Validator Node Slowdowns" category.

## Likelihood Explanation

**Likelihood: HIGH**

- **Attacker requirements**: Only requires one malicious validator, which is within the Byzantine fault tolerance assumption of up to 1/3 malicious validators
- **Complexity**: Low - the attacker simply creates `Batch` objects with empty transaction vectors and broadcasts them through normal consensus channels
- **Detection difficulty**: Empty batches appear structurally valid and collect legitimate quorum signatures, making them indistinguishable from delayed batches
- **Exploitation cost**: Minimal - no stake slashing or economic penalties for creating empty batches
- **Default configuration vulnerability**: The vulnerability exists in default settings with no configuration changes needed

Notably, the local batch generator intentionally avoids creating empty batches [15](#0-14) , but this protection does not extend to remote batches from malicious validators.

## Recommendation

Add validation to reject empty batches at multiple layers:

1. **In `ensure_max_limits()`**: Add a check that `batch.num_txns() > 0`
2. **In `insert_proof()`**: Add validation to reject proofs where `proof.num_txns() == 0`
3. **In `Batch::verify()`**: Add a check ensuring the transaction vector is non-empty
4. **In `pull_internal()`**: Add an early continue for batches with zero transactions

Example fix for `insert_proof()`:
```rust
pub(crate) fn insert_proof(&mut self, proof: ProofOfStore<BatchInfoExt>) {
    // Reject empty proofs
    if proof.num_txns() == 0 {
        counters::inc_rejected_pos_count(counters::POS_EMPTY_LABEL);
        return;
    }
    // ... rest of the function
}
```

## Proof of Concept

A malicious validator can exploit this by:

1. Creating empty batches using `Batch::new_v1(batch_id, vec![], epoch, expiration, author, 0)`
2. Broadcasting these to collect signatures from honest validators
3. Creating ProofOfStore with aggregated signatures
4. Broadcasting the proofs to flood other validators' proof queues
5. Observing unbounded memory growth and performance degradation when `pull_proofs()` is called

The attack succeeds because there are no checks preventing `num_txns = 0` at any validation layer in the batch creation, signature collection, or proof pulling pipeline.

## Notes

This vulnerability demonstrates a resource exhaustion attack that bypasses size-based protections through edge case handling. While individual empty batches are harmless, their accumulation creates an unbounded resource consumption vector. The fix requires defensive validation at multiple layers to ensure batches always contain at least one transaction.

### Citations

**File:** consensus/consensus-types/src/proof_of_store.rs (L60-81)
```rust
impl BatchInfo {
    pub fn new(
        author: PeerId,
        batch_id: BatchId,
        epoch: u64,
        expiration: u64,
        digest: HashValue,
        num_txns: u64,
        num_bytes: u64,
        gas_bucket_start: u64,
    ) -> Self {
        Self {
            author,
            batch_id,
            epoch,
            expiration,
            digest,
            num_txns,
            num_bytes,
            gas_bucket_start,
        }
    }
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L111-113)
```rust
    pub fn size(&self) -> PayloadTxnsSize {
        PayloadTxnsSize::new(self.num_txns, self.num_bytes)
    }
```

**File:** consensus/src/quorum_store/batch_coordinator.rs (L137-171)
```rust
    fn ensure_max_limits(&self, batches: &[Batch<BatchInfoExt>]) -> anyhow::Result<()> {
        let mut total_txns = 0;
        let mut total_bytes = 0;
        for batch in batches.iter() {
            ensure!(
                batch.num_txns() <= self.max_batch_txns,
                "Exceeds batch txn limit {} > {}",
                batch.num_txns(),
                self.max_batch_txns,
            );
            ensure!(
                batch.num_bytes() <= self.max_batch_bytes,
                "Exceeds batch bytes limit {} > {}",
                batch.num_bytes(),
                self.max_batch_bytes,
            );

            total_txns += batch.num_txns();
            total_bytes += batch.num_bytes();
        }
        ensure!(
            total_txns <= self.max_total_txns,
            "Exceeds total txn limit {} > {}",
            total_txns,
            self.max_total_txns,
        );
        ensure!(
            total_bytes <= self.max_total_bytes,
            "Exceeds total bytes limit: {} > {}",
            total_bytes,
            self.max_total_bytes,
        );

        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L101-108)
```rust
    fn inc_remaining_proofs(&mut self, author: &PeerId, num_txns: u64) {
        self.remaining_txns_with_duplicates += num_txns;
        self.remaining_proofs += 1;
        if *author == self.my_peer_id {
            self.remaining_local_txns += num_txns;
            self.remaining_local_proofs += 1;
        }
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L175-256)
```rust
    pub(crate) fn insert_proof(&mut self, proof: ProofOfStore<BatchInfoExt>) {
        if proof.expiration() <= self.latest_block_timestamp {
            counters::inc_rejected_pos_count(counters::POS_EXPIRED_LABEL);
            return;
        }
        let batch_key = BatchKey::from_info(proof.info());
        if self
            .items
            .get(&batch_key)
            .is_some_and(|item| item.proof.is_some() || item.is_committed())
        {
            counters::inc_rejected_pos_count(counters::POS_DUPLICATE_LABEL);
            return;
        }

        let author = proof.author();
        let bucket = proof.gas_bucket_start();
        let num_txns = proof.num_txns();
        let expiration = proof.expiration();

        let batch_sort_key = BatchSortKey::from_info(proof.info());
        let batches_for_author = self.author_to_batches.entry(author).or_default();
        batches_for_author.insert(batch_sort_key.clone(), proof.info().clone());

        // Check if a batch with a higher batch Id (reverse sorted) exists
        if let Some((prev_batch_key, _)) = batches_for_author
            .range((Bound::Unbounded, Bound::Excluded(batch_sort_key.clone())))
            .next_back()
        {
            if prev_batch_key.gas_bucket_start() == batch_sort_key.gas_bucket_start() {
                counters::PROOF_MANAGER_OUT_OF_ORDER_PROOF_INSERTION
                    .with_label_values(&[author.short_str().as_str()])
                    .inc();
            }
        }

        self.expirations.add_item(batch_sort_key, expiration);

        // If we are here, then proof is added for the first time. Otherwise, we will
        // return early. We only count when proof is added for the first time and txn
        // summary exists.
        if let Some(txn_summaries) = self
            .items
            .get(&batch_key)
            .and_then(|item| item.txn_summaries.as_ref())
        {
            for txn_summary in txn_summaries {
                *self
                    .txn_summary_num_occurrences
                    .entry(*txn_summary)
                    .or_insert(0) += 1;
            }
        }

        match self.items.entry(batch_key) {
            Entry::Occupied(mut entry) => {
                let item = entry.get_mut();
                item.proof = Some(proof);
                item.proof_insertion_time = Some(Instant::now());
            },
            Entry::Vacant(entry) => {
                entry.insert(QueueItem {
                    info: proof.info().clone(),
                    proof: Some(proof),
                    proof_insertion_time: Some(Instant::now()),
                    txn_summaries: None,
                });
            },
        }

        if author == self.my_peer_id {
            counters::inc_local_pos_count(bucket);
        } else {
            counters::inc_remote_pos_count(bucket);
        }
        self.inc_remaining_proofs(&author, num_txns);

        sample!(
            SampleRate::Duration(Duration::from_millis(500)),
            self.gc_expired_batch_summaries_without_proofs()
        );
    }
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L573-573)
```rust
        let mut result = Vec::new();
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L626-689)
```rust
        while !iters.is_empty() {
            iters.shuffle(&mut thread_rng());
            iters.retain_mut(|iter| {
                if full {
                    return false;
                }

                if let Some((batch, item)) = iter.next() {
                    if excluded_batches.contains(batch) {
                        excluded_txns += batch.num_txns();
                    } else {
                        // Calculate the number of unique transactions if this batch is included in the result
                        let unique_txns = if let Some(ref txn_summaries) = item.txn_summaries {
                            cur_unique_txns
                                + txn_summaries
                                    .iter()
                                    .filter(|txn_summary| {
                                        !filtered_txns.contains(txn_summary)
                                            && block_timestamp.as_secs()
                                                < txn_summary.expiration_timestamp_secs
                                    })
                                    .count() as u64
                        } else {
                            cur_unique_txns + batch.num_txns()
                        };
                        if cur_all_txns + batch.size() > max_txns
                            || unique_txns > max_txns_after_filtering
                        {
                            // Exceeded the limit for requested bytes or number of transactions.
                            full = true;
                            return false;
                        }
                        cur_all_txns += batch.size();
                        // Add this batch to filtered_txns and calculate the number of
                        // unique transactions added in the result so far.
                        cur_unique_txns +=
                            item.txn_summaries
                                .as_ref()
                                .map_or(batch.num_txns(), |summaries| {
                                    summaries
                                        .iter()
                                        .filter(|summary| {
                                            filtered_txns.insert(**summary)
                                                && block_timestamp.as_secs()
                                                    < summary.expiration_timestamp_secs
                                        })
                                        .count() as u64
                                });
                        assert!(item.proof.is_none() == batches_without_proofs);
                        result.push(item);
                        if cur_all_txns == max_txns
                            || cur_unique_txns == max_txns_after_filtering
                            || cur_unique_txns >= soft_max_txns_after_filtering
                        {
                            full = true;
                            return false;
                        }
                    }
                    true
                } else {
                    false
                }
            })
        }
```

**File:** consensus/consensus-types/src/utils.rs (L119-125)
```rust
impl std::ops::Add for PayloadTxnsSize {
    type Output = Self;

    fn add(self, rhs: Self) -> Self::Output {
        Self::new_normalized(self.count + rhs.count, self.bytes + rhs.bytes)
    }
}
```

**File:** consensus/src/quorum_store/types.rs (L262-290)
```rust
    pub fn verify(&self) -> anyhow::Result<()> {
        ensure!(
            self.payload.author() == self.author(),
            "Payload author doesn't match the info"
        );
        ensure!(
            self.payload.hash() == *self.digest(),
            "Payload hash doesn't match the digest"
        );
        ensure!(
            self.payload.num_txns() as u64 == self.num_txns(),
            "Payload num txns doesn't match batch info"
        );
        ensure!(
            self.payload.num_bytes() as u64 == self.num_bytes(),
            "Payload num bytes doesn't match batch info"
        );
        for txn in self.payload.txns() {
            ensure!(
                txn.gas_unit_price() >= self.gas_bucket_start(),
                "Payload gas unit price doesn't match batch info"
            );
            ensure!(
                !txn.payload().is_encrypted_variant(),
                "Encrypted transaction is not supported yet"
            );
        }
        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L488-528)
```rust
    fn persist_inner(
        &self,
        batch_info: BatchInfoExt,
        persist_request: PersistedValue<BatchInfoExt>,
    ) -> Option<SignedBatchInfo<BatchInfoExt>> {
        assert!(
            &batch_info == persist_request.batch_info(),
            "Provided batch info doesn't match persist request batch info"
        );
        match self.save(&persist_request) {
            Ok(needs_db) => {
                trace!("QS: sign digest {}", persist_request.digest());
                if needs_db {
                    if !batch_info.is_v2() {
                        let persist_request =
                            persist_request.try_into().expect("Must be a V1 batch");
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
                }
                if !batch_info.is_v2() {
                    self.generate_signed_batch_info(batch_info.info().clone())
                        .ok()
                        .map(|inner| inner.into())
                } else {
                    self.generate_signed_batch_info(batch_info).ok()
                }
            },
            Err(e) => {
                debug!("QS: failed to store to cache {:?}", e);
                None
            },
        }
    }
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L145-178)
```rust
    fn add_signature(
        &mut self,
        signed_batch_info: &SignedBatchInfo<BatchInfoExt>,
        validator_verifier: &ValidatorVerifier,
    ) -> Result<(), SignedBatchInfoError> {
        if signed_batch_info.batch_info() != &self.signature_aggregator.data() {
            return Err(SignedBatchInfoError::WrongInfo((
                signed_batch_info.batch_info().batch_id().id,
                self.signature_aggregator.data().batch_id().id,
            )));
        }

        match validator_verifier.get_voting_power(&signed_batch_info.signer()) {
            Some(voting_power) => {
                self.signature_aggregator.add_signature(
                    signed_batch_info.signer(),
                    signed_batch_info.signature_with_status(),
                );
                self.aggregated_voting_power += voting_power as u128;
                if signed_batch_info.signer() == self.signature_aggregator.data().author() {
                    self.self_voted = true;
                }
            },
            None => {
                error!(
                    "Received signature from author not in validator set: {}",
                    signed_batch_info.signer()
                );
                return Err(SignedBatchInfoError::InvalidAuthor);
            },
        }

        Ok(())
    }
```

**File:** consensus/src/quorum_store/batch_generator.rs (L364-372)
```rust
        if pulled_txns.is_empty() {
            counters::PULLED_EMPTY_TXNS_COUNT.inc();
            // Quorum store metrics
            counters::CREATED_EMPTY_BATCHES_COUNT.inc();

            counters::EMPTY_BATCH_CREATION_DURATION
                .observe_duration(self.last_end_batch_time.elapsed());
            self.last_end_batch_time = Instant::now();
            return vec![];
```
