# Audit Report

## Title
Transaction Limit Bypass via Incorrect Unique Transaction Accounting Across Multiple Batch Pulls

## Summary
The `ProofManager::handle_proposal_request` function fails to properly track unique transaction counts across multiple sequential batch pulls, allowing blocks to exceed the `max_txns_after_filtering` limit. This occurs because the unique transaction count from `pull_batches` is discarded, and `pull_batches_with_transactions` receives an unadjusted limit, enabling validators to construct blocks with more unique transactions than intended.

## Finding Description
The quorum store's proof manager pulls transactions in three sequential stages when constructing block proposals: `pull_proofs` (batches with proofs), `pull_batches` (optimistic batches), and `pull_batches_with_transactions` (inline batches).

The `max_txns_after_filtering` parameter is designed to limit the total number of unique transactions across all three pulls. However, a critical accounting flaw exists:

**Flaw 1: Discarded Unique Transaction Count** [1](#0-0) 

The third return value from `pull_batches` containing unique transaction count is assigned to `_` and discarded.

**Flaw 2: Unadjusted Limit for Inline Batches**

When calculating limits for inline batches, only the count from `pull_proofs` is subtracted: [2](#0-1) 

However, the unique transaction limit passed to `pull_batches_with_transactions` remains unadjusted: [3](#0-2) 

**Flaw 3: Independent Accounting Per Pull**

Each `pull_internal` call starts with its own local counter: [4](#0-3) 

And checks against the provided limit independently: [5](#0-4) 

This means each pull validates its unique transactions against `max_txns_after_filtering` separately, without global accounting across all three pulls.

**Attack Scenario:**
Given `max_txns_after_filtering = 100`:
1. `pull_proofs` pulls 50 unique transactions (checked against 100 ✓)
2. `pull_batches` pulls 40 unique transactions (checked against 100 ✓, but count discarded)
3. `pull_batches_with_transactions` receives limit of 100 (unadjusted)
4. Inline batches pull 50 unique transactions (checked against 100 ✓)
5. **Total: 50 + 40 + 50 = 140 unique transactions** (exceeds intended limit of 100)

The TODO comment acknowledges this gap: [6](#0-5) 

## Impact Explanation
This vulnerability qualifies as **High Severity** under Aptos bug bounty criteria:

**Validator Node Slowdowns**: Blocks exceeding intended transaction limits cause:
- Execution delays as validators process oversized blocks
- Memory pressure from handling more transactions than expected
- Degraded network performance affecting consensus timing

**Potential Consensus Risk**: Different validators may construct blocks with different transaction counts if they have varying batch arrival timing, leading to inconsistent block proposals and potential consensus divergence.

**Protocol Violation**: Breaks the fundamental invariant that block construction must respect configured transaction limits.

OptQS (Optimistic Quorum Store) is enabled by default: [7](#0-6) 

This makes the vulnerability active in production deployments.

## Likelihood Explanation
**Likelihood: Medium to High**

This vulnerability triggers when:
1. **OptQS is enabled** - Default configuration enables this feature
2. **Multiple batch authors** - Normal in production with multiple validators
3. **Asynchronous batch arrivals** - Standard network operation mode

The vulnerability does not require:
- Compromised validators or trusted roles
- Majority stake control
- Sophisticated timing attacks
- Special permissions

The TODO comment confirms this is a known implementation gap awaiting proper support for unique transaction calculation across multiple pulls.

## Recommendation
Adjust `max_txns_after_filtering` to account for unique transactions from all previous pulls:

```rust
// At line 134, capture the unique transaction count
let (opt_batches, opt_batch_txns_size, opt_unique_txns) =
    self.batch_proof_queue.pull_batches(...);

// At lines 161-166, subtract both proof and opt unique counts
max_inline_txns_to_pull.set_count(min(
    max_inline_txns_to_pull.count(),
    request.max_txns_after_filtering
        .saturating_sub(cur_unique_txns)
        .saturating_sub(opt_unique_txns),  // Add this line
));

// At line 176, pass the adjusted limit
request.max_txns_after_filtering
    .saturating_sub(cur_unique_txns)
    .saturating_sub(opt_unique_txns),  // Pass adjusted value
```

This ensures the total unique transactions across all three pulls respects the configured limit.

## Proof of Concept
The vulnerability can be demonstrated by:

1. Configuring `max_txns_after_filtering = 100`
2. Having three validators submit batches with non-overlapping transactions:
   - Validator A: 50 transactions with proofs
   - Validator B: 40 transactions without proofs (opt batches)
   - Validator C: 50 transactions for inline batches
3. Observing that the resulting block contains 140 unique transactions instead of the intended maximum of 100

The execution flow follows the proof manager's `handle_proposal_request` calling the three pull methods sequentially, with each independently validating against the unadjusted limit while the global total exceeds it.

---

**Notes:**
- This vulnerability exists in the current codebase as evidenced by the TODO comment
- The deduplication mechanism via `excluded_batches` prevents pulling the same batches but does not enforce global unique transaction limits across different pull types
- The impact increases with network size and transaction volume
- Fix requires proper accounting of unique transactions across all three sequential pulls

### Citations

**File:** consensus/src/quorum_store/proof_manager.rs (L130-130)
```rust
            // TODO(ibalajiarun): Support unique txn calculation
```

**File:** consensus/src/quorum_store/proof_manager.rs (L134-134)
```rust
                let (opt_batches, opt_payload_size, _) =
```

**File:** consensus/src/quorum_store/proof_manager.rs (L161-166)
```rust
                max_inline_txns_to_pull.set_count(min(
                    max_inline_txns_to_pull.count(),
                    request
                        .max_txns_after_filtering
                        .saturating_sub(cur_unique_txns),
                ));
```

**File:** consensus/src/quorum_store/proof_manager.rs (L176-176)
```rust
                        request.max_txns_after_filtering,
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L574-574)
```rust
        let mut cur_unique_txns = 0;
```

**File:** consensus/src/quorum_store/batch_proof_queue.rs (L651-653)
```rust
                        if cur_all_txns + batch.size() > max_txns
                            || unique_txns > max_txns_after_filtering
                        {
```

**File:** config/src/config/quorum_store_config.rs (L141-141)
```rust
            enable_opt_quorum_store: true,
```
