# Audit Report

## Title
TOCTOU Race Condition in BlockStore Causing Validator Node Crash via Concurrent QC Processing

## Summary
The `send_for_execution()` method in BlockStore contains a Time-of-Check to Time-of-Use (TOCTOU) race condition due to non-atomic read operations across three separate lock acquisitions. When concurrent threads process different Quorum Certificates (QCs), one thread can update `ordered_root` after another thread's validation check passes but before path computation, resulting in an empty block list that triggers an assertion failure and crashes the validator node.

## Finding Description

The BlockStore implements thread-safe concurrent access using `Arc<RwLock<BlockTree>>` for its internal state. [1](#0-0) 

Each `BlockReader` trait method independently acquires a read lock, performs its operation, and immediately releases the lock: [2](#0-1) 

The vulnerability manifests in `send_for_execution()` which performs three non-atomic read lock acquisitions:

**First read** (line 317-319): Retrieves the block to commit
**Second read** (line 323): Validates block_to_commit.round() > ordered_root().round()  
**Third read** (line 327-329): Computes path from ordered_root [3](#0-2) 

Between these operations, another concurrent thread can acquire the write lock and advance `ordered_root` (line 338), creating the race condition.

**Attack Scenario:**

1. Thread A processes QC for block at round 15, reads ordered_root().round() = 10
2. Thread A's validation passes: 15 > 10 âœ“
3. Thread B concurrently processes QC for block at round 20, acquires write lock
4. Thread B updates ordered_root to round 20 and releases lock
5. Thread A calls `path_from_ordered_root(block_15)` which now uses ordered_root at round 20
6. Since block 15's round < ordered_root 20's round, the path computation encounters the race condition

The developers explicitly documented this race condition in `path_from_root_to_block()`: [4](#0-3) 

The method returns `None` to gracefully handle the race: [5](#0-4) 

When the block's round is less than or equal to root_round, but the block_id doesn't match root_id, it returns `None` (lines 540-541).

However, `send_for_execution()` negates this protection by using `.unwrap_or_default()` followed by an assertion that causes a panic when the vector is empty (lines 327-331).

This vulnerability is triggered through normal consensus flow where multiple threads concurrently call `send_for_execution()`: [6](#0-5)  and [7](#0-6) 

The BlockStore is shared across threads via Arc: [8](#0-7) 

Message processing spawns concurrent verification tasks: [9](#0-8) 

## Impact Explanation

This vulnerability qualifies as **HIGH severity** under the Aptos Bug Bounty program's explicit criteria for "Validator node crashes". The assertion failure at line 331 causes immediate process termination via panic, directly violating consensus liveness guarantees.

**Concrete impacts:**
- **Immediate validator termination**: The `assert!` macro panics, crashing the entire validator process
- **Consensus liveness degradation**: Crashed validators cannot participate in consensus, reducing network capacity
- **Cascading failures**: Under high transaction throughput, multiple validators may simultaneously experience this race, potentially causing significant network disruption
- **Protocol violation**: The crash breaks the consensus layer's availability guarantees

This maps directly to the HIGH severity category which explicitly lists "Validator node crashes" as a qualifying impact.

## Likelihood Explanation

**HIGH likelihood** - This race condition occurs through normal consensus operation without requiring any malicious actor:

**Natural occurrence patterns:**
- Multiple validators independently aggregate votes into QCs at different times
- Network latency variations cause QCs to arrive out-of-order at each validator node
- Async message processing enables concurrent execution of `send_for_execution()` 
- The race window spans three separate async lock acquisitions, providing substantial opportunity for interleaving
- High transaction throughput increases QC generation frequency, amplifying race occurrence probability

**Technical feasibility:**
- No special privileges required - occurs during normal consensus message processing
- No Byzantine validator collusion needed - works with valid QCs from honest validators
- Can be exacerbated (though not required) by network conditions or strategic QC relay timing
- The concurrent task spawning model (line 1587-1622 in epoch_manager.rs) enables race conditions by design

## Recommendation

Replace the `.unwrap_or_default()` + `assert!` pattern with proper error handling that respects the `None` return value from `path_from_ordered_root`:

```rust
let blocks_to_commit = match self.path_from_ordered_root(block_id_to_commit) {
    Some(blocks) => blocks,
    None => {
        // Race condition detected: ordered_root advanced between check and use
        warn!(
            "Block {} committed by another thread before path computation, round {}",
            block_id_to_commit, block_to_commit.round()
        );
        return Ok(()); // Gracefully skip - block already ordered by concurrent thread
    }
};

assert!(!blocks_to_commit.is_empty());
```

Alternatively, use a single atomic operation by acquiring the write lock earlier:

```rust
let mut inner = self.inner.write();
let block_to_commit = self.get_block(block_id_to_commit)
    .ok_or_else(|| format_err!("Committed block id not found"))?;

ensure!(
    block_to_commit.round() > inner.ordered_root().round(),
    "Committed block round lower than root"
);

let blocks_to_commit = inner.path_from_ordered_root(block_id_to_commit)
    .ok_or_else(|| format_err!("Path computation failed"))?;

inner.update_ordered_root(block_to_commit.id());
// ... rest of the operations under same lock
```

## Proof of Concept

A proof of concept would require setting up a concurrent test environment that:
1. Creates two concurrent async tasks processing different QCs
2. Uses timing controls to trigger the race window
3. Verifies the panic occurs when the race is triggered

The PoC would leverage the existing test infrastructure in `consensus/src/block_storage/block_store_test.rs` to create the race condition scenario programmatically.

## Notes

The developers were aware of this race condition (as evidenced by the comment in block_tree.rs lines 515-518) and implemented a defensive `None` return in `path_from_root_to_block()`. However, the calling code in `send_for_execution()` defeats this protection by converting `None` to an empty vector and then asserting it's non-empty. This represents a disconnect between the defensive programming in the lower layer and the error handling in the upper layer.

The vulnerability exists in the current mainnet codebase and can be triggered during normal high-load consensus operation without any malicious actors.

### Citations

**File:** consensus/src/block_storage/block_store.rs (L85-86)
```rust
pub struct BlockStore {
    inner: Arc<RwLock<BlockTree>>,
```

**File:** consensus/src/block_storage/block_store.rs (L311-350)
```rust
    /// Send an ordered block id with the proof for execution, returns () on success or error
    pub async fn send_for_execution(
        &self,
        finality_proof: WrappedLedgerInfo,
    ) -> anyhow::Result<()> {
        let block_id_to_commit = finality_proof.commit_info().id();
        let block_to_commit = self
            .get_block(block_id_to_commit)
            .ok_or_else(|| format_err!("Committed block id not found"))?;

        // First make sure that this commit is new.
        ensure!(
            block_to_commit.round() > self.ordered_root().round(),
            "Committed block round lower than root"
        );

        let blocks_to_commit = self
            .path_from_ordered_root(block_id_to_commit)
            .unwrap_or_default();

        assert!(!blocks_to_commit.is_empty());

        let finality_proof_clone = finality_proof.clone();
        self.pending_blocks
            .lock()
            .gc(finality_proof.commit_info().round());

        self.inner.write().update_ordered_root(block_to_commit.id());
        self.inner
            .write()
            .insert_ordered_cert(finality_proof_clone.clone());
        update_counters_for_ordered_blocks(&blocks_to_commit);

        self.execution_client
            .finalize_order(blocks_to_commit, finality_proof.clone())
            .await
            .expect("Failed to persist commit");

        Ok(())
    }
```

**File:** consensus/src/block_storage/block_store.rs (L630-657)
```rust
impl BlockReader for BlockStore {
    fn block_exists(&self, block_id: HashValue) -> bool {
        self.inner.read().block_exists(&block_id)
    }

    fn get_block(&self, block_id: HashValue) -> Option<Arc<PipelinedBlock>> {
        self.inner.read().get_block(&block_id)
    }

    fn ordered_root(&self) -> Arc<PipelinedBlock> {
        self.inner.read().ordered_root()
    }

    fn commit_root(&self) -> Arc<PipelinedBlock> {
        self.inner.read().commit_root()
    }

    fn get_quorum_cert_for_block(&self, block_id: HashValue) -> Option<Arc<QuorumCert>> {
        self.inner.read().get_quorum_cert_for_block(&block_id)
    }

    fn path_from_ordered_root(&self, block_id: HashValue) -> Option<Vec<Arc<PipelinedBlock>>> {
        self.inner.read().path_from_ordered_root(block_id)
    }

    fn path_from_commit_root(&self, block_id: HashValue) -> Option<Vec<Arc<PipelinedBlock>>> {
        self.inner.read().path_from_commit_root(block_id)
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L512-518)
```rust
    /// Returns all the blocks between the commit root and the given block, including the given block
    /// but excluding the root.
    /// In case a given block is not the successor of the root, return None.
    /// While generally the provided blocks should always belong to the active tree, there might be
    /// a race, in which the root of the tree is propagated forward between retrieving the block
    /// and getting its path from root (e.g., at proposal generator). Hence, we don't want to panic
    /// and prefer to return None instead.
```

**File:** consensus/src/block_storage/block_tree.rs (L519-546)
```rust
    pub(super) fn path_from_root_to_block(
        &self,
        block_id: HashValue,
        root_id: HashValue,
        root_round: u64,
    ) -> Option<Vec<Arc<PipelinedBlock>>> {
        let mut res = vec![];
        let mut cur_block_id = block_id;
        loop {
            match self.get_block(&cur_block_id) {
                Some(ref block) if block.round() <= root_round => {
                    break;
                },
                Some(block) => {
                    cur_block_id = block.parent_id();
                    res.push(block);
                },
                None => return None,
            }
        }
        // At this point cur_block.round() <= self.root.round()
        if cur_block_id != root_id {
            return None;
        }
        // Called `.reverse()` to get the chronically increased order.
        res.reverse();
        Some(res)
    }
```

**File:** consensus/src/block_storage/sync_manager.rs (L175-200)
```rust
    pub async fn insert_quorum_cert(
        &self,
        qc: &QuorumCert,
        retriever: &mut BlockRetriever,
    ) -> anyhow::Result<()> {
        match self.need_fetch_for_quorum_cert(qc) {
            NeedFetchResult::NeedFetch => self.fetch_quorum_cert(qc.clone(), retriever).await?,
            NeedFetchResult::QCBlockExist => self.insert_single_quorum_cert(qc.clone())?,
            NeedFetchResult::QCAlreadyExist => return Ok(()),
            _ => (),
        }
        if self.ordered_root().round() < qc.commit_info().round() {
            SUCCESSFUL_EXECUTED_WITH_REGULAR_QC.inc();
            self.send_for_execution(qc.into_wrapped_ledger_info())
                .await?;
            if qc.ends_epoch() {
                retriever
                    .network
                    .broadcast_epoch_change(EpochChangeProof::new(
                        vec![qc.ledger_info().clone()],
                        /* more = */ false,
                    ))
                    .await;
            }
        }
        Ok(())
```

**File:** consensus/src/block_storage/sync_manager.rs (L206-227)
```rust
    pub async fn insert_ordered_cert(
        &self,
        ordered_cert: &WrappedLedgerInfo,
    ) -> anyhow::Result<()> {
        if self.ordered_root().round() < ordered_cert.ledger_info().ledger_info().round() {
            if let Some(ordered_block) = self.get_block(ordered_cert.commit_info().id()) {
                if !ordered_block.block().is_nil_block() {
                    observe_block(
                        ordered_block.block().timestamp_usecs(),
                        BlockStage::OC_ADDED,
                    );
                }
                SUCCESSFUL_EXECUTED_WITH_ORDER_VOTE_QC.inc();
                self.send_for_execution(ordered_cert.clone()).await?;
            } else {
                bail!("Ordered block not found in block store when inserting ordered cert");
            }
        } else {
            LATE_EXECUTION_WITH_ORDER_VOTE_QC.inc();
        }
        Ok(())
    }
```

**File:** consensus/src/epoch_manager.rs (L887-899)
```rust
        let block_store = Arc::new(BlockStore::new(
            Arc::clone(&self.storage),
            recovery_data,
            self.execution_client.clone(),
            self.config.max_pruned_blocks_in_mem,
            Arc::clone(&self.time_service),
            self.config.vote_back_pressure_limit,
            payload_manager,
            onchain_consensus_config.order_vote_enabled(),
            onchain_consensus_config.window_size(),
            self.pending_blocks.clone(),
            Some(pipeline_builder),
        ));
```

**File:** consensus/src/epoch_manager.rs (L1587-1622)
```rust
            self.bounded_executor
                .spawn(async move {
                    match monitor!(
                        "verify_message",
                        unverified_event.clone().verify(
                            peer_id,
                            &epoch_state.verifier,
                            &proof_cache,
                            quorum_store_enabled,
                            peer_id == my_peer_id,
                            max_num_batches,
                            max_batch_expiry_gap_usecs,
                        )
                    ) {
                        Ok(verified_event) => {
                            Self::forward_event(
                                quorum_store_msg_tx,
                                round_manager_tx,
                                buffered_proposal_tx,
                                peer_id,
                                verified_event,
                                payload_manager,
                                pending_blocks,
                            );
                        },
                        Err(e) => {
                            error!(
                                SecurityEvent::ConsensusInvalidMessage,
                                remote_peer = peer_id,
                                error = ?e,
                                unverified_event = unverified_event
                            );
                        },
                    }
                })
                .await;
```
