# Audit Report

## Title
Silent Iterator Error Suppression in Randomness Storage Causes Consensus Divergence

## Summary
The `get_all()` function in the consensus randomness storage layer silently discards database iterator errors using `filter_map`, returning incomplete datasets without indication of failure. This causes validators to have inconsistent views of certified augmented data, breaking consensus safety guarantees during randomness generation and leading to non-deterministic execution.

## Finding Description

The vulnerability exists in the randomness database storage implementation where the `get_all()` method silently suppresses iterator errors: [1](#0-0) 

The method uses `filter_map` to convert all `Err(_)` variants to `None`, silently dropping errors from the SchemaDB iterator. These errors can originate from RocksDB status checks or BCS deserialization failures: [2](#0-1) 

This function is invoked during critical initialization when loading certified augmented data into the `AugDataStore`: [3](#0-2) 

When iterator errors occur, `get_all_certified_aug_data()` returns an incomplete set without any indication. The calling code uses `unwrap_or_default()`, which only catches the outer `Result`, not the silent filtering inside, causing `AugDataStore` to initialize with missing validator data.

**Consensus Impact Chain:**

The certified augmented data contains Delta values that are processed via the `augment()` function to construct augmented public keys (APKs) for the weighted VUF randomness protocol: [4](#0-3) 

Missing certified deltas prevent APK reconstruction. When randomness shares arrive from validators whose data was silently dropped, share verification fails because the APK is unavailable: [5](#0-4) 

During share aggregation, missing APKs cause failures: [6](#0-5) 

The weighted VUF `derive_eval` function requires APKs for all participating players: [7](#0-6) 

**Critical Discovery:** Each validator independently computes randomness locally rather than using a consensus-agreed value. The randomness is sent from each validator's `RandManager` to their execution pipeline: [8](#0-7) 

The randomness value is then embedded in block metadata transactions during execution: [9](#0-8) [10](#0-9) 

This breaks **Consensus Safety** because validators experiencing different iterator errors will:
1. Have different views of which validators possess valid APKs
2. Accept/reject different sets of randomness shares
3. Aggregate different share subsets
4. Compute different randomness values via `derive_eval`
5. Execute identical blocks with different randomness in block metadata transactions
6. Produce different state roots, causing consensus divergence

## Impact Explanation

**Severity: CRITICAL** (per Aptos Bug Bounty criteria for "Consensus/Safety Violations")

This vulnerability causes **consensus-level protocol violations** by breaking deterministic execution guarantees. The impact matches the CRITICAL category "Different validators commit different blocks" because:

- **Consensus Divergence**: Different nodes compute different randomness values for identical blocks at identical rounds, leading to different state commitments
- **Protocol Safety Violation**: The weighted VUF protocol requires all honest validators to have consistent views of certified public key shares; this assumption is violated
- **Non-deterministic Execution**: Identical blocks produce different execution results on different nodes based on which database entries encountered errors
- **Liveness Failures**: Nodes missing critical validator APK data cannot properly verify or aggregate randomness shares

The APKs are stored in `OnceCell` structures that can only be set once: [11](#0-10) 

Once initialized with missing APKs due to silent database errors, the validator cannot recover without restarting.

## Likelihood Explanation

**Likelihood: MEDIUM to HIGH**

This vulnerability manifests through natural operational failures:

**Natural Occurrence (HIGH likelihood):**
- Database corruption from hardware failures, power loss, or disk errors
- Schema migration issues causing BCS deserialization failures during iterator processing  
- RocksDB hitting internal operational limits
- Filesystem I/O errors during database reads
- These are common operational issues in long-running distributed validator nodes

The vulnerability is particularly dangerous because:
1. Silent failures provide no error logs or diagnostics for operators
2. Inconsistent state across validators is difficult to detect until consensus failures manifest
3. Partial data loss (some validators affected, others not) creates non-deterministic failure patterns
4. The error occurs during initialization, so affected validators run with incomplete state throughout the epoch

## Recommendation

Replace the silent error suppression with proper error propagation:

```rust
fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
    let mut iter = self.db.iter::<S>()?;
    iter.seek_to_first();
    iter.collect::<Result<Vec<(S::Key, S::Value)>, _>>()
        .map_err(|e| DbError::from(e))
}
```

This ensures that iterator errors are propagated to callers, who can:
1. Log the errors for operator visibility
2. Fail initialization gracefully rather than running with incomplete state
3. Trigger recovery mechanisms or alerts

Additionally, add validation at the `AugDataStore` initialization to verify all expected validators have APKs before proceeding.

## Proof of Concept

While a full PoC would require simulating database corruption, the vulnerability is demonstrable through code inspection. The execution path is:

1. Database iterator error occurs (e.g., during RocksDB read or BCS deserialization)
2. `get_all()` silently converts the error to `None` via `filter_map`
3. `get_all_certified_aug_data()` returns incomplete data without indication
4. `AugDataStore::new()` initializes with missing APKs
5. Share verification/aggregation fails differently on different validators
6. Each validator computes different randomness values
7. Block execution produces different state roots, breaking consensus

The code evidence across multiple files demonstrates this complete chain without requiring a constructed test case.

### Citations

**File:** consensus/src/rand/rand_gen/storage/db.rs (L73-82)
```rust
    fn get_all<S: Schema>(&self) -> Result<Vec<(S::Key, S::Value)>, DbError> {
        let mut iter = self.db.iter::<S>()?;
        iter.seek_to_first();
        Ok(iter
            .filter_map(|e| match e {
                Ok((k, v)) => Some((k, v)),
                Err(_) => None,
            })
            .collect::<Vec<(S::Key, S::Value)>>())
    }
```

**File:** storage/schemadb/src/iterator.rs (L92-122)
```rust
    fn next_impl(&mut self) -> aptos_storage_interface::Result<Option<(S::Key, S::Value)>> {
        let _timer = APTOS_SCHEMADB_ITER_LATENCY_SECONDS.timer_with(&[S::COLUMN_FAMILY_NAME]);

        if let Status::Advancing = self.status {
            match self.direction {
                ScanDirection::Forward => self.db_iter.next(),
                ScanDirection::Backward => self.db_iter.prev(),
            }
        } else {
            self.status = Status::Advancing;
        }

        if !self.db_iter.valid() {
            self.db_iter.status().into_db_res()?;
            // advancing an invalid raw iter results in seg fault
            self.status = Status::Invalid;
            return Ok(None);
        }

        let raw_key = self.db_iter.key().expect("db_iter.key() failed.");
        let raw_value = self.db_iter.value().expect("db_iter.value(0 failed.");
        APTOS_SCHEMADB_ITER_BYTES.observe_with(
            &[S::COLUMN_FAMILY_NAME],
            (raw_key.len() + raw_value.len()) as f64,
        );

        let key = <S::Key as KeyCodec<S>>::decode_key(raw_key);
        let value = <S::Value as ValueCodec<S>>::decode_value(raw_value);

        Ok(Some((key?, value?)))
    }
```

**File:** consensus/src/rand/rand_gen/aug_data_store.rs (L51-65)
```rust
        let all_data = db.get_all_aug_data().unwrap_or_default();
        let (to_remove, aug_data) = Self::filter_by_epoch(epoch, all_data.into_iter());
        if let Err(e) = db.remove_aug_data(to_remove) {
            error!("[AugDataStore] failed to remove aug data: {:?}", e);
        }

        let all_certified_data = db.get_all_certified_aug_data().unwrap_or_default();
        let (to_remove, certified_data) =
            Self::filter_by_epoch(epoch, all_certified_data.into_iter());
        if let Err(e) = db.remove_certified_aug_data(to_remove) {
            error!(
                "[AugDataStore] failed to remove certified aug data: {:?}",
                e
            );
        }
```

**File:** consensus/src/rand/rand_gen/types.rs (L63-79)
```rust
        let maybe_apk = &rand_config.keys.certified_apks[index];
        if let Some(apk) = maybe_apk.get() {
            WVUF::verify_share(
                &rand_config.vuf_pp,
                apk,
                bcs::to_bytes(&rand_metadata)
                    .map_err(|e| anyhow!("Serialization failed: {}", e))?
                    .as_slice(),
                &self.share,
            )?;
        } else {
            bail!(
                "[RandShare] No augmented public key for validator id {}, {}",
                index,
                author
            );
        }
```

**File:** consensus/src/rand/rand_gen/types.rs (L119-127)
```rust
            let apk = rand_config
                .get_certified_apk(share.author())
                .ok_or_else(|| {
                    anyhow!(
                        "Share::aggregate failed with missing apk for share from {}",
                        share.author
                    )
                })?;
            apks_and_proofs.push((Player { id }, apk.clone(), share.share().share));
```

**File:** consensus/src/rand/rand_gen/types.rs (L134-142)
```rust
        let eval = WVUF::derive_eval(
            &rand_config.wconfig,
            &rand_config.vuf_pp,
            metadata_serialized.as_slice(),
            &rand_config.get_all_certified_apk(),
            &proof,
            THREAD_MANAGER.get_exe_cpu_pool(),
        )
        .map_err(|e| anyhow!("Share::aggregate failed with WVUF derive_eval error: {e}"))?;
```

**File:** consensus/src/rand/rand_gen/types.rs (L178-194)
```rust
    fn augment(
        &self,
        rand_config: &RandConfig,
        fast_rand_config: &Option<RandConfig>,
        author: &Author,
    ) {
        let AugmentedData { delta, fast_delta } = self;
        rand_config
            .add_certified_delta(author, delta.clone())
            .expect("Add delta should succeed");

        if let (Some(config), Some(fast_delta)) = (fast_rand_config, fast_delta) {
            config
                .add_certified_delta(author, fast_delta.clone())
                .expect("Add delta for fast path should succeed");
        }
    }
```

**File:** consensus/src/pipeline/execution_schedule_phase.rs (L64-67)
```rust
        for b in &ordered_blocks {
            if let Some(tx) = b.pipeline_tx().lock().as_mut() {
                tx.rand_tx.take().map(|tx| tx.send(b.randomness().cloned()));
            }
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L2519-2522)
```rust
            randomness
                .as_ref()
                .map(Randomness::randomness_cloned)
                .as_move_value(),
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L2544-2549)
```rust
        let output = get_system_transaction_output(
            session,
            module_storage,
            &self.storage_gas_params(log_context)?.change_set_configs,
        )?;
        Ok((VMStatus::Executed, output))
```

**File:** types/src/randomness.rs (L111-135)
```rust
    pub certified_apks: Vec<OnceCell<APK>>,
    // public key share of all validators, obtained from the DKG transcript of last epoch
    pub pk_shares: Vec<PKShare>,
}

impl RandKeys {
    pub fn new(ask: ASK, apk: APK, pk_shares: Vec<PKShare>, num_validators: usize) -> Self {
        let certified_apks = vec![OnceCell::new(); num_validators];

        Self {
            ask,
            apk,
            certified_apks,
            pk_shares,
        }
    }

    pub fn add_certified_apk(&self, index: usize, apk: APK) -> anyhow::Result<()> {
        assert!(index < self.certified_apks.len());
        if self.certified_apks[index].get().is_some() {
            return Ok(());
        }
        self.certified_apks[index].set(apk).unwrap();
        Ok(())
    }
```
