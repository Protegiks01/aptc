# Audit Report

## Title
Partial Shard Commit During Crash Can Cause Permanent Node Orphaning Leading to Unbounded Database Growth

## Summary
A critical asymmetry exists in the state merkle database recovery mechanism where stale node indices are deleted based on `stale_since_version` while actual nodes are deleted based on their creation `version`. This causes nodes to become permanently orphaned and unprunable when crashes occur during sharded commits, leading to unbounded database growth.

## Finding Description

The vulnerability stems from an asymmetric truncation logic in the state merkle database recovery process:

**1. Stale Node Index Structure**

The `StaleNodeIndex` contains two fields with different version semantics. [1](#0-0)  The `stale_since_version` indicates when a node became stale, while the `node_key` contains the node's original creation version. [2](#0-1) 

**2. Non-Atomic Cross-Shard Commit**

Shards are committed in parallel with no cross-shard atomicity guarantee. [3](#0-2)  The overall progress marker is written only after all shard commits complete in the top-level batch.

**3. Asymmetric Recovery Logic**

On restart, recovery truncates shards based on overall progress. The truncation logic contains a critical asymmetry in `delete_nodes_and_stale_indices_at_or_after_version`: [4](#0-3) 

Stale indices are deleted where `stale_since_version >= version`: [5](#0-4) 

But nodes are deleted by seeking to `NodeKey::new_empty_path(version)` which compares the node's creation `version` field (line 615).

**4. Orphaning Scenario**

Consider a node created at version 99 that becomes stale at version 100:
- `StaleNodeIndex { stale_since_version: 100, node_key: NodeKey(version=99, ...) }` is written to shard
- Shard commits successfully
- System crashes before overall progress (100) is written
- On recovery, `truncate_state_merkle_db_single_shard` is called with target_version=99: [6](#0-5) 
- This calls `delete_nodes_and_stale_indices_at_or_after_version(db, 100, ...)`
- Stale index deleted (because `stale_since_version=100 >= 100`)
- Node survives (because `node_key.version=99 < 100`)
- Node is now orphaned with no index entry

**5. Unprunable Forever**

The pruner operates by scanning stale node indices to discover which nodes to prune: [7](#0-6)  Without a StaleNodeIndex entry pointing to it, orphaned nodes can never be discovered by the pruner. [8](#0-7) 

Recovery is triggered on database initialization: [9](#0-8) 

## Impact Explanation

**Severity: High**

This qualifies as **High Severity** per Aptos bug bounty criteria for:

1. **Validator Node Slowdowns**: Accumulated orphaned nodes cause:
   - Increased disk I/O for database operations
   - Slower backup/restore operations  
   - Degraded iterator performance
   - Slower state sync for new nodes
   - Unbounded storage growth requiring manual intervention

2. **Significant Protocol Violations**: 
   - Breaks the state consistency invariant that all stale nodes should be prunable
   - Causes unbounded database growth violating storage efficiency guarantees
   - Creates non-deterministic database state across validators (different crash histories lead to different orphaned nodes)

3. **Economic Impact**: Storage costs increase linearly with orphaned nodes, creating unfair operational burden on validators.

While this does not directly break consensus safety (orphaned nodes are unreferenced in the current state), it causes significant validator performance degradation and protocol violations over time, meeting the High Severity criteria of "Validator Node Slowdowns."

## Likelihood Explanation

**Likelihood: Medium**

The vulnerability can realistically occur because:

1. **Frequent Trigger Conditions**: Crashes during commits occur through:
   - Validator restarts for upgrades/maintenance
   - OOM kills during high load
   - Hardware failures or power outages
   - Kernel panics

2. **High Exposure Window**: State merkle commits occur every block, providing frequent opportunities for crashes during the commit window between shard commits and overall progress update.

3. **Cumulative Impact**: Each crash orphans multiple nodes (all nodes that became stale at that version). Over weeks/months of 24/7 validator operation, the cumulative impact becomes significant.

4. **Realistic Operational Scenario**: Validators regularly experience restarts and occasional failures, making this a practical concern rather than a theoretical edge case.

## Recommendation

Align the truncation logic to use the same version field for both stale indices and nodes. Specifically:

1. **Option 1**: Delete stale indices where `node_key.version >= version` (matching node deletion logic)
2. **Option 2**: Delete nodes where `stale_since_version >= version` (matching stale index deletion logic)

Option 1 is recommended as it maintains the semantic that truncation removes all data created at or after the target version:

```rust
fn delete_stale_node_index_at_or_after_version<S>(
    db: &DB,
    version: Version,
    batch: &mut SchemaBatch,
) -> Result<()>
where
    S: Schema<Key = StaleNodeIndex>,
{
    let mut iter = db.iter::<S>()?;
    // Seek by the minimum possible StaleNodeIndex at target version
    iter.seek(&StaleNodeIndex {
        stale_since_version: 0,
        node_key: NodeKey::new_empty_path(version),
    })?;
    
    for item in iter {
        let (index, _) = item?;
        // Delete if the node was created at or after target version
        if index.node_key.version() >= version {
            batch.delete::<S>(&index)?;
        } else {
            break; // Indices are ordered, so we can stop here
        }
    }
    Ok(())
}
```

## Proof of Concept

This vulnerability can be demonstrated through the following scenario:

1. Run a validator and commit blocks up to version 99
2. Begin committing version 100 (which creates stale indices for nodes at version 99)
3. Simulate a crash after shard commits but before overall progress update
4. Restart the database and observe the recovery process
5. Query the database for nodes at version 99 and their corresponding stale indices
6. Verify that nodes exist without stale indices
7. Attempt to run the pruner and confirm these orphaned nodes cannot be pruned

A full Rust integration test would require access to the test infrastructure to simulate crashes during commits, but the code analysis clearly demonstrates the asymmetric logic that enables this vulnerability.

## Notes

This is a logic vulnerability in the crash recovery mechanism that affects the storage layer's ability to maintain database hygiene through pruning. While it does not compromise consensus safety or lead to immediate validator failure, it causes gradual performance degradation and violates the protocol's storage efficiency guarantees. The impact is cumulative and affects all validators over time, making it a significant operational concern that warrants High severity classification.

### Citations

**File:** storage/jellyfish-merkle/src/lib.rs (L195-201)
```rust
pub struct StaleNodeIndex {
    /// The version since when the node is overwritten and becomes stale.
    pub stale_since_version: Version,
    /// The [`NodeKey`](node_type/struct.NodeKey.html) identifying the node associated with this
    /// record.
    pub node_key: NodeKey,
}
```

**File:** storage/jellyfish-merkle/src/node_type/mod.rs (L49-54)
```rust
pub struct NodeKey {
    // The version at which the node is created.
    version: Version,
    // The nibble path this node represents in the tree.
    nibble_path: NibblePath,
}
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L157-170)
```rust
        THREAD_MANAGER.get_io_pool().install(|| {
            batches_for_shards
                .into_par_iter()
                .enumerate()
                .for_each(|(shard_id, batch)| {
                    self.db_shard(shard_id)
                        .write_schemas(batch)
                        .unwrap_or_else(|err| {
                            panic!("Failed to commit state merkle shard {shard_id}: {err}")
                        });
                })
        });

        self.commit_top_levels(version, top_levels_batch)
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L668-677)
```rust
        if !readonly {
            if let Some(overall_state_merkle_commit_progress) =
                get_state_merkle_commit_progress(&state_merkle_db)?
            {
                truncate_state_merkle_db_shards(
                    &state_merkle_db,
                    overall_state_merkle_commit_progress,
                )?;
            }
        }
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L193-206)
```rust
pub(crate) fn truncate_state_merkle_db_single_shard(
    state_merkle_db: &StateMerkleDb,
    shard_id: usize,
    target_version: Version,
) -> Result<()> {
    let mut batch = SchemaBatch::new();
    delete_nodes_and_stale_indices_at_or_after_version(
        state_merkle_db.db_shard(shard_id),
        target_version + 1,
        Some(shard_id),
        &mut batch,
    )?;
    state_merkle_db.db_shard(shard_id).write_schemas(batch)
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L583-601)
```rust
fn delete_stale_node_index_at_or_after_version<S>(
    db: &DB,
    version: Version,
    batch: &mut SchemaBatch,
) -> Result<()>
where
    S: Schema<Key = StaleNodeIndex>,
    Version: SeekKeyCodec<S>,
{
    let mut iter = db.iter::<S>()?;
    iter.seek(&version)?;
    for item in iter {
        let (index, _) = item?;
        assert_ge!(index.stale_since_version, version);
        batch.delete::<S>(&index)?;
    }

    Ok(())
}
```

**File:** storage/aptosdb/src/utils/truncation_helper.rs (L603-622)
```rust
fn delete_nodes_and_stale_indices_at_or_after_version(
    db: &DB,
    version: Version,
    shard_id: Option<usize>,
    batch: &mut SchemaBatch,
) -> Result<()> {
    delete_stale_node_index_at_or_after_version::<StaleNodeIndexSchema>(db, version, batch)?;
    delete_stale_node_index_at_or_after_version::<StaleNodeIndexCrossEpochSchema>(
        db, version, batch,
    )?;

    let mut iter = db.iter::<JellyfishMerkleNodeSchema>()?;
    iter.seek(&NodeKey::new_empty_path(version))?;
    for item in iter {
        let (key, _) = item?;
        batch.delete::<JellyfishMerkleNodeSchema>(&key)?;
    }

    StateMerkleDb::put_progress(version.checked_sub(1), shard_id, batch)
}
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs (L191-217)
```rust
    pub(in crate::pruner::state_merkle_pruner) fn get_stale_node_indices(
        state_merkle_db_shard: &DB,
        start_version: Version,
        target_version: Version,
        limit: usize,
    ) -> Result<(Vec<StaleNodeIndex>, Option<Version>)> {
        let mut indices = Vec::new();
        let mut iter = state_merkle_db_shard.iter::<S>()?;
        iter.seek(&StaleNodeIndex {
            stale_since_version: start_version,
            node_key: NodeKey::new_empty_path(0),
        })?;

        let mut next_version = None;
        while indices.len() < limit {
            if let Some((index, _)) = iter.next().transpose()? {
                next_version = Some(index.stale_since_version);
                if index.stale_since_version <= target_version {
                    indices.push(index);
                    continue;
                }
            }
            break;
        }

        Ok((indices, next_version))
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L58-100)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
        max_nodes_to_prune: usize,
    ) -> Result<()> {
        loop {
            let mut batch = SchemaBatch::new();
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;

            indices.into_iter().try_for_each(|index| {
                batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
                batch.delete::<S>(&index)
            })?;

            let mut done = true;
            if let Some(next_version) = next_version {
                if next_version <= target_version {
                    done = false;
                }
            }

            if done {
                batch.put::<DbMetadataSchema>(
                    &S::progress_metadata_key(Some(self.shard_id)),
                    &DbMetadataValue::Version(target_version),
                )?;
            }

            self.db_shard.write_schemas(batch)?;

            if done {
                break;
            }
        }

        Ok(())
    }
```
