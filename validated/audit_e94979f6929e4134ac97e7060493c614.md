# Audit Report

## Title
Missing fsync() in OnDiskStorage.write() Enables Consensus Safety Violations After Crashes

## Summary
The `OnDiskStorage::write()` method lacks a critical `fsync()` call before performing atomic rename operations, violating durability guarantees required for consensus safety. This enables crashes to corrupt `SafetyData` (including `last_voted_round`), potentially causing validators to double-vote and break AptosBFT consensus safety.

## Finding Description

The `OnDiskStorage::write()` method uses an atomic write pattern (write-to-temp-then-rename) but omits the required `fsync()` operation: [1](#0-0) 

The `PersistentSafetyStorage` interface explicitly requires synchronous persistence: [2](#0-1) 

**Vulnerability Chain:**

1. **Critical Data Storage**: OnDiskStorage persists consensus-critical data including BLS private keys and safety state containing `last_voted_round`, `epoch`, and `preferred_round`: [3](#0-2) 

2. **Durability Violation**: Without `file.sync_all()` before `fs::rename()`, writes remain in OS page cache. A crash can leave the renamed file with zero bytes or corrupted content, as `file.write_all()` only guarantees data reaches the OS buffer, not persistent storage.

3. **Production Configuration Gap**: Despite README warnings that OnDiskStorage "should not be used in production environments" [4](#0-3) , production validator configurations use it: [5](#0-4) [6](#0-5) 

4. **Double-Vote Prevention Failure**: When `SafetyData` corruption causes `last_voted_round` to revert (e.g., from 1000 to 900), the double-vote prevention check fails: [7](#0-6) 

The validator incorrectly believes it can vote on rounds 901-1000 again, enabling double-voting and violating AptosBFT's < 1/3 Byzantine fault tolerance assumption.

5. **Config Sanitizer Gap**: The safety rules config sanitizer only blocks `InMemoryStorage` on mainnet, not `OnDiskStorage`: [8](#0-7) [9](#0-8) 

## Impact Explanation

**Critical Severity** - Qualifies as "Consensus/Safety violations" per Aptos bug bounty (up to $1,000,000):

1. **Consensus Safety Violations**: Corrupted `SafetyData` enables double-voting, breaking the fundamental safety guarantee of AptosBFT consensus. If multiple validators experience simultaneous crashes with corruption, the < 1/3 Byzantine fault tolerance assumption is violated.

2. **Validator Key Loss**: Corrupted `CONSENSUS_KEY` files render validators unable to sign votes, causing loss of validator participation until manual key recovery.

3. **Network Liveness Impact**: Multiple validators with corrupted safety data can cause consensus deadlock requiring coordinated manual intervention.

The vulnerability affects consensus correctness - the highest severity category in blockchain systems.

## Likelihood Explanation

**High Likelihood** in production:

- Power failures, kernel panics, and hardware faults are common in distributed systems
- ALL validators using OnDiskStorage (current default per production configs) are vulnerable
- Modern filesystems with write-back caching (ext4 `data=ordered`, XFS default) make this especially likely, with flush delays of several seconds under load
- Historical precedent: This exact fsync-before-rename bug has caused production data corruption in PostgreSQL, MongoDB, and etcd

The codebase demonstrates awareness of this requirement - GCS backup code correctly uses `sync_all()`: [10](#0-9) 

## Recommendation

Add `sync_all()` before rename in `OnDiskStorage::write()`:

```rust
fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
    let contents = serde_json::to_vec(data)?;
    let mut file = File::create(self.temp_path.path())?;
    file.write_all(&contents)?;
    file.sync_all()?;  // Add this line
    fs::rename(&self.temp_path, &self.file_path)?;
    Ok(())
}
```

Additionally, update the config sanitizer to block `OnDiskStorage` on mainnet (similar to `InMemoryStorage`), or document that only `VaultStorage` should be used in production.

## Proof of Concept

The vulnerability can be demonstrated through crash injection testing:

1. Start validator with OnDiskStorage backend
2. Trigger consensus vote (updates `last_voted_round` via `set_safety_data()`)
3. Inject crash/power failure before kernel flushes page cache
4. Restart validator and observe corrupted/empty `secure-data.json`
5. Verify `last_voted_round` has reverted to older value
6. Demonstrate double-voting is now possible on previously voted rounds

A complete PoC would require integration testing with crash injection tools (e.g., `libeatmydata` or filesystem fault injection) to simulate the race condition.

## Notes

This vulnerability represents a gap between documented best practices (README warns against production use) and actual deployment configurations (production configs use OnDiskStorage) combined with inadequate config validation (sanitizer doesn't block it). The missing `fsync()` violates the explicit contract stated in `PersistentSafetyStorage` documentation that "Any set function is expected to sync to the remote system before returning."

### Citations

**File:** secure/storage/src/on_disk.rs (L64-70)
```rust
    fn write(&self, data: &HashMap<String, Value>) -> Result<(), Error> {
        let contents = serde_json::to_vec(data)?;
        let mut file = File::create(self.temp_path.path())?;
        file.write_all(&contents)?;
        fs::rename(&self.temp_path, &self.file_path)?;
        Ok(())
    }
```

**File:** consensus/safety-rules/src/persistent_safety_storage.rs (L16-18)
```rust
/// SafetyRules needs an abstract storage interface to act as a common utility for storing
/// persistent data to local disk, cloud, secrets managers, or even memory (for tests)
/// Any set function is expected to sync to the remote system before returning.
```

**File:** consensus/consensus-types/src/safety_data.rs (L8-21)
```rust
/// Data structure for safety rules to ensure consensus safety.
#[derive(Debug, Deserialize, Eq, PartialEq, Serialize, Clone, Default)]
pub struct SafetyData {
    pub epoch: u64,
    pub last_voted_round: u64,
    // highest 2-chain round, used for 3-chain
    pub preferred_round: u64,
    // highest 1-chain round, used for 2-chain
    #[serde(default)]
    pub one_chain_round: u64,
    pub last_vote: Option<Vote>,
    #[serde(default)]
    pub highest_timeout_round: u64,
}
```

**File:** secure/storage/README.md (L37-42)
```markdown
- `OnDisk`: Similar to InMemory, the OnDisk secure storage implementation provides another
useful testing implementation: an on-disk storage engine, where the storage backend is
implemented using a single file written to local disk. In a similar fashion to the in-memory
storage, on-disk should not be used in production environments as it provides no security
guarantees (e.g., encryption before writing to disk). Moreover, OnDisk storage does not
currently support concurrent data accesses.
```

**File:** docker/compose/aptos-node/validator.yaml (L11-13)
```yaml
    backend:
      type: "on_disk_storage"
      path: secure-data.json
```

**File:** terraform/helm/aptos-node/files/configs/validator-base.yaml (L14-16)
```yaml
    backend:
      type: "on_disk_storage"
      path: secure-data.json
```

**File:** consensus/safety-rules/src/safety_rules.rs (L213-232)
```rust
    pub(crate) fn verify_and_update_last_vote_round(
        &self,
        round: Round,
        safety_data: &mut SafetyData,
    ) -> Result<(), Error> {
        if round <= safety_data.last_voted_round {
            return Err(Error::IncorrectLastVotedRound(
                round,
                safety_data.last_voted_round,
            ));
        }

        safety_data.last_voted_round = round;
        trace!(
            SafetyLogSchema::new(LogEntry::LastVotedRound, LogEvent::Update)
                .last_voted_round(safety_data.last_voted_round)
        );

        Ok(())
    }
```

**File:** config/src/config/safety_rules_config.rs (L85-96)
```rust
        if let Some(chain_id) = chain_id {
            // Verify that the secure backend is appropriate for mainnet validators
            if chain_id.is_mainnet()
                && node_type.is_validator()
                && safety_rules_config.backend.is_in_memory()
            {
                return Err(Error::ConfigSanitizerFailed(
                    sanitizer_name,
                    "The secure backend should not be set to in memory storage in mainnet!"
                        .to_string(),
                ));
            }
```

**File:** config/src/config/secure_backend_config.rs (L45-48)
```rust
    /// Returns true iff the backend is in memory
    pub fn is_in_memory(&self) -> bool {
        matches!(self, SecureBackend::InMemoryStorage)
    }
```

**File:** ecosystem/indexer-grpc/indexer-grpc-table-info/src/backup_restore/gcs.rs (L300-300)
```rust
                temp_file.sync_all().await?;
```
