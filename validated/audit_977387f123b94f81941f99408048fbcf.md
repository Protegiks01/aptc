# Audit Report

## Title
Memory Exhaustion via Decompression Size Limit Bypass in State Sync Data Client

## Summary
The Aptos data client's `max_response_bytes` limit can be bypassed by malicious peers sending compressed responses that decompress to sizes exceeding the requested limit. While clients request data bounded by 20 MiB, decompression validates against ~61.875 MiB, allowing 3x memory allocation and potential validator node slowdowns or crashes.

## Finding Description

The vulnerability exploits a mismatch between the client-requested size limit and the decompression validation limit:

**Client Configuration**: The data client configures `max_response_bytes` to 20 MiB (CLIENT_MAX_MESSAGE_SIZE_V2), which honest servers respect when preparing uncompressed responses. [1](#0-0) [2](#0-1) 

**Request Structure**: V2 transaction data requests include the `max_response_bytes` field to communicate size limits to servers. [3](#0-2) 

**Server Enforcement**: Honest servers use `ResponseDataProgressTracker` to check serialized (uncompressed) data size against `max_response_bytes` before compression, ensuring compliance with client-requested limits.

**Decompression Bypass**: When receiving compressed responses, the client decompresses using `MAX_APPLICATION_MESSAGE_SIZE` (~61.875 MiB) as the size limit instead of the requested `max_response_bytes` (20 MiB). [4](#0-3) [5](#0-4) 

**Size Validation in Decompression**: The decompression library validates the LZ4 header size against `max_size`, but this parameter is set to `MAX_APPLICATION_MESSAGE_SIZE`, not the client's requested limit. [6](#0-5) 

**Missing Post-Decompression Check**: The client validates compression format compliance but never verifies that decompressed response size matches the originally requested `max_response_bytes`. [7](#0-6) 

**Attack Path**: A malicious peer can:
1. Receive a client request with `max_response_bytes = 20 MiB` and `use_compression = true`
2. Create a `DataResponse` with 60 MiB of serialized data (below MAX_APPLICATION_MESSAGE_SIZE)
3. Compress and send the response
4. Client decompresses using the 61.875 MiB limit
5. Client allocates 60 MiB instead of the expected 20 MiB

## Impact Explanation

**Severity: High** (up to $50,000 per Aptos Bug Bounty Program)

This qualifies as **Validator Node Slowdowns** under the High severity category:

1. **Memory Exhaustion**: With MAX_CONCURRENT_REQUESTS = 6, a syncing node expecting 120 MiB (6 × 20 MiB) could allocate 360 MiB (6 × 60 MiB), consuming 3x expected memory. [8](#0-7) 

2. **Resource Exhaustion Attacks**: Repeated exploitation can exhaust available memory on resource-constrained nodes, causing out-of-memory errors and node crashes.

3. **State Sync Disruption**: Validators and fullnodes attempting to sync can be targeted, degrading network synchronization performance and potentially preventing new nodes from joining.

4. **Compression Default Configuration**: The attack surface is always present since compression is enabled by default. [9](#0-8) 

## Likelihood Explanation

**Likelihood: Medium to High**

The attack is feasible because:

1. **Low Attacker Requirements**: Any party can run a malicious peer advertising storage service availability. No validator privileges, staked tokens, or governance participation required.

2. **Peer Selection Exposure**: The data client's peer selection mechanism chooses from available peers based on priority and latency metrics. A malicious peer with favorable metrics can be selected for data serving.

3. **Default Attack Surface**: Compression is enabled by default (`use_compression: true`), making this exploitable on all standard configurations without requiring special client settings.

4. **No Detection Mechanism**: The client has no validation to detect when decompressed response size exceeds the requested limit, allowing silent memory over-allocation.

## Recommendation

Implement post-decompression size validation in the data client:

1. **Track Requested Limit**: Store the requested `max_response_bytes` value when sending requests
2. **Validate After Decompression**: After calling `get_data_response()`, verify the decompressed size doesn't exceed the originally requested limit
3. **Reject Oversized Responses**: Return an error if decompressed size exceeds `max_response_bytes`, and penalize the peer's reputation score
4. **Alternative**: Pass the client's `max_response_bytes` to the decompression function instead of using `MAX_APPLICATION_MESSAGE_SIZE`

Example fix location in `state-sync/aptos-data-client/src/client.rs` after line 753:
- Add validation comparing decompressed response size against the original request's `max_response_bytes`
- Report malicious peers via `response_callback.notify_bad_response()` for violations

## Proof of Concept

A complete PoC would require:
1. Setting up a malicious storage service peer that ignores `max_response_bytes`
2. Creating oversized `DataResponse` objects (40-60 MiB) 
3. Compressing and serving these to syncing clients
4. Monitoring client memory allocation to confirm 3x over-allocation
5. Demonstrating cumulative impact with concurrent requests

The vulnerability can be triggered by any malicious peer without requiring consensus participation, validator keys, or stake.

---

**Notes**: 

This vulnerability exploits a protocol-level size validation gap rather than network flooding, distinguishing it from out-of-scope "Network DoS attacks". The impact falls under application-level resource exhaustion causing validator performance degradation, which is explicitly covered under "Validator Node Slowdowns (High)" in the Aptos Bug Bounty Program.

The core issue is that client size limits are advisory to honest servers but not enforced on received data, creating a trust boundary violation where malicious peers can cause resource exhaustion attacks.

### Citations

**File:** config/src/config/state_sync_config.rs (L20-20)
```rust
const CLIENT_MAX_MESSAGE_SIZE_V2: usize = 20 * 1024 * 1024; // 20 MiB (used for v2 data requests)
```

**File:** config/src/config/state_sync_config.rs (L30-30)
```rust
const MAX_CONCURRENT_REQUESTS: u64 = 6;
```

**File:** config/src/config/state_sync_config.rs (L472-472)
```rust
            max_response_bytes: CLIENT_MAX_MESSAGE_SIZE_V2 as u64,
```

**File:** config/src/config/state_sync_config.rs (L482-482)
```rust
            use_compression: true,
```

**File:** state-sync/storage-service/types/src/requests.rs (L425-431)
```rust
pub struct GetTransactionDataWithProofRequest {
    pub transaction_data_request_type: TransactionDataRequestType, // The type of transaction data to request
    pub proof_version: u64,      // The version the proof should be relative to
    pub start_version: u64,      // The starting version of the data
    pub end_version: u64,        // The ending version of the data (inclusive)
    pub max_response_bytes: u64, // The max number of bytes to return in the response
}
```

**File:** config/src/config/network_config.rs (L47-48)
```rust
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
```

**File:** state-sync/storage-service/types/src/responses.rs (L99-104)
```rust
            StorageServiceResponse::CompressedResponse(_, compressed_data) => {
                let raw_data = aptos_compression::decompress(
                    compressed_data,
                    CompressionClient::StateSync,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )?;
```

**File:** crates/aptos-compression/src/lib.rs (L150-184)
```rust
fn get_decompressed_size(
    compressed_data: &CompressedData,
    max_size: usize,
) -> Result<usize, Error> {
    // Ensure that the compressed data is at least 4 bytes long
    if compressed_data.len() < 4 {
        return Err(DecompressionError(format!(
            "Compressed data must be at least 4 bytes long! Got: {}",
            compressed_data.len()
        )));
    }

    // Parse the size prefix
    let size = (compressed_data[0] as i32)
        | ((compressed_data[1] as i32) << 8)
        | ((compressed_data[2] as i32) << 16)
        | ((compressed_data[3] as i32) << 24);
    if size < 0 {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer must not be negative! Got: {}",
            size
        )));
    }

    // Ensure that the size is not greater than the max size limit
    let size = size as usize;
    if size > max_size {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer is too big: {} > {}",
            size, max_size
        )));
    }

    Ok(size)
}
```

**File:** state-sync/aptos-data-client/src/client.rs (L736-766)
```rust
        // Ensure the response obeys the compression requirements
        let (context, storage_response) = storage_response.into_parts();
        if request.use_compression && !storage_response.is_compressed() {
            return Err(Error::InvalidResponse(format!(
                "Requested compressed data, but the response was uncompressed! Response: {:?}",
                storage_response.get_label()
            )));
        } else if !request.use_compression && storage_response.is_compressed() {
            return Err(Error::InvalidResponse(format!(
                "Requested uncompressed data, but the response was compressed! Response: {:?}",
                storage_response.get_label()
            )));
        }

        // Try to convert the storage service enum into the exact variant we're expecting.
        // We do this using spawn_blocking because it involves serde and compression.
        tokio::task::spawn_blocking(move || {
            match T::try_from(storage_response) {
                Ok(new_payload) => Ok(Response::new(context, new_payload)),
                // If the variant doesn't match what we're expecting, report the issue
                Err(err) => {
                    context
                        .response_callback
                        .notify_bad_response(ResponseError::InvalidPayloadDataType);
                    Err(err.into())
                },
            }
        })
        .await
        .map_err(|error| Error::UnexpectedErrorEncountered(error.to_string()))?
    }
```
