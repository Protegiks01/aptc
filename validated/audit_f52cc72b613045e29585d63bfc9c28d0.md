# Audit Report

## Title
Unbounded Batch Size in State KV Shard Pruner Recovery Causes Node Unrecoverability After Crash

## Summary
The state KV pruner's crash recovery mechanism in sharded mode attempts to catch up arbitrarily large version gaps in a single atomic transaction without batching, potentially causing memory exhaustion, extremely long startup times, or infinite crash loops that render a node unrecoverable.

## Finding Description

The state KV pruner in sharded mode uses a two-phase pruning approach that creates a critical vulnerability during crash recovery.

**Normal Operation Flow:**

During normal pruning, the system processes in configurable batches with a default of 5,000 versions. [1](#0-0) 

The batching loop in normal operation limits processing to max_versions per iteration. [2](#0-1) 

**The Critical Flaw:**

In sharded mode, the metadata pruner only iterates through entries to verify them but does NOT delete any data. [3](#0-2) 

It only commits the global progress marker. [4](#0-3) 

The actual deletions are performed by shard pruners in parallel. If a crash occurs after the metadata progress is committed but before all shards complete, the global progress becomes ahead of individual shard progress.

**Recovery Mechanism Vulnerability:**

During recovery, each shard attempts to catch up by calling prune() with the entire version gap. [5](#0-4) 

The critical vulnerability is that StateKvShardPruner::prune() operates on the ENTIRE gap without any internal batching. It iterates through all stale entries and adds ALL deletions to a single SchemaBatch before committing atomically. [6](#0-5) 

**Contrast with StateMerkleShardPruner:**

The state merkle shard pruner has internal batching protection via a loop that processes chunks. [7](#0-6) 

StateKvShardPruner lacks this protection entirely.

**No Size Limits on SchemaBatch:**

SchemaBatch is simply a HashMap that grows unbounded with no size limits. [8](#0-7)  The raw_put and raw_delete methods simply push to the HashMap without any size checks. [9](#0-8) 

## Impact Explanation

This qualifies as **High Severity** under the Aptos bug bounty criteria:

1. **Validator Node Slowdowns/Crashes**: Attempting to build a batch with hundreds of thousands of delete operations can exhaust memory (OOM), causing immediate crash, block node startup for extended periods, or create infinite crash loops if recovery repeatedly fails.

2. **Node Unrecoverability**: If the version gap is sufficiently large (e.g., millions of versions from extended downtime), the node may become permanently unable to restart without manual intervention (disabling pruning, manual database repair, or full resync).

3. **Network Availability Impact**: If multiple validators experience simultaneous crashes during active pruning, the network could experience reduced validator participation, affecting liveness.

This meets the HIGH severity category for "Validator Node Slowdowns" with potential escalation to node unrecoverability.

## Likelihood Explanation

**Likelihood: Medium-High**

This vulnerability has high likelihood because:

1. **Natural Trigger**: Requires only a crash during normal pruning operationsâ€”no malicious actor needed. Validator nodes can crash due to hardware failures, OOM from other operations, software bugs, or network partitions.

2. **Active Pruning is Default**: Most production nodes enable pruning (default configuration) to manage disk space. [10](#0-9) 

3. **Growing Gap Probability**: The longer a node remains down after a crash during pruning, the larger the version gap becomes. For high-throughput chains, gaps can reach millions of versions.

4. **Cascading Failures**: If the first recovery attempt causes OOM and crashes again, the node enters an infinite loop where each restart attempt fails.

## Recommendation

Add internal batching to StateKvShardPruner::prune() similar to StateMerkleShardPruner. The method should:

1. Accept a `max_entries_per_batch` parameter
2. Process deletions in a loop, creating new SchemaBatch for each iteration
3. Only update progress metadata when all batches complete
4. Break large version gaps into manageable chunks (e.g., 10,000 entries per batch)

This ensures recovery from large gaps remains bounded and won't exhaust memory.

## Proof of Concept

A proof of concept would involve:
1. Starting a node with sharded state KV pruner enabled
2. During active pruning, killing the process after metadata progress commits but before shard pruners complete
3. Restarting the node and observing memory exhaustion or extremely long startup times during StateKvShardPruner::new()

The vulnerability can be triggered naturally without requiring specific malicious inputs, as it only depends on timing of a crash relative to the two-phase pruning process.

## Notes

This vulnerability demonstrates a critical design inconsistency: StateMerkleShardPruner correctly implements internal batching for recovery scenarios, while StateKvShardPruner does not. The contrast between these two implementations confirms this is an oversight rather than intentional design. The unbounded growth of SchemaBatch during recovery poses a real operational risk to validator availability.

### Citations

**File:** config/src/config/storage_config.rs (L390-390)
```rust
            enable: true,
```

**File:** config/src/config/storage_config.rs (L392-392)
```rust
            batch_size: 5_000,
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/mod.rs (L55-57)
```rust
        while progress < target_version {
            let current_batch_target_version =
                min(progress + max_versions as Version, target_version);
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L35-50)
```rust
        if self.state_kv_db.enabled_sharding() {
            let num_shards = self.state_kv_db.num_shards();
            // NOTE: This can be done in parallel if it becomes the bottleneck.
            for shard_id in 0..num_shards {
                let mut iter = self
                    .state_kv_db
                    .db_shard(shard_id)
                    .iter::<StaleStateValueIndexByKeyHashSchema>()?;
                iter.seek(&current_progress)?;
                for item in iter {
                    let (index, _) = item?;
                    if index.stale_since_version > target_version {
                        break;
                    }
                }
            }
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs (L67-72)
```rust
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;

        self.state_kv_db.metadata_db().write_schemas(batch)
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L37-42)
```rust
        info!(
            progress = progress,
            metadata_progress = metadata_progress,
            "Catching up state kv shard {shard_id}."
        );
        myself.prune(progress, metadata_progress)?;
```

**File:** storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs (L47-72)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
    ) -> Result<()> {
        let mut batch = SchemaBatch::new();

        let mut iter = self
            .db_shard
            .iter::<StaleStateValueIndexByKeyHashSchema>()?;
        iter.seek(&current_progress)?;
        for item in iter {
            let (index, _) = item?;
            if index.stale_since_version > target_version {
                break;
            }
            batch.delete::<StaleStateValueIndexByKeyHashSchema>(&index)?;
            batch.delete::<StateValueByKeyHashSchema>(&(index.state_key_hash, index.version))?;
        }
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::StateKvShardPrunerProgress(self.shard_id),
            &DbMetadataValue::Version(target_version),
        )?;

        self.db_shard.write_schemas(batch)
    }
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_shard_pruner.rs (L58-100)
```rust
    pub(in crate::pruner) fn prune(
        &self,
        current_progress: Version,
        target_version: Version,
        max_nodes_to_prune: usize,
    ) -> Result<()> {
        loop {
            let mut batch = SchemaBatch::new();
            let (indices, next_version) = StateMerklePruner::get_stale_node_indices(
                &self.db_shard,
                current_progress,
                target_version,
                max_nodes_to_prune,
            )?;

            indices.into_iter().try_for_each(|index| {
                batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
                batch.delete::<S>(&index)
            })?;

            let mut done = true;
            if let Some(next_version) = next_version {
                if next_version <= target_version {
                    done = false;
                }
            }

            if done {
                batch.put::<DbMetadataSchema>(
                    &S::progress_metadata_key(Some(self.shard_id)),
                    &DbMetadataValue::Version(target_version),
                )?;
            }

            self.db_shard.write_schemas(batch)?;

            if done {
                break;
            }
        }

        Ok(())
    }
```

**File:** storage/schemadb/src/batch.rs (L131-131)
```rust
    rows: DropHelper<HashMap<ColumnFamilyName, Vec<WriteOp>>>,
```

**File:** storage/schemadb/src/batch.rs (L156-172)
```rust
    fn raw_put(&mut self, cf_name: ColumnFamilyName, key: Vec<u8>, value: Vec<u8>) -> DbResult<()> {
        self.rows
            .entry(cf_name)
            .or_default()
            .push(WriteOp::Value { key, value });

        Ok(())
    }

    fn raw_delete(&mut self, cf_name: ColumnFamilyName, key: Vec<u8>) -> DbResult<()> {
        self.rows
            .entry(cf_name)
            .or_default()
            .push(WriteOp::Deletion { key });

        Ok(())
    }
```
