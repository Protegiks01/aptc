# Audit Report

## Title
DAG Consensus Parent Digest Verification Bypass Enables Byzantine Validators to Inject Equivocating Nodes and Cause Consensus Split

## Summary
The DAG consensus implementation fails to verify that fetched parent nodes match the digest specified in node certificates. When honest validators fetch missing parents from Byzantine responders, the Byzantine validator can provide a different valid certified node (equivocation) with the same (round, author) but different digest. This allows Byzantine validators to cause different honest validators to store different versions of the DAG, breaking consensus safety and potentially causing a chain split.

## Finding Description

The vulnerability exists in the intersection of three components in the DAG consensus fetch mechanism:

**1. Responder Selection for Uncertified Nodes:**

When an honest validator receives an uncertified `Node` with missing parents, the responders list contains only the author of that node. [1](#0-0) 

If the author is Byzantine, they become the sole responder, giving them complete control over which parent nodes are provided during the fetch process.

**2. Missing Digest Verification in Fetch Response:**

When the fetch response is received and verified, the system checks that returned nodes match the requested bitmask (round, author) and have valid quorum signatures, but critically fails to verify that the node's digest matches the digest in the request's targets. [2](#0-1) 

The verification only checks that nodes are at positions not in the exists_bitmask and that certified nodes have valid signatures, completely ignoring whether the digest field in the returned nodes matches the digest specified in `NodeMetadata` targets.

**3. DAG Store Uses Only (Round, Author) for Existence Check:**

When validating that a node's parents exist in the DAG, the system looks up nodes by (round, author) only, ignoring the digest specified in the parent certificate. [3](#0-2) 

The `exists()` method calls `get_node_ref_by_metadata()` which in turn calls `get_node_ref(round, author)`, performing lookups solely based on round and author while ignoring the digest field.

**4. Parent Validation Relies on Flawed Existence Check:**

When a new node is added to the DAG, the validation only checks that parents exist using the flawed existence check. [4](#0-3) 

This means if a Byzantine validator provides a different node with the same (round, author) but different digest than what the parent certificate specifies, it will still pass validation.

**5. Reachability Traversal Creates Consensus Divergence:**

The reachability traversal used for ordering adds parent certificate digests to the reachable set, but checks actual stored node digests when filtering. [5](#0-4) 

When different validators store different nodes at the same (round, author) position, they compute different reachable sets, leading to different block orderings and consensus divergence.

**Attack Path:**

1. Byzantine validator B equivocates at round R-1, creating two different nodes P and P' for the same (round, author)
2. B gets both P and P' certified by different quorums (possible when n > 3f+1)
3. B creates node N at round R with parent certificate referencing P (digest D1)
4. B broadcasts uncertified N to honest validators H1 and H2
5. H1 and H2 check parent existence - P with digest D1 is missing
6. H1 and H2 create `RemoteFetchRequest` with targets containing NodeMetadata for P (digest D1)
7. Since N is uncertified, responders = [B] (only the author)
8. When H1 requests from B, B maliciously responds with P' (digest D2 â‰  D1)
9. `FetchResponse::verify` checks bitmask position and signatures but not digest matching
10. H1 accepts P' and stores it at position (R-1, author) with digest D2
11. H2 might receive P or P' depending on B's response
12. Later when validating N, `exists(parent.metadata())` looks up by (round, author), finds P' (even though digest doesn't match D1)
13. N is accepted with parent certificate digest D1 pointing to stored node with digest D2
14. When computing reachable nodes for ordering, H1 adds D1 to reachable set but finds node with D2, causing traversal mismatch
15. Different honest validators compute different reachable sets, leading to different orderings and consensus split

## Impact Explanation

This is a **Critical** severity vulnerability under the Aptos bug bounty criteria for Consensus/Safety Violations:

**Consensus Safety Violation:** The attack breaks the fundamental consensus safety guarantee that all honest validators maintain the same ledger state. By causing different honest validators to store different parent nodes in their DAGs, Byzantine validators create divergent views of the consensus history. When the reachability traversal is used for ordering, different validators compute different reachable sets from the same anchor, leading to different block orderings and potentially different committed blocks - a chain split.

**Impact on Invariants:**
- Violates **Consensus Safety**: AptosBFT must prevent chain splits under < 1/3 Byzantine validators, but this vulnerability enables splits with f < n/3 Byzantine nodes
- Violates **Deterministic Execution**: Validators produce different state roots for what should be identical consensus history

**Scope:** Affects all nodes running DAG consensus. Can lead to non-recoverable network partition requiring manual intervention or hard fork to resolve.

## Likelihood Explanation

**Likelihood: High**

**Attacker Requirements:**
- Control of f Byzantine validators where f < n/3 (within BFT threat model)
- Ability to create equivocating nodes and get them certified
- Network positioning to control message delivery to different honest validators

**Feasibility:**

The attack is highly practical because:

1. **Responder Control**: The responder selection for uncertified nodes gives Byzantine authors sole control over fetch responses with no fallback mechanism
2. **Equivocation Feasibility**: Equivocation is possible when n > 3f+1 (more than minimum honest validators), which is the common operational case for network redundancy
3. **Systematic Vulnerability**: The digest verification gap is not a race condition or timing issue but a systematic missing check in the validation pipeline
4. **No Additional Requirements**: No collusion beyond being Byzantine validator, no infrastructure attacks, no cryptographic breaks needed

**Constraints:**
- Requires n > 3f+1 to get both equivocations certified by different quorums
- Byzantine validator must be the author of nodes whose parents are being fetched

## Recommendation

Add digest verification to `FetchResponse::verify()` to ensure fetched nodes match the digest specified in request targets:

```rust
pub fn verify(
    self,
    request: &RemoteFetchRequest,
    validator_verifier: &ValidatorVerifier,
) -> anyhow::Result<Self> {
    // Create a map of expected (round, author) -> digest from request targets
    let expected_digests: HashMap<(Round, Author), HashValue> = request
        .targets()
        .map(|metadata| ((metadata.round(), *metadata.author()), *metadata.digest()))
        .collect();
    
    ensure!(
        self.certified_nodes.iter().all(|node| {
            let round = node.round();
            let author = node.author();
            if let Some(author_idx) =
                validator_verifier.address_to_validator_index().get(author)
            {
                // Check bitmask
                let bitmask_ok = !request.exists_bitmask.has(round, *author_idx);
                // Check digest matches expected
                let digest_ok = expected_digests
                    .get(&(round, *author))
                    .map(|expected| expected == &node.digest())
                    .unwrap_or(true); // If not in targets, allow (for transitive fetches)
                bitmask_ok && digest_ok
            } else {
                false
            }
        }),
        "nodes don't match requested bitmask or digest"
    );
    ensure!(
        self.certified_nodes
            .iter()
            .all(|node| node.verify(validator_verifier).is_ok()),
        "unable to verify certified nodes"
    );

    Ok(self)
}
```

Additionally, consider adding a digest verification in the DAG store's `exists()` method or at the point where parent certificates are validated against stored nodes.

## Proof of Concept

A proof of concept would require setting up a test environment with:

1. Multiple validators (n=5, f=1) to enable equivocation with different quorums
2. Byzantine validator that creates two different certified nodes P and P' at the same (round, author)
3. Byzantine validator broadcasts uncertified node N referencing P to honest validators
4. Byzantine validator responds with P' when honest validators fetch missing parent P
5. Verification that different honest validators store different nodes at the same position
6. Demonstration that reachability traversal produces different results, causing ordering divergence

The test would verify that the FetchResponse::verify method accepts nodes with mismatched digests and that the DAG store's existence check passes despite digest mismatches, ultimately leading to consensus divergence.

---

**Notes:**

This vulnerability represents a fundamental flaw in the DAG consensus parent verification mechanism. The digest field in `NodeMetadata` within parent certificates is meant to uniquely identify parent nodes, but this constraint is not enforced during the fetch process. The combination of single-responder selection for uncertified nodes, missing digest verification in fetch responses, and digest-agnostic existence checks creates a exploitable path for Byzantine validators to inject equivocating nodes into honest validators' DAGs, breaking consensus safety guarantees.

### Citations

**File:** consensus/src/dag/dag_fetcher.rs (L105-112)
```rust
    pub fn responders(&self, validators: &[Author]) -> Vec<Author> {
        match self {
            LocalFetchRequest::Node(node, _) => vec![*node.author()],
            LocalFetchRequest::CertifiedNode(node, _) => {
                node.signatures().get_signers_addresses(validators)
            },
        }
    }
```

**File:** consensus/src/dag/types.rs (L750-777)
```rust
    pub fn verify(
        self,
        request: &RemoteFetchRequest,
        validator_verifier: &ValidatorVerifier,
    ) -> anyhow::Result<Self> {
        ensure!(
            self.certified_nodes.iter().all(|node| {
                let round = node.round();
                let author = node.author();
                if let Some(author_idx) =
                    validator_verifier.address_to_validator_index().get(author)
                {
                    !request.exists_bitmask.has(round, *author_idx)
                } else {
                    false
                }
            }),
            "nodes don't match requested bitmask"
        );
        ensure!(
            self.certified_nodes
                .iter()
                .all(|node| node.verify(validator_verifier).is_ok()),
            "unable to verify certified nodes"
        );

        Ok(self)
    }
```

**File:** consensus/src/dag/dag_store.rs (L154-156)
```rust
            for parent in node.parents() {
                ensure!(self.exists(parent.metadata()), "parent not exist");
            }
```

**File:** consensus/src/dag/dag_store.rs (L199-229)
```rust
    pub fn exists(&self, metadata: &NodeMetadata) -> bool {
        self.get_node_ref_by_metadata(metadata).is_some()
    }

    pub fn all_exists<'a>(&self, nodes: impl Iterator<Item = &'a NodeMetadata>) -> bool {
        self.filter_missing(nodes).next().is_none()
    }

    pub fn all_exists_by_round_author<'a>(
        &self,
        mut nodes: impl Iterator<Item = &'a (Round, Author)>,
    ) -> bool {
        nodes.all(|(round, author)| self.get_node_ref(*round, author).is_some())
    }

    pub fn filter_missing<'a, 'b>(
        &'b self,
        nodes: impl Iterator<Item = &'a NodeMetadata> + 'b,
    ) -> impl Iterator<Item = &'a NodeMetadata> + 'b {
        nodes.filter(|node_metadata| !self.exists(node_metadata))
    }

    fn get_node_ref_by_metadata(&self, metadata: &NodeMetadata) -> Option<&NodeStatus> {
        self.get_node_ref(metadata.round(), metadata.author())
    }

    pub fn get_node_ref(&self, round: Round, author: &Author) -> Option<&NodeStatus> {
        let index = self.author_to_index.get(author)?;
        let round_ref = self.nodes_by_round.get(&round)?;
        round_ref[*index].as_ref()
    }
```

**File:** consensus/src/dag/dag_store.rs (L288-344)
```rust
    fn reachable_filter(start: Vec<HashValue>) -> impl FnMut(&Arc<CertifiedNode>) -> bool {
        let mut reachable: HashSet<HashValue> = HashSet::from_iter(start);
        move |node| {
            if reachable.contains(&node.digest()) {
                for parent in node.parents() {
                    reachable.insert(*parent.metadata().digest());
                }
                true
            } else {
                false
            }
        }
    }

    pub fn reachable_mut(
        &mut self,
        from: &Arc<CertifiedNode>,
        until: Option<Round>,
    ) -> impl Iterator<Item = &mut NodeStatus> + use<'_> {
        let until = until.unwrap_or(self.lowest_round());
        let mut reachable_filter = Self::reachable_filter(vec![from.digest()]);
        self.nodes_by_round
            .range_mut(until..=from.round())
            .rev()
            .flat_map(|(_, round_ref)| round_ref.iter_mut())
            .flatten()
            .filter(move |node_status| {
                matches!(node_status, NodeStatus::Unordered { .. })
                    && reachable_filter(node_status.as_node())
            })
    }

    pub fn reachable<'a>(
        &self,
        targets: impl Iterator<Item = &'a NodeMetadata> + Clone,
        until: Option<Round>,
        // TODO: replace filter with bool to filter unordered
        filter: impl Fn(&NodeStatus) -> bool,
    ) -> impl Iterator<Item = &NodeStatus> {
        let until = until.unwrap_or(self.lowest_round());
        let initial_round = targets
            .clone()
            .map(|t| t.round())
            .max()
            .expect("Round should be not empty!");
        let initial = targets.map(|t| *t.digest()).collect();

        let mut reachable_filter = Self::reachable_filter(initial);
        self.nodes_by_round
            .range(until..=initial_round)
            .rev()
            .flat_map(|(_, round_ref)| round_ref.iter())
            .flatten()
            .filter(move |node_status| {
                filter(node_status) && reachable_filter(node_status.as_node())
            })
    }
```
