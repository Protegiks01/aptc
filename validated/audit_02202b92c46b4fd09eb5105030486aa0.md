# Audit Report

## Title
Asymmetric Network Partition via Health Checker Single-Counter Design Leading to Inconsistent Peer Graphs

## Summary
The health checker uses a single failure counter per peer that is reset by inbound pings and incremented by outbound ping failures. Under asymmetric network conditions (where B→A works but A→B is broken), Node A's failure counter for B never accumulates because B's successful inbound pings continuously reset it, preventing A from ever disconnecting from B even though the outbound path is broken. This creates inconsistent peer graphs where B has disconnected from A but A still considers B connected, causing validator slowdowns due to timeouts on messages sent to disconnected peers.

## Finding Description

The vulnerability exists in the health checker's failure tracking design. The health checker maintains a single `failures` counter per peer in the `HealthCheckData` structure. [1](#0-0) 

When Node A receives an inbound ping from Node B in `handle_ping_request()`, it immediately resets B's failure counter to 0 before sending the pong response. [2](#0-1) 

The `reset_peer_failures()` function unconditionally sets the failure counter to 0. [3](#0-2) 

Meanwhile, when Node A's outbound pings to Node B fail, the failure counter is incremented. [4](#0-3) 

The disconnect logic only triggers when failures exceed the threshold (default: 3). [5](#0-4) 

**Under asymmetric network conditions:**
- Path B→A works: B can send pings to A
- Path A→B is broken: A's messages don't reach B

**Result:**
1. A sends outbound pings to B → timeout → failure counter increments (0→1)
2. B sends inbound pings to A → A receives them, resets B's failure counter (1→0), sends pong → pong doesn't reach B
3. B's outbound pings to A timeout → B's failure counter for A increments
4. After 3 failures (with default configuration [6](#0-5) ), B disconnects from A
5. A's failure counter for B never accumulates past threshold because inbound pings keep resetting it
6. A never disconnects from B despite broken outbound path

This creates asymmetric disconnection where B has sent `ConnectionNotification::LostPeer` but A still has B in its `health_check_data` and considers B connected. [7](#0-6) 

Existing tests validate that successful pings reset failure counters [8](#0-7) , but no test covers the asymmetric network scenario.

## Impact Explanation

This qualifies as **High Severity** per Aptos Bug Bounty criteria for "Validator Node Slowdowns: Significant performance degradation affecting consensus."

When Node A believes it's connected to Node B (but B has disconnected from A):
1. A attempts to send consensus messages to B
2. These messages timeout (20-second default timeout)
3. A experiences increased latency and retry overhead
4. Multiple such asymmetric partitions across validators cause cumulative performance degradation
5. Different nodes have inconsistent views of network topology, violating the health checker's design guarantee of maintaining consistent bidirectional connectivity

This does not cause complete consensus failure (which would be Critical severity), but causes significant performance degradation affecting consensus timing, retry overhead, and resource utilization - qualifying as High severity validator slowdown.

## Likelihood Explanation

**Likelihood: HIGH**

Asymmetric network conditions occur naturally in distributed systems due to:
1. **Asymmetric routing**: One direction degrades before the other due to congestion or hardware failures
2. **Load-based asymmetry**: Heavy load on one node affects outbound capacity while inbound still works
3. **NAT/Firewall misconfigurations**: Stateful firewalls may allow inbound responses but block outbound initiations
4. **Geographic distribution**: Global validators experience asymmetric latency patterns

The vulnerability is deterministic once these conditions exist - with 10-second ping intervals and 3 failure tolerance, asymmetric partitions establish within 30-40 seconds of asymmetric network degradation. No attacker action is required; this manifests under normal network conditions.

## Recommendation

Implement separate tracking for inbound and outbound connectivity health:

1. **Separate counters**: Track `outbound_failures` and `inbound_failures` independently in `HealthCheckData`
2. **Bidirectional requirement**: Only consider a peer healthy if BOTH directions are working
3. **Disconnect on either failure**: Disconnect if either outbound or inbound failures exceed threshold
4. **Alternative approach**: Don't reset outbound failure counters based on inbound ping success - only reset when outbound pings succeed

The health checker's comment at line 18 lists "Use successful inbound pings as a sign of remote note being healthy" as future work, but this is already implemented and creates the vulnerability. The implementation should be revised to track bidirectional health correctly.

## Proof of Concept

The vulnerability can be reproduced by simulating asymmetric network conditions in the health checker test harness:

1. Create two health checkers A and B
2. Simulate B→A path working: B sends pings to A, A receives and responds
3. Simulate A→B path broken: Drop all messages from A to B (including pongs)
4. Observe A's failure counter for B gets incremented on outbound ping timeouts
5. Observe A's failure counter for B gets reset to 0 on inbound ping receipt
6. After 3 rounds, B disconnects from A (B's outbound pings timeout consistently)
7. A never disconnects from B (A's failure counter never exceeds threshold)
8. Result: Inconsistent peer graphs where B has disconnected but A still considers B connected

**Notes**

This is a protocol design flaw in the health checker's use of a single failure counter per peer, not a network attack. The health checker is designed to detect unhealthy peers, but its current implementation fails to correctly detect asymmetric network failures - a condition that occurs naturally in distributed systems. The vulnerability causes validator performance degradation through message timeouts and retry overhead, meeting the High severity threshold for "Validator Node Slowdowns" in the Aptos bug bounty criteria.

### Citations

**File:** network/framework/src/protocols/health_checker/interface.rs (L26-36)
```rust
#[derive(Clone, Copy, Default, Debug, Eq, PartialEq)]
pub struct HealthCheckData {
    pub round: u64,
    pub failures: u64,
}

impl HealthCheckData {
    pub fn new(round: u64) -> Self {
        HealthCheckData { round, failures: 0 }
    }
}
```

**File:** network/framework/src/protocols/health_checker/interface.rs (L118-124)
```rust
    /// Resets the number of peer failures for the given peer.
    /// If the peer is not found, nothing is done.
    pub fn reset_peer_failures(&mut self, peer_id: PeerId) {
        if let Some(health_check_data) = self.health_check_data.write().get_mut(&peer_id) {
            health_check_data.failures = 0;
        }
    }
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L209-228)
```rust
                conn_event = connection_events.select_next_some() => {
                    match conn_event {
                        ConnectionNotification::NewPeer(metadata, network_id) => {
                            // PeersAndMetadata is a global singleton across all networks; filter connect/disconnect events to the NetworkId that this HealthChecker instance is watching
                            if network_id == self_network_id {
                                self.network_interface.create_peer_and_health_data(
                                    metadata.remote_peer_id, self.round
                                );
                            }
                        }
                        ConnectionNotification::LostPeer(metadata, network_id) => {
                            // PeersAndMetadata is a global singleton across all networks; filter connect/disconnect events to the NetworkId that this HealthChecker instance is watching
                            if network_id == self_network_id {
                                self.network_interface.remove_peer_and_health_data(
                                    &metadata.remote_peer_id
                                );
                            }
                        }
                    }
                }
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L277-306)
```rust
    fn handle_ping_request(
        &mut self,
        peer_id: PeerId,
        ping: Ping,
        protocol: ProtocolId,
        res_tx: oneshot::Sender<Result<Bytes, RpcError>>,
    ) {
        let message = match protocol.to_bytes(&HealthCheckerMsg::Pong(Pong(ping.0))) {
            Ok(msg) => msg,
            Err(e) => {
                warn!(
                    NetworkSchema::new(&self.network_context),
                    error = ?e,
                    "{} Unable to serialize pong response: {}", self.network_context, e
                );
                return;
            },
        };
        trace!(
            NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
            "{} Sending Pong response to peer: {} with nonce: {}",
            self.network_context,
            peer_id.short_str(),
            ping.0,
        );
        // Record Ingress HC here and reset failures.
        self.network_interface.reset_peer_failures(peer_id);

        let _ = res_tx.send(Ok(message.into()));
    }
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L343-354)
```rust
            Err(err) => {
                warn!(
                    NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                    round = round,
                    "{} Ping failed for peer: {} round: {} with error: {:#}",
                    self.network_context,
                    peer_id.short_str(),
                    round,
                    err
                );
                self.network_interface
                    .increment_peer_round_failure(peer_id, round);
```

**File:** network/framework/src/protocols/health_checker/mod.rs (L364-392)
```rust
                if failures > self.ping_failures_tolerated {
                    info!(
                        NetworkSchema::new(&self.network_context).remote_peer(&peer_id),
                        "{} Disconnecting from peer: {}",
                        self.network_context,
                        peer_id.short_str()
                    );
                    let peer_network_id =
                        PeerNetworkId::new(self.network_context.network_id(), peer_id);
                    if let Err(err) = timeout(
                        Duration::from_millis(50),
                        self.network_interface.disconnect_peer(
                            peer_network_id,
                            DisconnectReason::NetworkHealthCheckFailure,
                        ),
                    )
                    .await
                    {
                        warn!(
                            NetworkSchema::new(&self.network_context)
                                .remote_peer(&peer_id),
                            error = ?err,
                            "{} Failed to disconnect from peer: {} with error: {:?}",
                            self.network_context,
                            peer_id.short_str(),
                            err
                        );
                    }
                }
```

**File:** config/src/config/network_config.rs (L38-40)
```rust
pub const PING_INTERVAL_MS: u64 = 10_000;
pub const PING_TIMEOUT_MS: u64 = 20_000;
pub const PING_FAILURES_TOLERATED: u64 = 3;
```

**File:** network/framework/src/protocols/health_checker/test.rs (L270-315)
```rust
#[tokio::test]
async fn ping_success_resets_fail_counter() {
    let failures_triggered = 10;
    let ping_failures_tolerated = 2 * 10;
    let (mut harness, health_checker) = TestHarness::new_permissive(ping_failures_tolerated);

    let test = async move {
        // Trigger ping to a peer. This should do nothing.
        harness.trigger_ping().await;

        // Notify HealthChecker of new connected node.
        let peer_id = PeerId::new([0x42; PeerId::LENGTH]);
        harness.send_new_peer_notification(peer_id).await;

        // Trigger pings to a peer. These should ping the newly added peer, but not disconnect from
        // it.
        {
            for _ in 0..failures_triggered {
                // Health checker should send a ping request which fails.
                harness.trigger_ping().await;
                harness.expect_ping_send_not_ok().await;
            }
        }

        // Trigger successful ping. This should reset the counter of ping failures.
        {
            // Health checker should send a ping request which succeeds
            harness.trigger_ping().await;
            harness.expect_ping_send_ok().await;
        }

        // We would then need to fail for more than `ping_failures_tolerated` times before
        // triggering disconnect.
        {
            for _ in 0..=ping_failures_tolerated {
                // Health checker should send a ping request which fails.
                harness.trigger_ping().await;
                harness.expect_ping_send_not_ok().await;
            }
        }

        // Health checker should disconnect from peer after tolerated number of failures
        harness.expect_disconnect(peer_id).await;
    };
    future::join(health_checker.start(), test).await;
}
```
