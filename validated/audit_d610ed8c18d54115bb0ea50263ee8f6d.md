# Audit Report

## Title
Race Condition in Randomness Generation Allows Byzantine Validators to Crash Consensus Nodes via unreachable!() Panic

## Summary
A race condition exists between consensus reset operations and asynchronous share aggregation tasks in the randomness generation subsystem. Byzantine validators can exploit this by sending randomness shares immediately after a reset event, causing the `unreachable!()` macro in `RandItem::get_all_shares_authors()` to trigger and panic the entire consensus node.

## Finding Description

The vulnerability stems from an incorrect invariant assumption in the randomness generation code. The function `RandItem::get_all_shares_authors()` contains an `unreachable!()` macro that assumes it will never be called when the item is in the `PendingMetadata` state. [1](#0-0) 

However, this assumption is violated due to a race condition in the async task execution model:

**Normal Flow:**

1. When a block arrives, `process_incoming_metadata()` adds randomness metadata (transitioning the `RandItem` from `PendingMetadata` to `PendingDecision` state) and spawns an async task that returns a `DropGuard`: [2](#0-1) 

2. The async task sleeps for 300ms before calling `get_all_shares_authors()`: [3](#0-2) 

3. The `DropGuard` is stored in the block queue to enable task cancellation: [4](#0-3) [5](#0-4) 

**Race Condition Attack:**

1. During the 300ms sleep period, a consensus reset occurs (triggered by state synchronization or epoch transitions). The reset clears the block queue (dropping all `DropGuards`) and removes items from `rand_store`: [6](#0-5) [7](#0-6) 

2. The `DropGuard` drop calls `abort()` on the async task handle: [8](#0-7) 

3. Byzantine validators send randomness shares for a recently-processed round. These shares are accepted because the round check passes (shares up to 200 rounds in the future are accepted): [9](#0-8) [10](#0-9) 

4. A new `RandItem` is created in **PendingMetadata** state when the share is added to an empty round entry (line 304-306).

5. **Critical Issue:** The async task wakes up from sleep and executes synchronous code. The code between line 274 (sleep) and line 290 (next await) is entirely synchronous. Rust's `Abortable` futures only check the abort flag when polled at await points. Once the poll starts executing after the sleep completes, it runs all this code without checking the abort flag again, even though `abort()` was called when the `DropGuard` was dropped during reset.

6. The task acquires the lock and calls `get_all_shares_authors(round)` on the newly created `PendingMetadata` item: [11](#0-10) 

This triggers the `unreachable!()` macro, panicking the node.

The root cause is that between await points, Rust async code executes synchronously without checking cancellation flags. The lock contention creates a timing window where the item can be removed by reset and re-added by incoming shares while the task's synchronous execution is in progress.

## Impact Explanation

**Severity: HIGH** - Validator node crashes leading to network availability degradation

This vulnerability allows Byzantine validators to crash any consensus node participating in randomness generation. The impact includes:

1. **Individual Node Crashes**: Any validator node can be crashed by exploiting this race condition
2. **Network Availability Impact**: If multiple validators are crashed simultaneously, the network's ability to produce randomness and finalize blocks is degraded
3. **Repeated Attacks**: The attack can be repeated after node restart, causing persistent availability issues
4. **No Recovery Beyond Restart**: While nodes can restart, repeated exploitation could cause prolonged network disruption

Per the Aptos bug bounty criteria, this qualifies as **High Severity** due to:
- "Validator node slowdowns" (crashes are worse than slowdowns)
- "API crashes" (consensus node crashes)
- Degradation of network randomness generation capability

This does NOT reach Critical severity because:
- It doesn't cause permanent network partition (nodes can restart)
- It doesn't violate consensus safety (no fork or double-spend)
- It doesn't cause fund loss or permanent freezing
- It doesn't halt the entire network (only affects individual nodes)

## Likelihood Explanation

**Likelihood: Medium-High**

The attack is feasible with the following characteristics:

1. **Triggerable Conditions**: Consensus resets occur naturally during normal operations: [12](#0-11) [13](#0-12) [14](#0-13) 

These include epoch transitions, round synchronization, and state sync operations.

2. **Attacker Requirements**: Byzantine validators need to:
   - Monitor for reset events (observable through network activity)
   - Send randomness shares for recently-processed rounds immediately after reset
   - The timing window is narrow (~300ms sleep duration) but exploitable with automated monitoring

3. **Natural Occurrence**: This can also trigger **without malicious intent**:
   - Honest validators may resend shares after observing reset events
   - Network delays could cause shares to arrive in the vulnerable window
   - Makes this a reliability issue even without active attackers

4. **No Special Privileges**: Any validator can send valid randomness shares, no special access required beyond being part of the validator set

5. **Repeatability**: The attack can be repeated indefinitely, making it a serious availability threat

## Recommendation

The fix should ensure that `get_all_shares_authors()` is never called on a `PendingMetadata` item. Several approaches:

1. **Check and handle PendingMetadata state**: Replace the `unreachable!()` with proper handling:
```rust
fn get_all_shares_authors(&self) -> Option<HashSet<Author>> {
    match self {
        RandItem::PendingDecision { share_aggregator, .. } => {
            Some(share_aggregator.shares.keys().cloned().collect())
        },
        RandItem::Decided { .. } => None,
        RandItem::PendingMetadata(_) => None, // Return None instead of panicking
    }
}
```

2. **Add state verification in the async task**: Before calling `get_all_shares_authors()`, verify the item is in the correct state and gracefully exit if not.

3. **Use async mutex**: Replace the synchronous mutex with an async-aware mutex so that abort checks occur during lock acquisition.

4. **Add abort check**: Explicitly check if the task was aborted before calling `get_all_shares_authors()` using a shared atomic flag.

The safest fix is option 1 combined with option 2, ensuring both defensive programming and graceful degradation.

## Proof of Concept

A full PoC would require:
1. Setting up a test network with randomness generation enabled
2. Triggering a reset via state sync or epoch transition
3. Sending a randomness share from a Byzantine validator immediately after reset
4. Observing the consensus node panic

The vulnerability can be demonstrated by adding instrumentation to log the state transitions and timing of the async task execution during reset operations.

## Notes

This vulnerability demonstrates a subtle interaction between Rust's async execution model and the consensus reset mechanism. The `unreachable!()` macro was likely added with the assumption that the async task would be properly cancelled before any state changes occurred. However, the synchronous execution window between await points creates a race condition that violates this assumption.

The vulnerability is particularly concerning because:
- It can be triggered during normal network operations (not just attacks)
- It affects the network's randomness generation capability
- It can be repeatedly exploited to cause persistent availability issues
- The fix is straightforward but requires careful consideration of the async execution model

### Citations

**File:** consensus/src/rand/rand_gen/rand_store.rs (L195-205)
```rust
    fn get_all_shares_authors(&self) -> Option<HashSet<Author>> {
        match self {
            RandItem::PendingDecision {
                share_aggregator, ..
            } => Some(share_aggregator.shares.keys().cloned().collect()),
            RandItem::Decided { .. } => None,
            RandItem::PendingMetadata(_) => {
                unreachable!("Should only be called after block is added")
            },
        }
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L253-259)
```rust
    pub fn reset(&mut self, round: u64) {
        self.update_highest_known_round(round);
        // remove future rounds items in case they're already decided
        // otherwise if the block re-enters the queue, it'll be stuck
        let _ = self.rand_map.split_off(&round);
        let _ = self.fast_rand_map.as_mut().map(|map| map.split_off(&round));
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L280-313)
```rust
    pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
        ensure!(
            share.metadata().epoch == self.epoch,
            "Share from different epoch"
        );
        ensure!(
            share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
        let rand_metadata = share.metadata().clone();

        let (rand_config, rand_item) = if path == PathType::Fast {
            match (self.fast_rand_config.as_ref(), self.fast_rand_map.as_mut()) {
                (Some(fast_rand_config), Some(fast_rand_map)) => (
                    fast_rand_config,
                    fast_rand_map
                        .entry(rand_metadata.round)
                        .or_insert_with(|| RandItem::new(self.author, path)),
                ),
                _ => anyhow::bail!("Fast path not enabled"),
            }
        } else {
            (
                &self.rand_config,
                self.rand_map
                    .entry(rand_metadata.round)
                    .or_insert_with(|| RandItem::new(self.author, PathType::Slow)),
            )
        };

        rand_item.add_share(share, rand_config)?;
        rand_item.try_aggregate(rand_config, self.decision_tx.clone());
        Ok(rand_item.has_decision())
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L315-321)
```rust
    /// This should only be called after the block is added, returns None if already decided
    /// Otherwise returns existing shares' authors
    pub fn get_all_shares_authors(&self, round: Round) -> Option<HashSet<Author>> {
        self.rand_map
            .get(&round)
            .and_then(|item| item.get_all_shares_authors())
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L132-143)
```rust
    fn process_incoming_blocks(&mut self, blocks: OrderedBlocks) {
        let rounds: Vec<u64> = blocks.ordered_blocks.iter().map(|b| b.round()).collect();
        info!(rounds = rounds, "Processing incoming blocks.");
        let broadcast_handles: Vec<_> = blocks
            .ordered_blocks
            .iter()
            .map(|block| FullRandMetadata::from(block.block()))
            .map(|metadata| self.process_incoming_metadata(metadata))
            .collect();
        let queue_item = QueueItem::new(blocks, Some(broadcast_handles));
        self.block_queue.push_back(queue_item);
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L145-169)
```rust
    fn process_incoming_metadata(&self, metadata: FullRandMetadata) -> DropGuard {
        let self_share = S::generate(&self.config, metadata.metadata.clone());
        info!(LogSchema::new(LogEvent::BroadcastRandShare)
            .epoch(self.epoch_state.epoch)
            .author(self.author)
            .round(metadata.round()));
        let mut rand_store = self.rand_store.lock();
        rand_store.update_highest_known_round(metadata.round());
        rand_store
            .add_share(self_share.clone(), PathType::Slow)
            .expect("Add self share should succeed");

        if let Some(fast_config) = &self.fast_config {
            let self_fast_share =
                FastShare::new(S::generate(fast_config, metadata.metadata.clone()));
            rand_store
                .add_share(self_fast_share.rand_share(), PathType::Fast)
                .expect("Add self share for fast path should succeed");
        }

        rand_store.add_rand_metadata(metadata.clone());
        self.network_sender
            .broadcast_without_self(RandMessage::<S, D>::Share(self_share).into_network_message());
        self.spawn_aggregate_shares_task(metadata.metadata)
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L184-194)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.rand_store.lock().reset(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L263-303)
```rust
    fn spawn_aggregate_shares_task(&self, metadata: RandMetadata) -> DropGuard {
        let rb = self.reliable_broadcast.clone();
        let aggregate_state = Arc::new(ShareAggregateState::new(
            self.rand_store.clone(),
            metadata.clone(),
            self.config.clone(),
        ));
        let epoch_state = self.epoch_state.clone();
        let round = metadata.round;
        let rand_store = self.rand_store.clone();
        let task = async move {
            tokio::time::sleep(Duration::from_millis(300)).await;
            let maybe_existing_shares = rand_store.lock().get_all_shares_authors(round);
            if let Some(existing_shares) = maybe_existing_shares {
                let epoch = epoch_state.epoch;
                let request = RequestShare::new(metadata.clone());
                let targets = epoch_state
                    .verifier
                    .get_ordered_account_addresses_iter()
                    .filter(|author| !existing_shares.contains(author))
                    .collect::<Vec<_>>();
                info!(
                    epoch = epoch,
                    round = round,
                    "[RandManager] Start broadcasting share request for {}",
                    targets.len(),
                );
                rb.multicast(request, aggregate_state, targets)
                    .await
                    .expect("Broadcast cannot fail");
                info!(
                    epoch = epoch,
                    round = round,
                    "[RandManager] Finish broadcasting share request",
                );
            }
        };
        let (abort_handle, abort_registration) = AbortHandle::new_pair();
        tokio::spawn(Abortable::new(task, abort_registration));
        DropGuard::new(abort_handle)
    }
```

**File:** consensus/src/rand/rand_gen/block_queue.rs (L17-40)
```rust
pub struct QueueItem {
    ordered_blocks: OrderedBlocks,
    offsets_by_round: HashMap<Round, usize>,
    num_undecided_blocks: usize,
    broadcast_handle: Option<Vec<DropGuard>>,
}

impl QueueItem {
    pub fn new(ordered_blocks: OrderedBlocks, broadcast_handle: Option<Vec<DropGuard>>) -> Self {
        let len = ordered_blocks.ordered_blocks.len();
        assert!(len > 0);
        let offsets_by_round: HashMap<Round, usize> = ordered_blocks
            .ordered_blocks
            .iter()
            .enumerate()
            .map(|(idx, b)| (b.round(), idx))
            .collect();
        Self {
            ordered_blocks,
            offsets_by_round,
            num_undecided_blocks: len,
            broadcast_handle,
        }
    }
```

**File:** crates/reliable-broadcast/src/lib.rs (L222-236)
```rust
pub struct DropGuard {
    abort_handle: AbortHandle,
}

impl DropGuard {
    pub fn new(abort_handle: AbortHandle) -> Self {
        Self { abort_handle }
    }
}

impl Drop for DropGuard {
    fn drop(&mut self) {
        self.abort_handle.abort();
    }
}
```

**File:** consensus/src/rand/rand_gen/types.rs (L26-26)
```rust
pub const FUTURE_ROUNDS_TO_ACCEPT: u64 = 200;
```

**File:** consensus/src/pipeline/execution_client.rs (L650-659)
```rust
        // Sync for the specified duration
        let result = self.execution_proxy.sync_for_duration(duration).await;

        // Reset the rand and buffer managers to the new synced round
        if let Ok(latest_synced_ledger_info) = &result {
            self.reset(latest_synced_ledger_info).await?;
        }

        result
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L661-672)
```rust
    async fn sync_to_target(&self, target: LedgerInfoWithSignatures) -> Result<(), StateSyncError> {
        fail_point!("consensus::sync_to_target", |_| {
            Err(anyhow::anyhow!("Injected error in sync_to_target").into())
        });

        // Reset the rand and buffer managers to the target round
        self.reset(&target).await?;

        // TODO: handle the state sync error (e.g., re-push the ordered
        // blocks to the buffer manager when it's reset but sync fails).
        self.execution_proxy.sync_to_target(target).await
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L674-709)
```rust
    async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
        let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
            let handle = self.handle.read();
            (
                handle.reset_tx_to_rand_manager.clone(),
                handle.reset_tx_to_buffer_manager.clone(),
            )
        };

        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
        }

        if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
            // reset execution phase and commit phase
            let (tx, rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::ResetDropped)?;
            rx.await.map_err(|_| Error::ResetDropped)?;
        }

        Ok(())
    }
```
