# Audit Report

## Title
Consensus Split via Hardcoded max_loop_depth Configuration During Validator Version Upgrades

## Summary
The `max_loop_depth` bytecode verification parameter is hardcoded in the production VM configuration and not derived from on-chain consensus state. During version upgrades where this value changes, validators running different code versions will accept or reject identical Move bytecode differently, causing divergent transaction outcomes and consensus failure requiring hardfork.

## Finding Description

The critical invariant violated is **Deterministic Execution**: "All validators must produce identical state roots for identical blocks."

The vulnerability exists in the bytecode verification pipeline:

1. **Hardcoded Configuration**: The `max_loop_depth` is hardcoded to `Some(5)` in the production verifier config, not derived from on-chain state or feature flags. Unlike other parameters in the same configuration (such as `max_type_nodes`, `max_function_return_values`, and `max_type_depth`) which are conditionally set based on feature flags, `max_loop_depth` remains constant regardless of on-chain configuration. [1](#0-0) 

2. **Verification Check**: During module publishing execution, the control flow verifier performs reducibility analysis and checks loop depth against the configured limit. When nested loops exceed the configured `max_loop_depth`, the verification fails. [2](#0-1) 

3. **Error Classification**: When the limit is exceeded, it returns `StatusCode::LOOP_MAX_DEPTH_REACHED` (1111), which is classified as a Verification status type (range 1000-1999). [3](#0-2) 

4. **Transaction Kept with Different Outcomes**: Verification errors are KEPT (not discarded) and charged gas, but produce `MiscellaneousError` status. This is explicitly documented: "A transaction that publishes code that cannot be verified will be charged." [4](#0-3) 

5. **Module Publishing Path**: During transaction execution, modules are verified using the `VMConfig`'s `verifier_config` in the `build_locally_verified_module` function, which is called as part of the module publishing flow. [5](#0-4) 

6. **Configuration Source**: The `AptosEnvironment` creates `VMConfig` via `aptos_prod_vm_config()` which embeds the hardcoded verifier configuration during environment initialization. [6](#0-5) 

**Attack Scenario:**
1. Aptos team releases version 2.0 changing `max_loop_depth` from `Some(5)` to `Some(10)`
2. During the upgrade window, validators are running mixed versions (standard practice - coordinated upgrades happen over hours/days)
3. Any user submits a transaction publishing a module with 7 nested loops
4. Validator A (v1.0, max_loop_depth=5): Verification fails with `LOOP_MAX_DEPTH_REACHED` → Transaction KEPT with `MiscellaneousError`, module NOT published, gas charged
5. Validator B (v2.0, max_loop_depth=10): Verification succeeds → Transaction KEPT with `Success`, module IS published, gas charged
6. **Result**: Different state modifications (module published vs not published) → different state roots → consensus split → chain halt

The verification happens during execution (not during pre-validation), so both validators process the transaction in consensus but produce different outputs, violating deterministic execution.

## Impact Explanation

This is **Critical Severity** under the Aptos bug bounty program:

- **Non-recoverable network partition (requires hardfork)**: When validators produce different state roots for the same block, consensus cannot proceed. The chain splits into incompatible forks that cannot be reconciled without a hardfork to force all validators to the same version.

- **Consensus/Safety violation**: This directly violates the BFT consensus safety property that honest validators must agree on committed blocks. The disagreement is deterministic based on code version, not Byzantine behavior.

- **Total loss of liveness/network availability**: Once validators disagree on state roots, block proposals will fail to reach consensus. The network becomes unavailable for transaction processing until manual intervention.

The vulnerability breaks the fundamental deterministic execution guarantee required for blockchain consensus.

## Likelihood Explanation

**Likelihood: HIGH**

This vulnerability WILL occur if:
1. The Aptos team changes `max_loop_depth` in any future release (reasonable for evolving gas economics, performance improvements, or security hardening)
2. Validators upgrade at different times (standard practice - coordinated upgrades happen over hours/days, never instantaneous)
3. ANY user submits a module with loop depth between the old and new limits during the upgrade window

The attack requires:
- **No special privileges**: Any user can submit module publishing transactions
- **No validator collusion**: Happens naturally during version upgrades
- **Trivial to trigger**: Simply publish Move code with appropriately nested loops
- **Undetectable until consensus fails**: Validators won't know they're on divergent paths until block proposal failures occur

The parameter is configurable (defined as `Option<usize>`) and not feature-gated, suggesting the Aptos team designed it to be adjustable. This makes future changes plausible for legitimate technical reasons.

## Recommendation

Implement one of the following solutions:

**Solution 1 (Recommended): Feature-flag the parameter**
Add a feature flag to gate `max_loop_depth` changes, similar to how `max_type_nodes`, `max_function_return_values`, and `max_type_depth` are gated by `enable_function_values`. This ensures all validators use the same value within an epoch.

```rust
pub fn aptos_prod_verifier_config(gas_feature_version: u64, features: &Features) -> VerifierConfig {
    // Add new feature flag
    let increased_loop_depth = features.is_enabled(FeatureFlag::INCREASED_LOOP_DEPTH);
    
    VerifierConfig {
        max_loop_depth: if increased_loop_depth {
            Some(10)
        } else {
            Some(5)
        },
        // ... rest of config
    }
}
```

**Solution 2: Move to on-chain configuration**
Store `max_loop_depth` as an on-chain configuration resource that updates at epoch boundaries via governance, ensuring all validators read the same value from consensus state.

**Solution 3: Coordinate changes with version upgrades**
Document that any `max_loop_depth` changes require coordinated network-wide upgrades with explicit validator coordination, similar to hardfork procedures.

## Proof of Concept

The existing test demonstrates the behavior: [7](#0-6) 

To demonstrate the consensus split scenario, one would need to:
1. Create two validator nodes with different `max_loop_depth` values in their compiled binaries
2. Submit a module publishing transaction with loop depth between the two limits
3. Observe that validators produce different state roots for the same block
4. Confirm consensus failure occurs

The vulnerability is confirmed by code inspection showing the hardcoded parameter, execution-time verification, and KEPT status for verification errors.

## Notes

This vulnerability represents a class of consensus determinism issues where configuration parameters embedded in node binaries can cause state divergence during rolling upgrades. Similar issues have affected other blockchain networks (Ethereum Shanghai fork timing issues, Cosmos SDK upgrade coordination failures).

The Aptos codebase shows awareness of this pattern by feature-gating many other verification parameters, but `max_loop_depth` was not included in this protection mechanism. This appears to be an oversight rather than an intentional design decision.

### Citations

**File:** aptos-move/aptos-vm-environment/src/prod_configs.rs (L157-157)
```rust
        max_loop_depth: Some(5),
```

**File:** third_party/move/move-bytecode-verifier/src/control_flow.rs (L174-177)
```rust
        if let Some(max_depth) = verifier_config.max_loop_depth {
            if depth as usize > max_depth {
                return err(StatusCode::LOOP_MAX_DEPTH_REACHED, summary.block(head));
            }
```

**File:** third_party/move/move-core/types/src/vm_status.rs (L24-27)
```rust
pub static VERIFICATION_STATUS_MIN_CODE: u64 = 1000;

/// The maximum status code for verification statuses
pub static VERIFICATION_STATUS_MAX_CODE: u64 = 1999;
```

**File:** third_party/move/move-core/types/src/vm_status.rs (L300-301)
```rust
                    // A transaction that publishes code that cannot be verified will be charged.
                    StatusType::Verification => Ok(KeptVMStatus::MiscellaneousError),
```

**File:** third_party/move/move-vm/runtime/src/storage/environment.rs (L192-195)
```rust
            move_bytecode_verifier::verify_module_with_config(
                &self.vm_config().verifier_config,
                compiled_module.as_ref(),
            )?;
```

**File:** aptos-move/aptos-vm-environment/src/environment.rs (L276-282)
```rust
        let vm_config = aptos_prod_vm_config(
            chain_id,
            gas_feature_version,
            &features,
            &timed_features,
            ty_builder,
        );
```

**File:** aptos-move/e2e-move-tests/src/tests/max_loop_depth.rs (L19-29)
```rust
#[test]
fn module_loop_depth_just_above_limit() {
    let mut h = MoveHarness::new();

    // Load the code
    let acc = h.new_account_at(AccountAddress::from_hex_literal("0xbeef").unwrap());
    assert_vm_status!(
        h.publish_package(&acc, &common::test_dir_path("max_loop_depth.data/pack-bad"),),
        StatusCode::LOOP_MAX_DEPTH_REACHED
    );
}
```
