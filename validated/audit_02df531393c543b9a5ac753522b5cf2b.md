# Audit Report

## Title
Ordered Certificate Rollback During BlockTree Rebuild Violates Finality Invariant

## Summary
The `highest_ordered_cert()` function can decrease its round value when `BlockStore::rebuild()` is called during sync operations, violating the critical finality invariant that ordered rounds must be monotonically increasing. This occurs because the rebuild process creates a new `BlockTree` with `highest_ordered_cert` initialized from the commit certificate, discarding any higher previously-seen ordered certificate values.

## Finding Description

The AptosBFT consensus protocol with order votes enabled maintains a `highest_ordered_cert` field representing the highest round for which blocks have been ordered for execution. This value should never decrease, as it represents a finality commitment. [1](#0-0) 

During normal operation, `highest_ordered_cert` is correctly enforced to only increase through two mechanisms: [2](#0-1) [3](#0-2) 

However, when `BlockStore::rebuild()` is called during sync operations, it completely replaces the `BlockTree`: [4](#0-3) 

The new tree is created via `BlockTree::new()` with a `root_ordered_cert` that comes from the recovery data: [5](#0-4) 

When `order_vote_enabled = true`, this `root_ordered_cert` is created from the committed ledger state: [6](#0-5) 

**The vulnerability:** The `root_ordered_cert` is based on the **commit round** from storage, which can be significantly lower than the previous `highest_ordered_cert` value due to execution pipelining. At line 260 of block_store.rs, the old tree is completely replaced (`*tree_to_replace.write() = tree;`), permanently losing the higher `highest_ordered_cert` value. Notably, only `highest_2chain_timeout_cert` is preserved during rebuild, not `highest_ordered_cert`.

**Attack Scenario:**
1. Node has `highest_ordered_cert` at round 100 (from recently received order certificate)
2. Node has `ordered_root` at round 90, `commit_root` at round 80 (normal pipelining lag)
3. Node receives SyncInfo from peer with `highest_commit_cert` at round 95
4. Sync is triggered because the commit cert block doesn't exist or node fell behind: [7](#0-6) 

5. `fast_forward_sync()` creates recovery data with `root_ordered_cert` at round 95
6. `rebuild()` replaces the tree, setting `highest_ordered_cert` to round 95
7. **Result:** `highest_ordered_cert()` rolled back from 100 to 95

The rollback is then propagated when the node creates new SyncInfo messages: [8](#0-7) 

## Impact Explanation

**Severity: CRITICAL** - This is a consensus safety violation with multiple severe impacts:

1. **Order Vote Re-acceptance:** The RoundManager only processes order votes within 100 rounds of `highest_ordered_round`: [9](#0-8) 

After rollback from round 100 to 95, order votes for rounds 96-100 become acceptable again. This could cause the node to:
- Accept and process order votes for rounds it already ordered
- Potentially order different blocks at the same rounds
- Create consensus fork if different blocks are ordered at the same rounds

2. **Network-wide Inconsistency:** The rolled-back `highest_ordered_round` is broadcast to peers via SyncInfo, misleading the network about actual ordering progress and potentially causing cascading rollbacks across multiple nodes.

3. **Finality Violation:** The fundamental invariant that "ordered rounds are monotonically increasing" is broken, undermining the consensus protocol's safety guarantees. This violates the core assumption that once a round is ordered, it remains ordered.

This meets the **Critical Severity** criteria for "Consensus/Safety violations" per the Aptos bug bounty program and could lead to consensus divergence or network-wide state inconsistency.

## Likelihood Explanation

**Likelihood: HIGH** - This vulnerability can be triggered during normal network operations:

1. **Natural Trigger Conditions:**
   - Node temporarily falls behind (common in distributed networks)
   - Node restarts and syncs from peers
   - Network partition temporarily isolates a node
   - Any scenario where sync is triggered while execution pipeline has uncommitted ordered blocks

2. **No Attacker Control Required:** The vulnerability is triggered by legitimate sync operations, not malicious input. The gap between `highest_ordered_cert` and `commit_root` is a normal consequence of execution pipelining where blocks are ordered before they are committed.

3. **Affects All Nodes:** When `order_vote_enabled = true` (production configuration), all nodes are vulnerable during sync operations.

4. **Automatic Propagation:** Once one node experiences rollback, it broadcasts the incorrect `highest_ordered_round` to peers via SyncInfo, potentially causing network-wide confusion.

The combination of natural occurrence, no attacker requirements, and network-wide scope makes this a high-likelihood critical vulnerability.

## Recommendation

Preserve the `highest_ordered_cert` value during rebuild operations, similar to how `highest_2chain_timeout_cert` is currently preserved. Modify `BlockStore::rebuild()` to:

1. Capture the previous `highest_ordered_cert` before rebuild
2. After creating the new tree, compare and update to the maximum of the old and new values
3. Ensure monotonic increase invariant is maintained

Example fix in `block_store.rs`:

```rust
pub async fn rebuild(...) {
    // Preserve the previous highest_ordered_cert
    let prev_highest_ordered_cert = self.highest_ordered_cert();
    
    // Rollover the previous highest TC from the old tree to the new one.
    let prev_2chain_htc = self.highest_2chain_timeout_cert().map(|tc| tc.as_ref().clone());
    
    // ... existing rebuild logic ...
    
    // After rebuild, ensure highest_ordered_cert doesn't decrease
    let new_highest_ordered_cert = self.highest_ordered_cert();
    if prev_highest_ordered_cert.commit_info().round() > new_highest_ordered_cert.commit_info().round() {
        self.inner.write().insert_ordered_cert((*prev_highest_ordered_cert).clone());
    }
}
```

## Proof of Concept

While a full executable PoC would require a multi-node testnet setup, the vulnerability can be demonstrated through code inspection:

1. Start with a node having `highest_ordered_cert` at round 100 (obtainable through order vote processing)
2. Ensure execution pipeline lag with `commit_root` at round 80
3. Trigger sync via `need_sync_for_ledger_info()` with a peer's `highest_commit_cert` at round 95
4. Observe that `rebuild()` creates new BlockTree with `highest_ordered_cert` at round 95
5. Verify the rollback by checking `sync_info().highest_ordered_round()` returns 95 instead of 100

The code paths are deterministic and the vulnerability is evident from the source code analysis.

### Citations

**File:** consensus/src/block_storage/block_tree.rs (L88-90)
```rust
    highest_2chain_timeout_cert: Option<Arc<TwoChainTimeoutCertificate>>,
    /// The quorum certificate that has highest commit info.
    highest_ordered_cert: Arc<WrappedLedgerInfo>,
```

**File:** consensus/src/block_storage/block_tree.rs (L104-148)
```rust
    pub(super) fn new(
        commit_root_id: HashValue,
        window_root: PipelinedBlock,
        root_quorum_cert: QuorumCert,
        root_ordered_cert: WrappedLedgerInfo,
        root_commit_cert: WrappedLedgerInfo,
        max_pruned_blocks_in_mem: usize,
        highest_2chain_timeout_cert: Option<Arc<TwoChainTimeoutCertificate>>,
    ) -> Self {
        assert_eq!(window_root.epoch(), root_ordered_cert.commit_info().epoch());
        assert!(window_root.round() <= root_ordered_cert.commit_info().round());
        let window_root_id = window_root.id();

        // Build the tree from the window root block which is <= the commit root block.
        let mut id_to_block = HashMap::new();
        let mut round_to_ids = BTreeMap::new();
        round_to_ids.insert(window_root.round(), window_root_id);
        id_to_block.insert(window_root_id, LinkableBlock::new(window_root));
        counters::NUM_BLOCKS_IN_TREE.set(1);

        let root_quorum_cert = Arc::new(root_quorum_cert);
        let mut id_to_quorum_cert = HashMap::new();
        id_to_quorum_cert.insert(
            root_quorum_cert.certified_block().id(),
            Arc::clone(&root_quorum_cert),
        );

        let pruned_block_ids = VecDeque::with_capacity(max_pruned_blocks_in_mem);

        BlockTree {
            id_to_block,
            ordered_root_id: commit_root_id,
            commit_root_id, // initially we set commit_root_id = root_id
            window_root_id,
            highest_certified_block_id: commit_root_id,
            highest_quorum_cert: Arc::clone(&root_quorum_cert),
            highest_ordered_cert: Arc::new(root_ordered_cert),
            highest_commit_cert: Arc::new(root_commit_cert),
            id_to_quorum_cert,
            pruned_block_ids,
            max_pruned_blocks_in_mem,
            highest_2chain_timeout_cert,
            round_to_ids,
        }
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L380-383)
```rust
        if self.highest_ordered_cert.commit_info().round() < qc.commit_info().round() {
            // Question: We are updating highest_ordered_cert but not highest_ordered_root. Is that fine?
            self.highest_ordered_cert = Arc::new(qc.into_wrapped_ledger_info());
        }
```

**File:** consensus/src/block_storage/block_tree.rs (L388-392)
```rust
    pub fn insert_ordered_cert(&mut self, ordered_cert: WrappedLedgerInfo) {
        if ordered_cert.commit_info().round() > self.highest_ordered_cert.commit_info().round() {
            self.highest_ordered_cert = Arc::new(ordered_cert);
        }
    }
```

**File:** consensus/src/block_storage/block_store.rs (L352-395)
```rust
    pub async fn rebuild(
        &self,
        root: RootInfo,
        root_metadata: RootMetadata,
        blocks: Vec<Block>,
        quorum_certs: Vec<QuorumCert>,
    ) {
        info!(
            "Rebuilding block tree. root {:?}, blocks {:?}, qcs {:?}",
            root,
            blocks.iter().map(|b| b.id()).collect::<Vec<_>>(),
            quorum_certs
                .iter()
                .map(|qc| qc.certified_block().id())
                .collect::<Vec<_>>()
        );
        let max_pruned_blocks_in_mem = self.inner.read().max_pruned_blocks_in_mem();

        // Rollover the previous highest TC from the old tree to the new one.
        let prev_2chain_htc = self
            .highest_2chain_timeout_cert()
            .map(|tc| tc.as_ref().clone());
        let _ = Self::build(
            root,
            root_metadata,
            blocks,
            quorum_certs,
            prev_2chain_htc,
            self.execution_client.clone(),
            Arc::clone(&self.storage),
            max_pruned_blocks_in_mem,
            Arc::clone(&self.time_service),
            self.vote_back_pressure_limit,
            self.payload_manager.clone(),
            self.order_vote_enabled,
            self.window_size,
            self.pending_blocks.clone(),
            self.pipeline_builder.clone(),
            Some(self.inner.clone()),
        )
        .await;

        self.try_send_for_execution().await;
    }
```

**File:** consensus/src/block_storage/block_store.rs (L680-688)
```rust
    fn sync_info(&self) -> SyncInfo {
        SyncInfo::new_decoupled(
            self.highest_quorum_cert().as_ref().clone(),
            self.highest_ordered_cert().as_ref().clone(),
            self.highest_commit_cert().as_ref().clone(),
            self.highest_2chain_timeout_cert()
                .map(|tc| tc.as_ref().clone()),
        )
    }
```

**File:** consensus/src/persistent_liveness_storage.rs (L145-151)
```rust
        let (root_ordered_cert, root_commit_cert) = if order_vote_enabled {
            // We are setting ordered_root same as commit_root. As every committed block is also ordered, this is fine.
            // As the block store inserts all the fetched blocks and quorum certs and execute the blocks, the block store
            // updates highest_ordered_cert accordingly.
            let root_ordered_cert =
                WrappedLedgerInfo::new(VoteData::dummy(), latest_ledger_info_sig.clone());
            (root_ordered_cert.clone(), root_ordered_cert)
```

**File:** consensus/src/block_storage/sync_manager.rs (L65-93)
```rust
    pub fn need_sync_for_ledger_info(&self, li: &LedgerInfoWithSignatures) -> bool {
        const MAX_PRECOMMIT_GAP: u64 = 200;
        let block_not_exist = self.ordered_root().round() < li.commit_info().round()
            && !self.block_exists(li.commit_info().id());
        // TODO move min gap to fallback (30) to config, and if configurable make sure the value is
        // larger than buffer manager MAX_BACKLOG (20)
        let max_commit_gap = 30.max(2 * self.vote_back_pressure_limit);
        let min_commit_round = li.commit_info().round().saturating_sub(max_commit_gap);
        let current_commit_round = self.commit_root().round();

        if let Some(pre_commit_status) = self.pre_commit_status() {
            let mut status_guard = pre_commit_status.lock();
            if block_not_exist || status_guard.round() < min_commit_round {
                // pause the pre_commit so that pre_commit task doesn't over-commit
                // it can still commit if it receives the LI previously forwarded,
                // but it won't exceed the LI here
                // it'll resume after state sync is done
                status_guard.pause();
                true
            } else {
                if current_commit_round + MAX_PRECOMMIT_GAP < status_guard.round() {
                    status_guard.pause();
                }
                false
            }
        } else {
            block_not_exist || current_commit_round < min_commit_round
        }
    }
```

**File:** consensus/src/round_manager.rs (L1568-1573)
```rust
            let highest_ordered_round = self.block_store.sync_info().highest_ordered_round();
            let order_vote_round = order_vote_msg.order_vote().ledger_info().round();
            let li_digest = order_vote_msg.order_vote().ledger_info().hash();
            if order_vote_round > highest_ordered_round
                && order_vote_round < highest_ordered_round + 100
            {
```
