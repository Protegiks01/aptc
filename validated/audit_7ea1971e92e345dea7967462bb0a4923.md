# Audit Report

## Title
Incarnation Regression in BlockSTM V1 Block Epilogue Causes Validator Node Panic

## Summary
The BlockSTM V1 scheduler's `prepare_for_block_epilogue()` function hardcodes the returned incarnation to 1, regardless of the actual current incarnation. When a block epilogue transaction undergoes multiple execution attempts before the block is cut, this causes a non-monotonic incarnation sequence that violates MVHashMap's strict incarnation ordering invariant, resulting in an assertion failure and validator node crash.

## Finding Description

The vulnerability exists in the BlockSTM V1 scheduler's handling of block epilogue transaction incarnations during block cutting scenarios.

**Root Cause:**

When `halt_transaction_execution()` is called, it replaces the execution status with `ExecutionHalted(bool)`, completely discarding the incarnation number from the previous state: [1](#0-0) 

The `ExecutionHalted` enum variant only tracks a boolean flag for `safely_finished`, losing all incarnation information that was previously stored in states like `Executed(incarnation)` or `Executing(incarnation, _)`: [2](#0-1) 

Subsequently, when `prepare_for_block_epilogue()` is invoked, it has no way to determine the actual current incarnation and **hardcodes the return value to 1**: [3](#0-2) 

This hardcoded incarnation 1 is then used for the epilogue's final execution: [4](#0-3) 

**Invariant Violation:**

The MVHashMap enforces strict monotonic incarnation ordering through an assertion in `write_impl()`: [5](#0-4) 

The assertion at line 645 requires `*prev_incarnation < incarnation`. If the epilogue transaction previously executed with incarnation 1 (or higher) before being halted, attempting to write again with incarnation 1 violates this invariant, causing an assertion failure and validator node panic.

**Attack Scenario:**

1. Block epilogue transaction starts execution with incarnation 0
2. Execution completes, but validation fails due to read dependency invalidation
3. Transaction aborts via `set_aborted_status`, incarnation increments to 1
4. Transaction re-executes with incarnation 1, writes state to MVHashMap
5. Execution completes successfully with `Executed(1)` status
6. Before commit, block is cut due to gas limit exceeded or other halting condition
7. `halt()` is called, replacing status with `ExecutionHalted(true)` - **incarnation 1 is lost**
8. `prepare_for_block_epilogue()` returns hardcoded incarnation 1 instead of correct value 2
9. `execute_txn_after_commit()` attempts to execute with incarnation 1
10. Transaction writes trigger `write_impl()` which finds existing entry with incarnation 1
11. Assertion `assert!(prev_incarnation < incarnation)` evaluates to `assert!(1 < 1)` â†’ **PANIC**
12. Validator node crashes with assertion failure

**Contrast with Scheduler V2:**

The V2 scheduler correctly handles this by preserving incarnation state and incrementing appropriately: [6](#0-5) 

V2 retrieves the current incarnation at line 469 and conditionally increments it at lines 480-485 when the status is Aborted or Executed.

## Impact Explanation

**Severity: Critical**

This vulnerability meets the Critical severity criteria per the Aptos bug bounty program:

1. **Validator Node Crashes**: The assertion failure causes immediate node panic, leading to validator downtime and potential network liveness issues if multiple validators are affected simultaneously.

2. **Deterministic Execution Violation**: Different validators may crash at different points depending on their parallel execution timing, breaking the deterministic execution invariant that all validators must produce identical state roots for identical blocks.

3. **Network Instability**: During high-load periods or complex blocks where epilogue transactions are more likely to undergo multiple incarnations, coordinated crashes could cause network-wide liveness failures.

4. **Total Loss of Liveness**: This directly maps to the "Total Loss of Liveness/Network Availability" Critical impact category, as the bug can halt all validators using BlockSTM V1 from progressing.

The bug directly violates state consistency invariants and can lead to complete network unavailability under realistic conditions.

## Likelihood Explanation

**Likelihood: Medium-High**

The vulnerability is highly likely to occur in production because:

1. **V1 Scheduler is Default**: BlockSTM V1 remains the default configuration: [7](#0-6) 

2. **Natural Occurrence**: Block epilogue transactions can legitimately undergo multiple incarnations during normal parallel execution due to:
   - Read dependency invalidation from other transactions
   - Speculative execution conflicts  
   - Resource contention in parallel execution

3. **Block Cutting is Common**: Blocks are frequently cut before all transactions commit due to:
   - Per-block gas limit enforcement
   - SkipRest transaction status
   - Other halting conditions
   - Module publishing with read/write conflicts

4. **No Special Permissions Required**: The vulnerability triggers through normal blockchain operation without requiring attacker control or malicious validator behavior.

The only mitigating factor is that the epilogue transaction must go through at least one abort/retry cycle before the block is cut, which while not guaranteed every block, is a common occurrence in high-throughput scenarios.

## Recommendation

**Fix for V1 Scheduler:**

Modify `prepare_for_block_epilogue()` to track and preserve the actual incarnation number before halting, similar to how V2 handles it. The status should store the incarnation in `ExecutionHalted` or retrieve it from a separate tracking mechanism:

```rust
pub(crate) fn prepare_for_block_epilogue(
    &self,
    block_epilogue_idx: TxnIndex,
) -> Result<Incarnation, PanicError> {
    if block_epilogue_idx == self.num_txns {
        return Ok(0);
    }

    let mut status = self.txn_status[block_epilogue_idx as usize].0.write();
    
    // Extract the incarnation before it was halted
    let next_incarnation = match *status {
        ExecutionStatus::ExecutionHalted(safely_finished) => {
            if !safely_finished {
                return Err(code_invariant_error(format!(
                    "Status at block epilogue txn {} not safely finished",
                    block_epilogue_idx
                )));
            }
            // Retrieve the incarnation that was lost during halting
            // This requires modifying ExecutionHalted to store incarnation
            // or maintaining a separate incarnation counter per transaction
            self.get_last_incarnation(block_epilogue_idx)? + 1
        },
        _ => return Err(code_invariant_error(format!(
            "Status {:?} at block epilogue txn {} not ExecutionHalted",
            &*status, block_epilogue_idx
        ))),
    };

    *status = ExecutionStatus::Ready(next_incarnation, ExecutionTaskType::Execution);
    Ok(next_incarnation)
}
```

**Recommended Long-term Solution:**

Migrate all validators to BlockSTM V2, which correctly handles incarnation tracking through its `StatusWithIncarnation` structure and doesn't suffer from this bug.

## Proof of Concept

The following scenario demonstrates the vulnerability:

```rust
// Simplified PoC showing the bug trigger
#[test]
fn test_incarnation_regression_panic() {
    let scheduler = Scheduler::new(2); // 2 transactions
    
    // Simulate epilogue at index 0
    let epilogue_idx = 0;
    
    // Execute incarnation 0, then abort
    scheduler.try_incarnate(epilogue_idx);
    scheduler.set_executed_status(epilogue_idx, 0);
    scheduler.try_abort(epilogue_idx, 0);
    scheduler.finish_abort(epilogue_idx, 0); // Incarnation becomes 1
    
    // Execute incarnation 1, write to MVHashMap
    scheduler.try_incarnate(epilogue_idx);
    scheduler.set_executed_status(epilogue_idx, 1);
    // At this point, MVHashMap has an entry for (epilogue_idx, incarnation=1)
    
    // Block is cut, halt is called
    scheduler.halt();
    
    // prepare_for_block_epilogue returns hardcoded 1
    let incarnation = scheduler.prepare_for_block_epilogue(epilogue_idx).unwrap();
    assert_eq!(incarnation, 1); // Hardcoded to 1, should be 2
    
    // Attempting to write with incarnation 1 again will trigger:
    // assert!(prev_incarnation < incarnation) => assert!(1 < 1) => PANIC!
}
```

The actual panic occurs when the executor attempts to write to MVHashMap with the hardcoded incarnation 1, finding an existing entry with incarnation 1, violating the strict monotonic ordering invariant.

### Citations

**File:** aptos-move/block-executor/src/scheduler.rs (L140-164)
```rust
enum ExecutionStatus {
    Ready(Incarnation, ExecutionTaskType),
    Executing(Incarnation, ExecutionTaskType),
    Suspended(Incarnation, DependencyCondvar),
    Executed(Incarnation),
    // TODO[agg_v2](cleanup): rename to Finalized or ReadyToCommit / CommitReady?
    // it gets committed later, without scheduler tracking.
    Committed(Incarnation),
    Aborting(Incarnation),
    // The bool in ExecutionHalted tracks an useful invariant for the block epilogue txn
    // when the block is cut, and the final execution of the epilogue txn occurs at
    // some idx < num_txns. In this case, it must be ensured that any control flow that
    // started to apply changes to the shared data structures was completed despite
    // a concurrent halt (which must be invoked due to block cutting).
    // - in case of Aborting, finish_abort must be called (after estimates are marked).
    // - in case of Executing, finish_execution must be called, which happens after
    // the caller records the input/output (needed to mark outputs as estimates or
    // clear the prior write-set).
    //
    // In particular, [Scheduler::set_aborted_status] & [Scheduler::set_executed_status]
    // must be called to reset the flag to true. The flag is set to false if when halting,
    // the txn status is aborting or executing, or if right before applying the outputs
    // to the shared data structures the txn is already halted.
    ExecutionHalted(bool),
}
```

**File:** aptos-move/block-executor/src/scheduler.rs (L430-455)
```rust
    pub(crate) fn prepare_for_block_epilogue(
        &self,
        block_epilogue_idx: TxnIndex,
    ) -> Result<Incarnation, PanicError> {
        if block_epilogue_idx == self.num_txns {
            return Ok(0);
        }

        let mut status = self.txn_status[block_epilogue_idx as usize].0.write();
        if let ExecutionStatus::ExecutionHalted(safely_finished) = *status {
            if !safely_finished {
                return Err(code_invariant_error(format!(
                    "Status at block epilogue txn {} not safely finished after ExecutionHalted but not finished",
                    block_epilogue_idx
                )));
            }
        } else {
            return Err(code_invariant_error(format!(
                "Status {:?} at block epilogue txn {} not ExecutionHalted",
                &*status, block_epilogue_idx
            )));
        }

        *status = ExecutionStatus::Ready(1, ExecutionTaskType::Execution);
        Ok(1)
    }
```

**File:** aptos-move/block-executor/src/scheduler.rs (L772-794)
```rust
    fn halt_transaction_execution(&self, txn_idx: TxnIndex) {
        let mut status = self.txn_status[txn_idx as usize].0.write();

        // Always replace the status.
        match std::mem::replace(&mut *status, ExecutionStatus::ExecutionHalted(true)) {
            ExecutionStatus::Suspended(_, condvar)
            | ExecutionStatus::Ready(_, ExecutionTaskType::Wakeup(condvar))
            | ExecutionStatus::Executing(_, ExecutionTaskType::Wakeup(condvar)) => {
                // Condvar lock must always be taken inner-most.
                let (lock, cvar) = &*condvar;

                let mut lock = lock.lock();
                *lock = DependencyStatus::ExecutionHalted;
                cvar.notify_one();
            },
            ExecutionStatus::Executing(_, _) | ExecutionStatus::Aborting(_) => {
                // If Executing or Aborting, set safely_finished to false, which can only be
                // reset by finish_execution or finish_abort.
                *status = ExecutionStatus::ExecutionHalted(false);
            },
            _ => (),
        }
    }
```

**File:** aptos-move/block-executor/src/executor.rs (L1652-1673)
```rust
                let incarnation = scheduler.prepare_for_block_epilogue::<T, E>(
                    epilogue_txn_idx,
                    last_input_output,
                    versioned_cache,
                )?;

                Self::execute_txn_after_commit(
                    &epilogue_txn,
                    &block_epilogue_aux_info,
                    epilogue_txn_idx,
                    incarnation,
                    scheduler,
                    versioned_cache,
                    last_input_output,
                    start_shared_counter,
                    shared_counter,
                    executor,
                    base_view,
                    module_cache,
                    runtime_environment,
                    &self.config.onchain.block_gas_limit_type,
                )?;
```

**File:** aptos-move/mvhashmap/src/versioned_data.rs (L625-653)
```rust
    fn write_impl(
        versioned_values: &mut VersionedValue<V>,
        txn_idx: TxnIndex,
        incarnation: Incarnation,
        value: ValueWithLayout<V>,
        dependencies: BTreeMap<TxnIndex, Incarnation>,
    ) {
        let prev_entry = versioned_values.versioned_map.insert(
            ShiftedTxnIndex::new(txn_idx),
            CachePadded::new(new_write_entry(incarnation, value, dependencies)),
        );

        // Assert that the previous entry for txn_idx, if present, had lower incarnation.
        assert!(prev_entry.is_none_or(|entry| -> bool {
            if let EntryCell::ResourceWrite {
                incarnation: prev_incarnation,
                ..
            } = &entry.value
            {
                // For BlockSTMv1, the dependencies are always empty.
                *prev_incarnation < incarnation
                // TODO(BlockSTMv2): when AggregatorV1 is deprecated, we can assert that
                // prev_dependencies is empty: they must have been drained beforehand
                // (into dependencies) if there was an entry at the same index before.
            } else {
                true
            }
        }));
    }
```

**File:** aptos-move/block-executor/src/scheduler_status.rs (L463-497)
```rust
    pub(crate) fn prepare_for_block_epilogue(
        &self,
        block_epilogue_idx: TxnIndex,
    ) -> Result<Incarnation, PanicError> {
        let status = &self.statuses[block_epilogue_idx as usize];
        let status_guard = &mut *status.status_with_incarnation.lock();
        let incarnation = status_guard.incarnation();

        match status_guard.status {
            SchedulingStatus::Executing(_) => {
                return Err(code_invariant_error(
                    "Block epilogue txn must not be executing",
                ));
            },
            SchedulingStatus::Aborted | SchedulingStatus::Executed => {
                // Start abort is idempotent for the same incarnation.
                self.start_abort(block_epilogue_idx, incarnation)?;
                self.to_pending_scheduling(
                    block_epilogue_idx,
                    status_guard,
                    incarnation + 1,
                    false,
                );
            },
            SchedulingStatus::PendingScheduling => {},
        }

        self.to_executing(block_epilogue_idx, status_guard)?
            .ok_or_else(|| {
                code_invariant_error(format!(
                    "Expected PendingScheduling Status for block epilogue idx {}",
                    block_epilogue_idx
                ))
            })
    }
```

**File:** config/src/config/execution_config.rs (L90-92)
```rust
            genesis_waypoint: None,
            blockstm_v2_enabled: false,
            layout_caches_enabled: true,
```
