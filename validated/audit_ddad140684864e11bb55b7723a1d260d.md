# Audit Report

## Title
Critical Race Condition: Payload Removal During Block Execution Causes Liveness Failure in Consensus Observer

## Summary
A critical race condition exists in the consensus observer's block processing pipeline where block payloads can be removed by commit callbacks after payload verification but before execution accesses them. This causes either immediate block processing failures or infinite retry loops in the execution pipeline, resulting in total loss of liveness for the consensus observer.

## Finding Description

The consensus observer processes blocks in multiple stages with separate locking windows, creating a race condition between payload verification and payload access during execution.

**Execution Flow and Race Window:**

The payload arrival triggers block processing through `process_block_payload_message`, which inserts the payload and calls `order_ready_pending_block` to process any pending blocks that are now ready. [1](#0-0) 

The `order_ready_pending_block` function acquires a lock on `observer_block_data`, calls `remove_ready_pending_block` which internally checks `all_payloads_exist`, retrieves the pending block, and then **releases the lock** before calling `process_ordered_block`. [2](#0-1) 

Inside `remove_ready_block`, the payload existence check verifies all payloads are present and verified before returning the pending block. [3](#0-2) 

The payload existence check confirms payloads have status `AvailableAndVerified`. [4](#0-3) 

**The Critical Race Window:** After the lock is released but before `process_ordered_block` executes, commit callbacks from the execution pipeline can fire concurrently. These callbacks invoke `handle_committed_blocks`, which removes all payloads up to the committed round without checking if they're still needed by in-flight processing. [5](#0-4) 

The payload removal uses `remove_blocks_for_epoch_round`, which removes all payloads up to and including the committed round. [6](#0-5) 

**Two Failure Modes:**

**Mode 1 - Early Verification Failure:** When `process_ordered_block` attempts to verify payloads immediately after the race occurs, verification fails because payloads were removed. The block is dropped and never retried. [7](#0-6) 

**Mode 2 - Infinite Retry Loop (More Severe):** If the block passes early verification and enters the execution pipeline through `finalize_ordered_block`, it eventually reaches the `materialize` phase which contains an infinite retry loop. [8](#0-7) 

During materialization, `get_transactions_for_observer` attempts to retrieve the payload but finds it missing (removed by commit callback), returning an `InternalError`. [9](#0-8) 

The error causes the infinite loop to retry indefinitely with 100ms sleeps, as documented by the comment "the loop can only be abort by the caller" - there is no automatic exit condition.

**Root Cause:** The locking granularity is insufficient - the lock is released after verifying payload existence but before the execution pipeline accesses those payloads. Concurrent commit callbacks can remove payloads during this window, violating the invariant that verified blocks have accessible payloads.

## Impact Explanation

**Critical Severity** per Aptos bug bounty category: "Total loss of liveness/network availability"

**Infinite Retry Loop Impact:**
- The execution pipeline enters an infinite retry loop attempting to materialize a block whose payloads no longer exist
- All subsequent block processing is blocked waiting for the stuck materialization task
- The consensus observer cannot process any further blocks, causing it to fall permanently behind the network
- Manual intervention (process restart) is required to recover

**Block Loss Impact:**
- Valid blocks that passed all cryptographic and structural verification are permanently lost when the early verification path fails
- The pending block is removed from storage and cannot be re-processed if it arrives again
- Payloads for these blocks may also be removed, making recovery impossible without re-synchronization

**Network-Wide Impact:**
- Multiple consensus observers experiencing this race simultaneously would create a de-facto network partition
- Consensus observers are critical for network participation and validation
- Loss of observer liveness impacts network decentralization and availability guarantees

This directly violates the liveness property of the consensus protocol and constitutes a critical failure mode.

## Likelihood Explanation

**High Likelihood** - This race condition occurs naturally during normal network operations:

1. **Race Window Always Present:** Every block that transitions from pending (waiting for payloads) to ready creates a race window between payload verification and payload access

2. **Concurrent Execution:** The execution pipeline processes multiple blocks concurrently, with commit callbacks firing asynchronously from the block processing thread

3. **No Synchronization:** There is no lock held across the entire critical section from payload verification through execution, allowing commit callbacks to interleave

4. **Realistic Trigger Scenario:**
   - Block A sent to execution, currently executing
   - Block B receives payloads, becomes ready, passes verification
   - Block B sent to execution pipeline
   - Block C (higher round) completes execution faster and commits
   - Block C's commit callback removes all payloads up to its round (including Block B's payloads)
   - Block B's materialization fails with missing payloads
   - Infinite retry loop engaged

5. **High Throughput Amplification:** Higher transaction throughput increases concurrent block processing, raising the probability that the timing aligns for the race condition

6. **Deterministic Once Triggered:** When the timing aligns, the failure is deterministic - the infinite retry loop will reliably block all progress

No special attacker capabilities are required - this is a pure implementation bug that manifests under normal concurrent load conditions.

## Recommendation

**Implement Reference Counting or Extended Lock Protection:**

1. **Option 1 - Reference Counting:** Implement reference counting on payloads so they're only removed when no in-flight processing holds references:
   - Add a reference count to `BlockPayloadStatus`
   - Increment when a block enters processing (`order_ready_pending_block`)
   - Decrement after execution completes (in commit callback or error paths)
   - Only remove payloads when reference count reaches zero

2. **Option 2 - Extended Critical Section:** Hold the lock across the entire critical section:
   - Acquire lock in `order_ready_pending_block`
   - Hold lock through payload verification in `process_ordered_block`
   - Only release after payloads are safely copied or block is inserted into execution pipeline
   - May impact concurrency but ensures correctness

3. **Option 3 - Payload Lifecycle Management:** Separate committed payload removal from in-flight payload protection:
   - Mark payloads as "in-use" when blocks enter processing
   - Commit callbacks only remove payloads that are not marked "in-use"
   - Clear "in-use" marker after execution completes or fails

**Add Timeout to Retry Loop:** As an immediate mitigation, add a timeout or maximum retry count to the infinite loop in `materialize` to prevent permanent liveness loss:
   - Track retry count or elapsed time
   - After threshold, return fatal error instead of retrying
   - Allow fallback mechanisms (state sync) to recover

## Proof of Concept

The race condition can be demonstrated by examining the code flow under concurrent execution conditions. While a complete runnable PoC would require orchestrating specific timing in a test environment, the vulnerability is evident from the code structure:

**Race Condition Timing:**
```
Thread 1 (Block Processing):          Thread 2 (Execution Pipeline):
1. Lock acquired
2. all_payloads_exist() → true
3. Remove pending block
4. Lock released
                                      5. Block A commits
                                      6. Commit callback fires
                                      7. remove_blocks_for_epoch_round()
                                      8. Payloads removed
8. process_ordered_block starts
9. verify_payloads → FAILURE
   OR
9. Block sent to execution
10. materialize_block called
                                      11. Block B also commits
                                      12. More payloads removed
11. get_transactions_for_observer()
12. Payload missing → InternalError
13. Retry loop → INFINITE
```

The vulnerability is structural in the locking and payload lifecycle management design, requiring code changes rather than runtime exploitation to trigger reliably in a test environment.

### Citations

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L341-353)
```rust
    async fn order_ready_pending_block(&mut self, block_epoch: u64, block_round: Round) {
        // Remove any ready pending block
        let pending_block_with_metadata = self
            .observer_block_data
            .lock()
            .remove_ready_pending_block(block_epoch, block_round);

        // Process the ready ordered block (if it exists)
        if let Some(pending_block_with_metadata) = pending_block_with_metadata {
            self.process_ordered_block(pending_block_with_metadata)
                .await;
        }
    }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L428-438)
```rust
        self.observer_block_data
            .lock()
            .insert_block_payload(block_payload, verified_payload);

        // Check if there are blocks that were missing payloads but are
        // now ready because of the new payload. Note: this should only
        // be done if the payload has been verified correctly.
        if verified_payload {
            self.order_ready_pending_block(block_epoch, block_round)
                .await;
        }
```

**File:** consensus/src/consensus_observer/observer/consensus_observer.rs (L754-771)
```rust
        // Verify the block payloads against the ordered block
        if let Err(error) = self
            .observer_block_data
            .lock()
            .verify_payloads_against_ordered_block(&ordered_block)
        {
            // Log the error and update the invalid message counter
            error!(
                LogSchema::new(LogEntry::ConsensusObserver).message(&format!(
                    "Failed to verify block payloads against ordered block! Ignoring: {:?}, from peer: {:?}. Error: {:?}",
                    ordered_block.proof_block_info(),
                    peer_network_id,
                    error
                ))
            );
            increment_invalid_message_counter(&peer_network_id, metrics::ORDERED_BLOCK_LABEL);
            return;
        }
```

**File:** consensus/src/consensus_observer/observer/pending_blocks.rs (L217-228)
```rust
        if let Some((epoch_and_round, pending_block)) = self.blocks_without_payloads.pop_last() {
            // If all payloads exist for the block, then the block is ready
            if block_payload_store.all_payloads_exist(pending_block.ordered_block().blocks()) {
                ready_block = Some(pending_block);
            } else {
                // Otherwise, check if we're still waiting for higher payloads for the block
                let last_pending_block_round = pending_block.ordered_block().last_block().round();
                if last_pending_block_round > received_payload_round {
                    blocks_at_higher_rounds.insert(epoch_and_round, pending_block);
                }
            }
        }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L48-57)
```rust
    pub fn all_payloads_exist(&self, blocks: &[Arc<PipelinedBlock>]) -> bool {
        let block_payloads = self.block_payloads.lock();
        blocks.iter().all(|block| {
            let epoch_and_round = (block.epoch(), block.round());
            matches!(
                block_payloads.get(&epoch_and_round),
                Some(BlockPayloadStatus::AvailableAndVerified(_))
            )
        })
    }
```

**File:** consensus/src/consensus_observer/observer/payload_store.rs (L112-119)
```rust
    pub fn remove_blocks_for_epoch_round(&self, epoch: u64, round: Round) {
        // Determine the round to split off
        let split_off_round = round.saturating_add(1);

        // Remove the blocks from the payload store
        let mut block_payloads = self.block_payloads.lock();
        *block_payloads = block_payloads.split_off(&(epoch, split_off_round));
    }
```

**File:** consensus/src/consensus_observer/observer/block_data.rs (L182-189)
```rust
    fn handle_committed_blocks(&mut self, ledger_info: LedgerInfoWithSignatures) {
        // Remove the committed blocks from the payload and ordered block stores
        self.block_payload_store.remove_blocks_for_epoch_round(
            ledger_info.commit_info().epoch(),
            ledger_info.commit_info().round(),
        );
        self.ordered_block_store
            .remove_blocks_for_commit(&ledger_info);
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L634-646)
```rust
        let result = loop {
            match preparer.materialize_block(&block, qc_rx.clone()).await {
                Ok(input_txns) => break input_txns,
                Err(e) => {
                    warn!(
                        "[BlockPreparer] failed to prepare block {}, retrying: {}",
                        block.id(),
                        e
                    );
                    tokio::time::sleep(Duration::from_millis(100)).await;
                },
            }
        };
```

**File:** consensus/src/payload_manager/co_payload_manager.rs (L49-57)
```rust
        Entry::Vacant(_) => {
            // This shouldn't happen (the payload should already be present)
            let error = format!(
                "Missing payload data for block epoch {}, round {}!",
                block.epoch(),
                block.round()
            );
            return Err(InternalError { error });
        },
```
