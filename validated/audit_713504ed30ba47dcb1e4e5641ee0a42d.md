# Audit Report

## Title
Blocking Thread Pool Exhaustion via Coordinated Secret Share Flooding

## Summary
A malicious validator can exhaust the tokio blocking thread pool by withholding secret shares across multiple rounds and then releasing them simultaneously, causing up to 200 concurrent expensive cryptographic aggregation operations that starve other critical blocking operations and degrade validator node performance.

## Finding Description

The secret sharing aggregation mechanism uses `tokio::task::spawn_blocking` to offload expensive cryptographic operations to a blocking thread pool without any application-level concurrency control. [1](#0-0) 

The tokio runtime's blocking thread pool is globally limited to 64 threads. [2](#0-1) 

The system accepts secret shares for up to 200 rounds in the future relative to the highest known round. [3](#0-2) 

This future-round validation allows shares to be buffered across many rounds. [4](#0-3) [5](#0-4) 

**Attack Path:**

1. A Byzantine validator withholds their secret shares for up to 200 consecutive rounds
2. During this period, honest validators broadcast their shares, accumulating shares for each round that are just below the threshold (e.g., 65% of total stake when threshold is 67%)
3. The attacker suddenly broadcasts all 200 withheld shares in rapid succession
4. Each share is processed sequentially through the event loop. [6](#0-5) 
5. When each share pushes its respective round over the aggregation threshold, `try_aggregate()` is called. [7](#0-6) 
6. This spawns 200 concurrent `spawn_blocking` tasks, but only 64 can execute simultaneously due to the thread pool limit
7. The remaining 136 tasks queue up, and each aggregation involves expensive operations including FFT-based Lagrange coefficient computation for secret reconstruction. [8](#0-7) 
8. The blocking thread pool remains saturated for several seconds, starving other operations that depend on it (REST API handlers, storage operations, other blocking I/O)

**Critical Finding:** The code uses `tokio::task::spawn_blocking` directly without any `BoundedExecutor` or semaphore-based concurrency control, unlike other parts of the codebase that properly bound concurrent blocking operations. [9](#0-8) 

**Security Guarantee Violated:** The system fails to bound concurrent expensive blocking operations, allowing a single Byzantine validator (within the AptosBFT 3f+1 threat model) to monopolize shared computational resources. [10](#0-9) 

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty framework's "Validator Node Slowdowns" category, which explicitly includes "DoS through resource exhaustion" as valid impact.

**Concrete Impact:**
- **Validator node performance degradation**: The saturated blocking thread pool causes degraded performance across the entire validator node
- **Node responsiveness suffers**: The blocking pool is shared with REST API handlers and other critical operations that use `spawn_blocking`
- **Consensus liveness impact**: While this doesn't violate consensus safety properties, slow block processing can impact network liveness

**Why Not Critical:**
- Aggregation results remain cryptographically correct (no safety violation)
- The attack doesn't prevent eventual recovery (thread pool clears after aggregations complete)
- No fund loss or permanent damage occurs
- Consensus can continue, albeit more slowly

This aligns with HIGH severity ($50,000 category) rather than CRITICAL severity, as it causes significant performance degradation but does not compromise consensus safety or result in fund loss.

## Likelihood Explanation

**Likelihood: Medium to High**

**Requirements for Exploitation:**
- Attacker must be a validator to create valid cryptographic shares (within AptosBFT threat model for Byzantine validators < f out of 3f+1)
- Attacker needs sufficient stake that their share can tip rounds over the threshold (typically 5-10% is sufficient when threshold is ~67%)
- Timing coordination: wait for honest shares to accumulate just below threshold, then broadcast all withheld shares

**Execution Simplicity:**
- Attack is straightforward: simply withhold shares for multiple rounds, then broadcast en masse
- No complex race conditions or precise timing required
- No collusion with other validators needed
- Can be fully automated with simple network manipulation

**Realistic Feasibility:**
- A single Byzantine validator with even 5-10% stake can execute this attack
- The 200-round acceptance window provides ample opportunity
- AptosBFT's threat model explicitly allows for Byzantine validators (up to f out of 3f+1)
- Network bandwidth is not a constraint (shares are small, hundreds can be transmitted rapidly)

## Recommendation

Implement bounded concurrency control for secret share aggregation operations:

1. **Add a `BoundedExecutor` for aggregation tasks**: Replace direct `tokio::task::spawn_blocking` calls with bounded execution through a dedicated executor with a reasonable concurrency limit (e.g., 8-16 concurrent aggregations).

2. **Rate-limit share processing per validator**: Track the number of pending aggregations triggered by each validator and apply backpressure when excessive.

3. **Implement aggregation queueing with priority**: Queue aggregation requests and process them with priority based on round number, preventing older rounds from being starved.

4. **Add telemetry**: Monitor blocking thread pool utilization and aggregation queue depth to detect potential attacks in progress.

Example fix structure:
```rust
// In SecretShareStore::new(), create a bounded executor for aggregations
let aggregation_executor = BoundedExecutor::new(
    MAX_CONCURRENT_AGGREGATIONS,
    runtime_handle.clone()
);

// In try_aggregate(), use the bounded executor instead of spawn_blocking
aggregation_executor.spawn_blocking(move || {
    let maybe_key = SecretShare::aggregate(self.shares.values(), &dec_config);
    // ... rest of aggregation logic
}).await;
```

## Proof of Concept

A proof of concept would require:
1. Setting up a local testnet with 4 validators (3f+1 = 4, f = 1)
2. Configuring one validator as Byzantine
3. Having the Byzantine validator withhold shares for 200 rounds
4. Broadcasting all 200 shares simultaneously
5. Monitoring blocking thread pool metrics to observe saturation
6. Measuring REST API latency and block processing time during the attack

The attack logic would be:
```rust
// Pseudocode for Byzantine validator behavior
let mut withheld_shares = Vec::new();

// Phase 1: Withhold shares for 200 rounds
for round in current_round..(current_round + 200) {
    let share = generate_secret_share(round);
    withheld_shares.push(share);
    // Don't broadcast
}

// Phase 2: Wait for honest validators to accumulate shares
wait_for_shares_below_threshold();

// Phase 3: Flood all withheld shares simultaneously
for share in withheld_shares {
    broadcast_share(share);
}

// Observe: 200 spawn_blocking tasks queued, only 64 execute concurrently
// Result: Blocking thread pool saturated, node performance degraded
```

## Notes

This vulnerability demonstrates a resource exhaustion attack that exploits the lack of bounded concurrency control in the secret sharing aggregation path. While AptosBFT is designed to tolerate Byzantine validators (up to f out of 3f+1 in a 3f+1 model), the implementation does not adequately protect against resource exhaustion attacks from individual Byzantine validators.

The distinction between this vulnerability and out-of-scope "Network DoS attacks" is critical: this is an application-level protocol exploitation requiring validator access and protocol knowledge, not a simple network flood attack. It exploits specific protocol logic (secret share aggregation) through legitimate protocol operations to exhaust shared computational resources.

### Citations

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L55-70)
```rust
        tokio::task::spawn_blocking(move || {
            let maybe_key = SecretShare::aggregate(self.shares.values(), &dec_config);
            match maybe_key {
                Ok(key) => {
                    let dec_key = SecretSharedKey::new(metadata, key);
                    let _ = decision_tx.unbounded_send(dec_key);
                },
                Err(e) => {
                    warn!(
                        epoch = metadata.epoch,
                        round = metadata.round,
                        "Aggregation error: {e}"
                    );
                },
            }
        });
```

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L244-248)
```rust
        ensure!(metadata.epoch == self.epoch, "Share from different epoch");
        ensure!(
            metadata.round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
```

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L262-266)
```rust
        ensure!(metadata.epoch == self.epoch, "Share from different epoch");
        ensure!(
            metadata.round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
```

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L272-274)
```rust
        item.add_share(share, weight)?;
        item.try_aggregate(&self.secret_share_config, self.decision_tx.clone());
        Ok(item.has_decision())
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```

**File:** consensus/src/rand/rand_gen/types.rs (L26-26)
```rust
pub const FUTURE_ROUNDS_TO_ACCEPT: u64 = 200;
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L310-320)
```rust
            SecretShareMessage::Share(share) => {
                info!(LogSchema::new(LogEvent::ReceiveSecretShare)
                    .author(self.author)
                    .epoch(share.epoch())
                    .round(share.metadata().round)
                    .remote_peer(*share.author()));

                if let Err(e) = self.secret_share_store.lock().add_share(share) {
                    warn!("[SecretShareManager] Failed to add share: {}", e);
                }
            },
```

**File:** types/src/secret_sharing.rs (L84-98)
```rust
    pub fn aggregate<'a>(
        dec_shares: impl Iterator<Item = &'a SecretShare>,
        config: &SecretShareConfig,
    ) -> anyhow::Result<DecryptionKey> {
        let threshold = config.threshold();
        let shares: Vec<SecretKeyShare> = dec_shares
            .map(|dec_share| dec_share.share.clone())
            .take(threshold as usize)
            .collect();
        let decryption_key =
            <FPTXWeighted as BatchThresholdEncryption>::reconstruct_decryption_key(
                &shares,
                &config.config,
            )?;
        Ok(decryption_key)
```

**File:** crates/bounded-executor/src/executor.rs (L1-50)
```rust
// Copyright (c) Aptos Foundation
// Licensed pursuant to the Innovation-Enabling Source Code License, available at https://github.com/aptos-labs/aptos-core/blob/main/LICENSE

//! A bounded tokio [`Handle`]. Only a bounded number of tasks can run
//! concurrently when spawned through this executor, defined by the initial
//! `capacity`.

use futures::future::{Future, FutureExt};
use std::sync::Arc;
use tokio::{
    runtime::Handle,
    sync::{OwnedSemaphorePermit, Semaphore},
    task::JoinHandle,
};

#[derive(Clone, Debug)]
pub struct BoundedExecutor {
    semaphore: Arc<Semaphore>,
    executor: Handle,
}

impl BoundedExecutor {
    /// Create a new `BoundedExecutor` from an existing tokio [`Handle`]
    /// with a maximum concurrent task capacity of `capacity`.
    pub fn new(capacity: usize, executor: Handle) -> Self {
        let semaphore = Arc::new(Semaphore::new(capacity));
        Self {
            semaphore,
            executor,
        }
    }

    async fn acquire_permit(&self) -> OwnedSemaphorePermit {
        self.semaphore.clone().acquire_owned().await.unwrap()
    }

    fn try_acquire_permit(&self) -> Option<OwnedSemaphorePermit> {
        self.semaphore.clone().try_acquire_owned().ok()
    }

    /// Spawn a [`Future`] on the `BoundedExecutor`. This function is async and
    /// will block if the executor is at capacity until one of the other spawned
    /// futures completes. This function returns a [`JoinHandle`] that the caller
    /// can `.await` on for the results of the [`Future`].
    pub async fn spawn<F>(&self, future: F) -> JoinHandle<F::Output>
    where
        F: Future + Send + 'static,
        F::Output: Send + 'static,
    {
        let permit = self.acquire_permit().await;
```

**File:** consensus/README.md (L14-19)
```markdown
Agreement on the database state must be reached between validators, even if
there are Byzantine faults. The Byzantine failures model allows some validators
to arbitrarily deviate from the protocol without constraint, with the exception
of being computationally bound (and thus not able to break cryptographic assumptions). Byzantine faults are worst-case errors where validators collude and behave maliciously to try to sabotage system behavior. A consensus protocol that tolerates Byzantine faults caused by malicious or hacked validators can also mitigate arbitrary hardware and software failures.

AptosBFT assumes that a set of 3f + 1 votes is distributed among a set of validators that may be honest or Byzantine. AptosBFT remains safe, preventing attacks such as double spends and forks when at most f votes are controlled by Byzantine validators &mdash; also implying that at least 2f+1 votes are honest.  AptosBFT remains live, committing transactions from clients, as long as there exists a global stabilization time (GST), after which all messages between honest validators are delivered to other honest validators within a maximal network delay $\Delta$ (this is the partial synchrony model introduced in [DLS](https://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf)). In addition to traditional guarantees, AptosBFT maintains safety when validators crash and restart â€” even if all valida ... (truncated)
```
