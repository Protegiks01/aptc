# Audit Report

## Title
Unbounded Task Spawning in Payload Prefetching Causes Validator Resource Exhaustion

## Summary
The `prefetch_payload_data` method in QuorumStorePayloadManager does not validate the number of batches in a received block proposal payload. A malicious proposer can create a proposal containing thousands of unique batches, causing all validators to spawn unbounded concurrent tasks during prefetch, leading to memory exhaustion and denial of service.

## Finding Description

When a validator receives a block proposal, the consensus system verifies the proposal and then calls `prefetch_payload_data` to asynchronously fetch batch data before the proposal reaches the round manager. However, there is a critical missing validation that allows resource exhaustion:

**Missing Batch Count Validation in Payload Verification:**

The `Payload::verify()` method validates proof signatures and inline batch digests but does NOT check if the number of batches exceeds the configured `max_num_batches` limit (default: 20 batches). [1](#0-0) 

This is inconsistent with other message types which DO enforce this limit:
- `BatchMsg::verify()` checks batch count [2](#0-1) 
- `SignedBatchInfoMsg::verify()` checks batch count [3](#0-2) 
- `ProofOfStoreMsg::verify()` checks proof count [4](#0-3) 

**Unbounded Task Spawning During Prefetch:**

When `prefetch_payload_data` is called after proposal verification, it iterates over all batches in the payload and calls `request_transactions` [5](#0-4) , which invokes `batch_reader.get_batch()` for each batch without limit [6](#0-5) .

The `get_or_fetch_batch` method spawns a tokio task via `tokio::spawn` for each unique batch that hasn't been fetched yet [7](#0-6) . While the `inflight_fetch_requests` map prevents duplicate tasks for the same batch [8](#0-7) , it does NOT limit the total number of concurrent tasks across different batches.

**Attack Vector:**
1. Malicious proposer creates a block proposal with a payload containing hundreds to thousands of unique batches
2. The payload size is only limited by the network message size (64 MiB) [9](#0-8) , allowing potentially thousands of `ProofOfStore` entries (~200-300 bytes each)
3. Payload verification passes because there's no batch count validation
4. After verification in `ProposalMsg::verify()` [10](#0-9) , `prefetch_payload_data` is triggered [11](#0-10) 
5. For each of the thousands of batches, a tokio task is spawned
6. All validators receiving the proposal spawn thousands of concurrent tasks simultaneously
7. Each task attempts to fetch batch data, consuming memory for task metadata, stack space, and network buffers
8. Per-peer quotas in BatchStore are checked when batches are STORED via `update_quota()` in `insert_to_cache()` [12](#0-11) , not when tasks are SPAWNED

## Impact Explanation

This vulnerability qualifies as **High Severity** under the Aptos bug bounty program because it causes "Validator node slowdowns" which can lead to:

- **Memory Exhaustion**: Spawning thousands of tokio tasks consumes memory for task metadata, stack space, and pending network operations
- **Scheduler Overload**: The tokio runtime becomes overwhelmed managing thousands of concurrent tasks
- **Network Resource Exhaustion**: Thousands of concurrent batch fetch requests consume network bandwidth and file descriptors
- **Potential Crashes**: In extreme cases, memory exhaustion can cause validator processes to crash via OOM

The attack affects ALL validators that receive the malicious proposal, potentially causing network-wide service degradation. While per-peer storage quotas exist (120 MB memory, 300 MB disk, 300k batches) [13](#0-12) , these are insufficient protection because:
1. They apply only when batches are stored, not when tasks are spawned
2. The resource consumption from spawning thousands of tasks occurs before quota checks
3. Quotas are per-peer, but a malicious payload can include batches from multiple peers

## Likelihood Explanation

**Likelihood: Medium**

The attack requires:
- The attacker to be a validator selected as proposer in the current round
- No collusion with other validators is needed
- A single malicious proposal can trigger the attack

While being a proposer requires validator status, this is within the standard Byzantine threat model for BFT consensus (tolerating < 1/3 Byzantine validators). The attack is straightforward to execute once the proposer role is obtained, requiring only crafting a proposal with an excessive number of unique batches within the network message size limit.

## Recommendation

Add batch count validation to `Payload::verify()` method, consistent with other message types:

```rust
// In consensus/consensus-types/src/common.rs, Payload::verify() method
pub fn verify(
    &self,
    verifier: &ValidatorVerifier,
    proof_cache: &ProofCache,
    quorum_store_enabled: bool,
    max_num_batches: usize, // Add this parameter
) -> anyhow::Result<()> {
    match (quorum_store_enabled, self) {
        (true, Payload::InQuorumStore(proof_with_status)) => {
            ensure!(
                proof_with_status.proofs.len() <= max_num_batches,
                "Too many batches: {} > {}",
                proof_with_status.proofs.len(),
                max_num_batches
            );
            Self::verify_with_cache(&proof_with_status.proofs, verifier, proof_cache)
        },
        // Add similar checks for other payload types
        ...
    }
}
```

Additionally, consider adding a global limit on concurrent prefetch tasks in `get_or_fetch_batch` using a semaphore or task counter.

## Proof of Concept

The vulnerability can be demonstrated by:
1. Creating a malicious block proposal with >1000 unique batch digests
2. Observing that `Payload::verify()` passes without checking batch count against the configured `receiver_max_num_batches` (default: 20) [14](#0-13) 
3. Monitoring memory usage and task count as `prefetch_payload_data` spawns unbounded tasks
4. Comparing with `BatchMsg` which properly rejects messages exceeding the limit

## Notes

This vulnerability exploits an inconsistency in validation logic rather than a pure network DoS attack. The missing validation in `Payload::verify()` is particularly concerning because:
- The limit exists in configuration (`receiver_max_num_batches`)
- Other message types (`BatchMsg`, `SignedBatchInfoMsg`, `ProofOfStoreMsg`) all enforce this limit
- Only block proposal payloads bypass this check
- The verification occurs in `ProposalMsg::verify()` before prefetching begins, making it the appropriate place to enforce limits

### Citations

**File:** consensus/consensus-types/src/common.rs (L574-632)
```rust
    pub fn verify(
        &self,
        verifier: &ValidatorVerifier,
        proof_cache: &ProofCache,
        quorum_store_enabled: bool,
    ) -> anyhow::Result<()> {
        match (quorum_store_enabled, self) {
            (false, Payload::DirectMempool(_)) => Ok(()),
            (true, Payload::InQuorumStore(proof_with_status)) => {
                Self::verify_with_cache(&proof_with_status.proofs, verifier, proof_cache)
            },
            (true, Payload::InQuorumStoreWithLimit(proof_with_status)) => Self::verify_with_cache(
                &proof_with_status.proof_with_data.proofs,
                verifier,
                proof_cache,
            ),
            (true, Payload::QuorumStoreInlineHybrid(inline_batches, proof_with_data, _))
            | (true, Payload::QuorumStoreInlineHybridV2(inline_batches, proof_with_data, _)) => {
                Self::verify_with_cache(&proof_with_data.proofs, verifier, proof_cache)?;
                Self::verify_inline_batches(
                    inline_batches.iter().map(|(info, txns)| (info, txns)),
                )?;
                Ok(())
            },
            (true, Payload::OptQuorumStore(OptQuorumStorePayload::V1(p))) => {
                let proof_with_data = p.proof_with_data();
                Self::verify_with_cache(&proof_with_data.batch_summary, verifier, proof_cache)?;
                Self::verify_inline_batches(
                    p.inline_batches()
                        .iter()
                        .map(|batch| (batch.info(), batch.transactions())),
                )?;
                Self::verify_opt_batches(verifier, p.opt_batches())?;
                Ok(())
            },
            (true, Payload::OptQuorumStore(OptQuorumStorePayload::V2(p))) => {
                if true {
                    bail!("OptQuorumStorePayload::V2 cannot be accepted yet");
                }
                #[allow(unreachable_code)]
                {
                    let proof_with_data = p.proof_with_data();
                    Self::verify_with_cache(&proof_with_data.batch_summary, verifier, proof_cache)?;
                    Self::verify_inline_batches(
                        p.inline_batches()
                            .iter()
                            .map(|batch| (batch.info(), batch.transactions())),
                    )?;
                    Self::verify_opt_batches(verifier, p.opt_batches())?;
                    Ok(())
                }
            },
            (_, _) => Err(anyhow::anyhow!(
                "Wrong payload type. Expected Payload::InQuorumStore {} got {} ",
                quorum_store_enabled,
                self
            )),
        }
    }
```

**File:** consensus/src/quorum_store/types.rs (L440-445)
```rust
        ensure!(
            self.batches.len() <= max_num_batches,
            "Too many batches: {} > {}",
            self.batches.len(),
            max_num_batches
        );
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L372-376)
```rust
            self.signed_infos.len() <= max_num_batches,
            "Too many batches: {} > {}",
            self.signed_infos.len(),
            max_num_batches
        );
```

**File:** consensus/consensus-types/src/proof_of_store.rs (L573-578)
```rust
        ensure!(
            self.proofs.len() <= max_num_proofs,
            "Too many proofs: {} > {}",
            self.proofs.len(),
            max_num_proofs
        );
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L89-109)
```rust
    fn request_transactions(
        batches: Vec<(BatchInfo, Vec<PeerId>)>,
        block_timestamp: u64,
        batch_reader: Arc<dyn BatchReader>,
    ) -> Vec<Shared<Pin<Box<dyn Future<Output = ExecutorResult<Vec<SignedTransaction>>> + Send>>>>
    {
        let mut futures = Vec::new();
        for (batch_info, responders) in batches {
            trace!(
                "QSE: requesting batch {:?}, time = {}",
                batch_info,
                block_timestamp
            );
            if block_timestamp <= batch_info.expiration() {
                futures.push(batch_reader.get_batch(batch_info, responders.clone()));
            } else {
                debug!("QSE: skipped expired batch {}", batch_info.digest());
            }
        }
        futures
    }
```

**File:** consensus/src/payload_manager/quorum_store_payload_manager.rs (L210-306)
```rust
    fn prefetch_payload_data(&self, payload: &Payload, author: Author, timestamp: u64) {
        // This is deprecated.
        // TODO(ibalajiarun): Remove this after migrating to OptQuorumStore type
        let request_txns_and_update_status =
            move |proof_with_status: &ProofWithData, batch_reader: Arc<dyn BatchReader>| {
                Self::request_transactions(
                    proof_with_status
                        .proofs
                        .iter()
                        .map(|proof| {
                            (
                                proof.info().clone(),
                                proof.shuffled_signers(&self.ordered_authors),
                            )
                        })
                        .collect(),
                    timestamp,
                    batch_reader,
                );
            };

        fn prefetch_helper<T: TDataInfo>(
            data_pointer: &BatchPointer<T>,
            batch_reader: Arc<dyn BatchReader>,
            author: Option<Author>,
            timestamp: u64,
            ordered_authors: &[PeerId],
        ) {
            let batches_and_responders = data_pointer
                .batch_summary
                .iter()
                .map(|data_info| {
                    let mut signers = data_info.signers(ordered_authors);
                    if let Some(author) = author {
                        signers.push(author);
                    }
                    (data_info.info().clone(), signers)
                })
                .collect();
            QuorumStorePayloadManager::request_transactions(
                batches_and_responders,
                timestamp,
                batch_reader,
            );
        }

        match payload {
            Payload::InQuorumStore(proof_with_status) => {
                request_txns_and_update_status(proof_with_status, self.batch_reader.clone());
            },
            Payload::InQuorumStoreWithLimit(proof_with_data) => {
                request_txns_and_update_status(
                    &proof_with_data.proof_with_data,
                    self.batch_reader.clone(),
                );
            },
            Payload::QuorumStoreInlineHybrid(_, proof_with_data, _)
            | Payload::QuorumStoreInlineHybridV2(_, proof_with_data, _) => {
                request_txns_and_update_status(proof_with_data, self.batch_reader.clone());
            },
            Payload::DirectMempool(_) => {
                unreachable!()
            },
            Payload::OptQuorumStore(OptQuorumStorePayload::V1(p)) => {
                prefetch_helper(
                    p.opt_batches(),
                    self.batch_reader.clone(),
                    Some(author),
                    timestamp,
                    &self.ordered_authors,
                );
                prefetch_helper(
                    p.proof_with_data(),
                    self.batch_reader.clone(),
                    None,
                    timestamp,
                    &self.ordered_authors,
                )
            },
            Payload::OptQuorumStore(OptQuorumStorePayload::V2(p)) => {
                prefetch_helper(
                    p.opt_batches(),
                    self.batch_reader.clone(),
                    Some(author),
                    timestamp,
                    &self.ordered_authors,
                );
                prefetch_helper(
                    p.proof_with_data(),
                    self.batch_reader.clone(),
                    None,
                    timestamp,
                    &self.ordered_authors,
                )
            },
        };
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L383-391)
```rust
            let value_to_be_stored = if self
                .peer_quota
                .entry(author)
                .or_insert(QuotaManager::new(
                    self.db_quota,
                    self.memory_quota,
                    self.batch_quota,
                ))
                .update_quota(value.num_bytes() as usize)?
```

**File:** consensus/src/quorum_store/batch_store.rs (L670-676)
```rust
        self.inflight_fetch_requests
            .lock()
            .entry(*batch_info.digest())
            .and_modify(|fetch_unit| {
                fetch_unit.responders.lock().append(&mut responders);
            })
            .or_insert_with(|| {
```

**File:** consensus/src/quorum_store/batch_store.rs (L714-714)
```rust
                tokio::spawn(fut.clone());
```

**File:** network/framework/src/constants.rs (L21-21)
```rust
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```

**File:** consensus/consensus-types/src/proposal_msg.rs (L97-110)
```rust
        let (payload_result, sig_result) = rayon::join(
            || {
                self.proposal().payload().map_or(Ok(()), |p| {
                    p.verify(validator, proof_cache, quorum_store_enabled)
                })
            },
            || {
                self.proposal()
                    .validate_signature(validator)
                    .map_err(|e| format_err!("{:?}", e))
            },
        );
        payload_result?;
        sig_result?;
```

**File:** consensus/src/epoch_manager.rs (L1767-1771)
```rust
                        payload_manager.prefetch_payload_data(
                            payload,
                            p.proposer(),
                            p.proposal().timestamp_usecs(),
                        );
```

**File:** config/src/config/quorum_store_config.rs (L122-122)
```rust
            receiver_max_num_batches: 20,
```

**File:** config/src/config/quorum_store_config.rs (L133-135)
```rust
            memory_quota: 120_000_000,
            db_quota: 300_000_000,
            batch_quota: 300_000,
```
