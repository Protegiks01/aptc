# Audit Report

## Title
Unbounded Blocking Thread Pool Exhaustion in RPC Response Deserialization

## Summary
The `send_rb_rpc_raw()` function uses unbounded `tokio::task::spawn_blocking` for deserializing RPC responses, creating a resource exhaustion vulnerability. Under high concurrent load from multiple reliable broadcasts, this can exhaust the tokio blocking thread pool (limited to 64 threads in consensus runtime), causing validator node slowdowns and potential consensus liveness degradation.

## Finding Description
The reliable broadcast mechanism used throughout consensus (DAG, commit votes, randomness generation) sends RPCs to multiple validators concurrently. When RPC responses return, each response is deserialized using `tokio::task::spawn_blocking` without any concurrency control. [1](#0-0) 

This contrasts sharply with how incoming network messages are handled, where deserialization tasks are explicitly bounded using `buffer_unordered(max_parallel_deserialization_tasks)`: [2](#0-1) 

The codebase includes a `BoundedExecutor` with a `spawn_blocking` method designed for exactly this purpose: [3](#0-2) 

However, `NetworkSender` does not have access to a `BoundedExecutor`, and reliable broadcast RPC response deserialization bypasses all concurrency controls. The reliable broadcast system uses `BoundedExecutor` for aggregation tasks but NOT for deserialization: [4](#0-3) [5](#0-4) 

The consensus runtime is configured with only 64 blocking threads (not 512 as tokio's default): [6](#0-5) [7](#0-6) 

**Attack/Trigger Scenario:**
1. During high consensus activity (multiple DAG rounds, commit votes, randomness generation), reliable broadcasts send RPCs to 100+ validators
2. When validators respond quickly, responses arrive in bursts
3. Each response spawns an unbounded blocking task via `spawn_blocking`
4. With multiple concurrent broadcasts Ã— validator set size, hundreds of blocking tasks are queued
5. The 64-thread blocking pool becomes saturated
6. Legitimate blocking operations (file I/O, signature verification) are delayed
7. Consensus operations slow down due to delayed message processing

## Impact Explanation
This vulnerability falls under **High Severity** per Aptos bug bounty criteria: "Validator node slowdowns" (up to $50,000).

**Quantified Impact:**
- Affects all validator nodes during periods of high consensus activity
- Can cause consensus liveness degradation when blocking pool is exhausted
- Degrades performance of all blocking operations (storage I/O, signature verification)
- Could cascade into broader consensus failures if validators cannot process messages timely

This does not reach Critical severity because:
- It does not cause permanent liveness loss (recovers when load decreases)
- No funds are at risk
- No consensus safety violations (only liveness impact)

## Likelihood Explanation
**Likelihood: Medium to High**

This vulnerability can manifest during legitimate network operation without requiring malicious actors:

1. **Organic triggers**: Epoch transitions, DAG consensus with high validator counts, concurrent commit vote broadcasts, randomness generation rounds
2. **No attacker required**: The flaw manifests under normal high-load conditions
3. **Realistic parameters**: With 100-200 validators and 3-5 concurrent broadcast types, 500-1000 concurrent RPC responses are realistic
4. **Fast networks amplify**: Modern validator networks with low latency cause response bursts
5. **Limited thread pool**: Only 64 blocking threads makes saturation more likely than with tokio's default 512

The likelihood increases proportionally with validator set size, network performance, and consensus protocol complexity.

## Recommendation
Modify `NetworkSender` to accept a `BoundedExecutor` and use `executor.spawn_blocking()` instead of `tokio::task::spawn_blocking()` for RPC response deserialization in both `send_rb_rpc_raw()` and `send_rb_rpc()` methods. This would ensure deserialization tasks respect the same concurrency limits as other consensus operations.

## Proof of Concept
This is a resource management vulnerability triggered by legitimate high-load conditions. A proof of concept would require:
1. Deploying a testnet with 100+ validators
2. Triggering multiple concurrent reliable broadcasts (DAG nodes, commit votes, randomness)
3. Monitoring blocking thread pool utilization
4. Observing performance degradation when concurrent RPCs exceed 64

The vulnerability is evident from the code structure where deserialization uses unbounded `spawn_blocking` while aggregation uses bounded execution.

## Notes
The vulnerability is exacerbated by the fact that the consensus runtime limits blocking threads to 64 rather than tokio's default 512, making thread pool saturation more likely under realistic validator set sizes and concurrent broadcast patterns.

### Citations

**File:** consensus/src/network.rs (L684-696)
```rust
    async fn send_rb_rpc_raw(
        &self,
        receiver: Author,
        raw_message: Bytes,
        timeout: Duration,
    ) -> anyhow::Result<Res> {
        let response_msg = self
            .consensus_network_client
            .send_rpc_raw(receiver, raw_message, timeout)
            .await
            .map_err(|e| anyhow!("invalid rpc response: {}", e))?;
        tokio::task::spawn_blocking(|| TConsensusMsg::from_network_message(response_msg)).await?
    }
```

**File:** network/framework/src/protocols/network/mod.rs (L215-235)
```rust
        let max_parallel_deserialization_tasks = max_parallel_deserialization_tasks.unwrap_or(1);

        let data_event_stream = peer_mgr_notifs_rx.map(|notification| {
            tokio::task::spawn_blocking(move || received_message_to_event(notification))
        });

        let data_event_stream: Pin<
            Box<dyn Stream<Item = Event<TMessage>> + Send + Sync + 'static>,
        > = if allow_out_of_order_delivery {
            Box::pin(
                data_event_stream
                    .buffer_unordered(max_parallel_deserialization_tasks)
                    .filter_map(|res| future::ready(res.expect("JoinError from spawn blocking"))),
            )
        } else {
            Box::pin(
                data_event_stream
                    .buffered(max_parallel_deserialization_tasks)
                    .filter_map(|res| future::ready(res.expect("JoinError from spawn blocking"))),
            )
        };
```

**File:** crates/bounded-executor/src/executor.rs (L70-80)
```rust
    /// Like [`BoundedExecutor::spawn`] but spawns the given closure onto a
    /// blocking task (see [`tokio::task::spawn_blocking`] for details).
    pub async fn spawn_blocking<F, R>(&self, func: F) -> JoinHandle<R>
    where
        F: FnOnce() -> R + Send + 'static,
        R: Send + 'static,
    {
        let permit = self.acquire_permit().await;
        self.executor
            .spawn_blocking(function_with_permit(func, permit))
    }
```

**File:** crates/reliable-broadcast/src/lib.rs (L145-155)
```rust
                    }
                    let send_fut = if receiver == self_author {
                        network_sender.send_rb_rpc(receiver, message, rpc_timeout_duration)
                    } else if let Some(raw_message) = protocols.get(&receiver).cloned() {
                        network_sender.send_rb_rpc_raw(receiver, raw_message, rpc_timeout_duration)
                    } else {
                        network_sender.send_rb_rpc(receiver, message, rpc_timeout_duration)
                    };
                    (receiver, send_fut.await)
                }
                .boxed()
```

**File:** crates/reliable-broadcast/src/lib.rs (L169-181)
```rust
                    Some((receiver, result)) = rpc_futures.next() => {
                        let aggregating = aggregating.clone();
                        let future = executor.spawn(async move {
                            (
                                    receiver,
                                    result
                                        .and_then(|msg| {
                                            msg.try_into().map_err(|e| anyhow::anyhow!("{:?}", e))
                                        })
                                        .and_then(|ack| aggregating.add(receiver, ack)),
                            )
                        }).await;
                        aggregate_futures.push(future);
```

**File:** consensus/src/consensus_provider.rs (L56-56)
```rust
    let runtime = aptos_runtimes::spawn_named_runtime("consensus".into(), None);
```

**File:** crates/aptos-runtimes/src/lib.rs (L27-50)
```rust
    const MAX_BLOCKING_THREADS: usize = 64;

    // Verify the given name has an appropriate length
    if thread_name.len() > MAX_THREAD_NAME_LENGTH {
        panic!(
            "The given runtime thread name is too long! Max length: {}, given name: {}",
            MAX_THREAD_NAME_LENGTH, thread_name
        );
    }

    // Create the runtime builder
    let atomic_id = AtomicUsize::new(0);
    let thread_name_clone = thread_name.clone();
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
```
