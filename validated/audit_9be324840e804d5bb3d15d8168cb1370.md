# Audit Report

## Title
Secret Share Loss Due to Missing Reset During State Synchronization

## Summary
During state synchronization, the execution client's `reset()` function fails to reset the `SecretShareManager`, causing stale secret shares to remain in memory. When consensus resumes after sync, attempts to add new shares for rounds that already have stale shares in `PendingDecision` state trigger panics, preventing validators from participating in the randomness beacon and potentially stalling consensus.

## Finding Description

The vulnerability exists in the consensus reset mechanism during state synchronization. The critical flaw is that **the `reset()` function does not reset the SecretShareManager**, while it does reset the RandManager and BufferManager. [1](#0-0) 

The reset function only extracts and uses `reset_tx_to_rand_manager` and `reset_tx_to_buffer_manager` from the handle (lines 675-681), completely omitting `reset_tx_to_secret_share_manager` despite it being available in the BufferManagerHandle structure. [2](#0-1) 

This creates a state management flaw where:

1. **Pre-Sync State**: Node processes blocks and computes secret shares with specific metadata. The shares transition to `PendingDecision` state in the `secret_share_map`.

2. **State Sync Event**: Node falls behind and triggers state synchronization via `sync_to_target`. [3](#0-2) 

3. **Incomplete Reset**: The reset function is called, but only rand_manager and buffer_manager are reset. The SecretShareManager continues running with its old state, including stale shares in `secret_share_map`.

4. **Post-Sync Processing**: After sync completes and consensus resumes, when blocks are processed, the system attempts to add new secret shares.

5. **Share Addition Failure**: The `add_self_share` function is called with the new share. [4](#0-3) 

This calls `add_share_with_metadata` which encounters the existing `PendingDecision` item and explicitly bails: [5](#0-4) 

The error propagates back to the `expect` statement at line 147, causing a **panic that crashes the consensus thread**.

6. **RPC Request Failures**: When other validators request this node's share for a round with specific metadata, the `get_self_share` function filters by exact metadata match: [6](#0-5) 

Stale shares with old metadata fail the filter at line 302, returning `Ok(None)` and triggering a warning at line 300-303 in secret_share_manager.rs.

7. **No Cleanup Mechanism**: There is no garbage collection for old rounds in the `secret_share_map`, so stale shares persist indefinitely within an epoch.

Furthermore, when `process_reset` IS called on SecretShareManager (during epoch end, not during state sync), it also fails to clear the map: [7](#0-6) 

The function only clears the `block_queue` and updates `highest_known_round`, leaving the `secret_share_map` intact.

## Impact Explanation

**Severity: High** (up to $50,000 per Aptos Bug Bounty)

This vulnerability causes **Validator Node Crashes and Consensus Liveness Issues**, qualifying for HIGH severity under the "Validator node slowdowns" category:

1. **Immediate Crash**: The panic at line 147 in secret_share_manager.rs crashes the consensus thread for affected validators, removing them from participation until restart.

2. **Share Aggregation Failure**: Validators with stale shares cannot provide valid shares for RPC requests with different metadata, preventing threshold achievement.

3. **Cascade Effect**: State sync is often triggered simultaneously across multiple validators (e.g., during network partitions or periods of high load), causing multiple nodes to fail concurrently.

4. **Randomness Beacon Failure**: Without sufficient valid shares, the secret sharing threshold cannot be reached, preventing randomness generation.

5. **Consensus Impact**: Since Aptos randomness is integrated into the consensus protocol for leader election and transaction ordering, randomness beacon failure can halt or significantly degrade block production.

6. **Persistence**: The issue persists until the affected validator restarts its consensus component or a new epoch begins, potentially causing extended periods of degraded consensus performance.

## Likelihood Explanation

**Likelihood: High**

This vulnerability has high likelihood of occurring in production:

1. **Frequent Trigger**: State synchronization is a common operation in distributed blockchain networks:
   - Validators falling behind due to temporary performance issues
   - Network delays or partitions
   - Validator restarts or upgrades
   - Catching up after being offline [8](#0-7) 

2. **No Malicious Action Required**: This is purely a protocol-level bug triggered by normal consensus operations. No attacker involvement is necessary.

3. **Deterministic Failure**: Once a validator has processed shares for a round and then undergoes state sync without proper cleanup, the failure is deterministic when attempting to add shares for existing PendingDecision entries.

4. **Production-Realistic Scenarios**: The conditions for this bug (block processing followed by state sync) occur regularly in real-world deployments under normal network conditions.

## Recommendation

The issue can be fixed by ensuring the `reset()` function sends reset requests to the SecretShareManager, consistent with how it handles RandManager and BufferManager:

```rust
async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
    let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager, reset_tx_to_secret_share_manager) = {
        let handle = self.handle.read();
        (
            handle.reset_tx_to_rand_manager.clone(),
            handle.reset_tx_to_buffer_manager.clone(),
            handle.reset_tx_to_secret_share_manager.clone(), // ADD THIS LINE
        )
    };

    if let Some(mut reset_tx) = reset_tx_to_rand_manager {
        let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
        reset_tx
            .send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::TargetRound(target.commit_info().round()),
            })
            .await
            .map_err(|_| Error::RandResetDropped)?;
        ack_rx.await.map_err(|_| Error::RandResetDropped)?;
    }

    // ADD THIS BLOCK
    if let Some(mut reset_tx) = reset_tx_to_secret_share_manager {
        let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
        reset_tx
            .send(ResetRequest {
                tx: ack_tx,
                signal: ResetSignal::TargetRound(target.commit_info().round()),
            })
            .await
            .map_err(|_| Error::SecretShareResetDropped)?;
        ack_rx.await.map_err(|_| Error::SecretShareResetDropped)?;
    }

    if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
        // ... existing code ...
    }

    Ok(())
}
```

Additionally, the `process_reset` function in SecretShareManager should clear the `secret_share_map` to ensure stale entries are removed:

```rust
fn process_reset(&mut self, request: ResetRequest) {
    let ResetRequest { tx, signal } = request;
    let target_round = match signal {
        ResetSignal::Stop => 0,
        ResetSignal::TargetRound(round) => round,
    };
    self.block_queue = BlockQueue::new();
    {
        let mut store = self.secret_share_store.lock();
        store.update_highest_known_round(target_round);
        store.secret_share_map.clear(); // ADD THIS LINE
    }
    self.stop = matches!(signal, ResetSignal::Stop);
    let _ = tx.send(ResetAck::default());
}
```

## Proof of Concept

This vulnerability can be demonstrated through a consensus integration test that:
1. Processes blocks with secret sharing enabled
2. Triggers state sync via `sync_to_target`
3. Attempts to process blocks at rounds with existing PendingDecision entries
4. Observes the panic in `add_self_share`

The proof requires access to the consensus testing framework and is best validated through the existing test infrastructure in `consensus/src/` with modifications to inject state sync during block processing.

## Notes

This vulnerability represents a critical inconsistency in the state synchronization reset logic. The fact that RandManager and BufferManager are explicitly reset during `sync_to_target` while SecretShareManager is omitted, despite having the same reset channel infrastructure, indicates this is an implementation oversight rather than an intentional design choice. The panic at line 147 makes this a high-severity issue that can cause immediate validator crashes during normal consensus operations.

### Citations

**File:** consensus/src/pipeline/execution_client.rs (L124-177)
```rust
struct BufferManagerHandle {
    pub execute_tx: Option<UnboundedSender<OrderedBlocks>>,
    pub commit_tx:
        Option<aptos_channel::Sender<AccountAddress, (AccountAddress, IncomingCommitRequest)>>,
    pub reset_tx_to_buffer_manager: Option<UnboundedSender<ResetRequest>>,
    pub reset_tx_to_rand_manager: Option<UnboundedSender<ResetRequest>>,
    pub reset_tx_to_secret_share_manager: Option<UnboundedSender<ResetRequest>>,
}

impl BufferManagerHandle {
    pub fn new() -> Self {
        Self {
            execute_tx: None,
            commit_tx: None,
            reset_tx_to_buffer_manager: None,
            reset_tx_to_rand_manager: None,
            reset_tx_to_secret_share_manager: None,
        }
    }

    pub fn init(
        &mut self,
        execute_tx: UnboundedSender<OrderedBlocks>,
        commit_tx: aptos_channel::Sender<AccountAddress, (AccountAddress, IncomingCommitRequest)>,
        reset_tx_to_buffer_manager: UnboundedSender<ResetRequest>,
        reset_tx_to_rand_manager: Option<UnboundedSender<ResetRequest>>,
        maybe_reset_tx_to_secret_share_manager: Option<UnboundedSender<ResetRequest>>,
    ) {
        self.execute_tx = Some(execute_tx);
        self.commit_tx = Some(commit_tx);
        self.reset_tx_to_buffer_manager = Some(reset_tx_to_buffer_manager);
        self.reset_tx_to_rand_manager = reset_tx_to_rand_manager;
        self.reset_tx_to_secret_share_manager = maybe_reset_tx_to_secret_share_manager;
    }

    pub fn reset(
        &mut self,
    ) -> (
        Option<UnboundedSender<ResetRequest>>,
        Option<UnboundedSender<ResetRequest>>,
        Option<UnboundedSender<ResetRequest>>,
    ) {
        let reset_tx_to_rand_manager = self.reset_tx_to_rand_manager.take();
        let reset_tx_to_buffer_manager = self.reset_tx_to_buffer_manager.take();
        let reset_tx_to_secret_share_manager = self.reset_tx_to_secret_share_manager.take();
        self.execute_tx = None;
        self.commit_tx = None;
        (
            reset_tx_to_rand_manager,
            reset_tx_to_buffer_manager,
            reset_tx_to_secret_share_manager,
        )
    }
}
```

**File:** consensus/src/pipeline/execution_client.rs (L661-672)
```rust
    async fn sync_to_target(&self, target: LedgerInfoWithSignatures) -> Result<(), StateSyncError> {
        fail_point!("consensus::sync_to_target", |_| {
            Err(anyhow::anyhow!("Injected error in sync_to_target").into())
        });

        // Reset the rand and buffer managers to the target round
        self.reset(&target).await?;

        // TODO: handle the state sync error (e.g., re-push the ordered
        // blocks to the buffer manager when it's reset but sync fails).
        self.execution_proxy.sync_to_target(target).await
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L674-709)
```rust
    async fn reset(&self, target: &LedgerInfoWithSignatures) -> Result<()> {
        let (reset_tx_to_rand_manager, reset_tx_to_buffer_manager) = {
            let handle = self.handle.read();
            (
                handle.reset_tx_to_rand_manager.clone(),
                handle.reset_tx_to_buffer_manager.clone(),
            )
        };

        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
        }

        if let Some(mut reset_tx) = reset_tx_to_buffer_manager {
            // reset execution phase and commit phase
            let (tx, rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::ResetDropped)?;
            rx.await.map_err(|_| Error::ResetDropped)?;
        }

        Ok(())
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L142-148)
```rust
        {
            let mut secret_share_store = self.secret_share_store.lock();
            secret_share_store.update_highest_known_round(block.round());
            secret_share_store
                .add_self_share(self_secret_share.clone())
                .expect("Add self dec share should succeed");
        }
```

**File:** consensus/src/rand/secret_sharing/secret_share_manager.rs (L172-184)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.secret_share_store
            .lock()
            .update_highest_known_round(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L156-182)
```rust
    fn add_share_with_metadata(
        &mut self,
        share: SecretShare,
        share_weights: &HashMap<Author, u64>,
    ) -> anyhow::Result<()> {
        let item = std::mem::replace(self, Self::new(Author::ONE));
        let share_weight = *share_weights
            .get(share.author())
            .expect("Author must exist in weights");
        let new_item = match item {
            SecretShareItem::PendingMetadata(mut share_aggregator) => {
                let metadata = share.metadata.clone();
                share_aggregator.retain(share.metadata(), share_weights);
                share_aggregator.add_share(share, share_weight);
                SecretShareItem::PendingDecision {
                    metadata,
                    share_aggregator,
                }
            },
            SecretShareItem::PendingDecision { .. } => {
                bail!("Cannot add self share in PendingDecision state");
            },
            SecretShareItem::Decided { .. } => return Ok(()),
        };
        let _ = std::mem::replace(self, new_item);
        Ok(())
    }
```

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L288-303)
```rust
    pub fn get_self_share(
        &mut self,
        metadata: &SecretShareMetadata,
    ) -> anyhow::Result<Option<SecretShare>> {
        ensure!(
            metadata.round <= self.highest_known_round,
            "Request share from future round {}, highest known round {}",
            metadata.round,
            self.highest_known_round
        );
        Ok(self
            .secret_share_map
            .get(&metadata.round)
            .and_then(|item| item.get_self_share())
            .filter(|share| &share.metadata == metadata))
    }
```

**File:** consensus/src/state_computer.rs (L180-230)
```rust
        let target_logical_time =
            LogicalTime::new(target.ledger_info().epoch(), target.ledger_info().round());

        // Before state synchronization, we have to call finish() to free the
        // in-memory SMT held by BlockExecutor to prevent a memory leak.
        self.executor.finish();

        // The pipeline phase already committed beyond the target block timestamp, just return.
        if *latest_logical_time >= target_logical_time {
            warn!(
                "State sync target {:?} is lower than already committed logical time {:?}",
                target_logical_time, *latest_logical_time
            );
            return Ok(());
        }

        // This is to update QuorumStore with the latest known commit in the system,
        // so it can set batches expiration accordingly.
        // Might be none if called in the recovery path, or between epoch stop and start.
        if let Some(inner) = self.state.read().as_ref() {
            let block_timestamp = target.commit_info().timestamp_usecs();
            inner
                .payload_manager
                .notify_commit(block_timestamp, Vec::new());
        }

        // Inject an error for fail point testing
        fail_point!("consensus::sync_to_target", |_| {
            Err(anyhow::anyhow!("Injected error in sync_to_target").into())
        });

        // Invoke state sync to synchronize to the specified target. Here, the
        // ChunkExecutor will process chunks and commit to storage. However, after
        // block execution and commits, the internal state of the ChunkExecutor may
        // not be up to date. So, it is required to reset the cache of the
        // ChunkExecutor in state sync when requested to sync.
        let result = monitor!(
            "sync_to_target",
            self.state_sync_notifier.sync_to_target(target).await
        );

        // Update the latest logical time
        *latest_logical_time = target_logical_time;

        // Similarly, after state synchronization, we have to reset the cache of
        // the BlockExecutor to guarantee the latest committed state is up to date.
        self.executor.reset()?;

        // Return the result
        result.map_err(|error| {
            let anyhow_error: anyhow::Error = error.into();
```
