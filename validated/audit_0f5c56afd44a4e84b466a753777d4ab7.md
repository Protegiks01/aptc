# Audit Report

## Title
Resource Exhaustion via Unvalidated Transaction Signatures in Remote Batch Processing

## Summary
The Quorum Store batch coordinator accepts and stores batches from remote validators without validating transaction signatures, allowing malicious validators to consume storage quota, network bandwidth, and processing resources on honest nodes with cryptographically invalid transactions that are only rejected during the execution pipeline's prepare phase.

## Finding Description

The vulnerability exists in the Quorum Store's deferred signature validation design. When remote batches arrive, they bypass signature verification and consume resources before being rejected:

**1. Batch Reception Without Signature Validation**

The `BatchCoordinator::handle_batches_msg()` method receives remote batches but only validates size limits and optionally applies transaction filters—it never validates transaction signatures. [1](#0-0) 

**2. Metadata-Only Verification**

The `Batch::verify()` method only checks metadata consistency (author, digest, transaction counts, gas prices) and explicitly does not verify transaction signatures. [2](#0-1) 

**3. Filter Does Not Validate Signatures**

The `BatchTransactionFilter::allows_transaction()` only matches on batch metadata (batch ID, author, digest) and transaction properties, not cryptographic validity. [3](#0-2) 

**4. Resource Consumption Before Validation**

Invalid batches are stored in the batch store, consuming per-peer storage quota via `QuotaManager::update_quota()` before any signature verification occurs. [4](#0-3) 

**5. Deferred Signature Verification**

Signatures are only verified during the pipeline's prepare phase using `SIG_VERIFY_POOL` for parallel verification, which occurs after batches are already stored and gossiped. [5](#0-4) 

**6. Conversion to SignatureVerifiedTransaction**

The `From<Transaction>` trait implementation calls `verify_signature()` and marks transactions with invalid signatures as `SignatureVerifiedTransaction::Invalid`. [6](#0-5) 

**7. Execution Discard**

Invalid transactions are immediately discarded during execution with `INVALID_SIGNATURE` status and discarded output, but only after resources have already been consumed. [7](#0-6) 

**Attack Scenario**: A Byzantine validator crafts batches containing transactions with invalid signatures (random bytes) and broadcasts them. Honest validators store these batches (consuming quota), gossip them to peers (wasting bandwidth), include them in block proposals (wasting consensus time), and only reject them during signature verification in the prepare phase.

## Impact Explanation

**Severity: HIGH** per Aptos Bug Bounty criteria for "Validator node slowdowns."

**Resource Exhaustion Impact**:

1. **Storage Quota Depletion**: Each validator has configurable per-peer quotas (default: 120MB memory, 300MB database, 300K batch count). A Byzantine validator can fill these quotas with invalid batches, preventing legitimate batches from being stored. [8](#0-7) 

2. **Network Bandwidth Waste**: Invalid batches consume network resources during gossip across the validator network before being rejected.

3. **Consensus Processing Overhead**: Blocks containing invalid batches waste consensus round time during preparation and validation cycles.

4. **Database Write Amplification**: When memory quota is exceeded, invalid batches trigger unnecessary database writes via the persistence layer. [9](#0-8) 

**Scope**: Affects all honest validators receiving batches from Byzantine peers. With N validators, a single Byzantine validator can amplify resource consumption N-1 times across the network.

## Likelihood Explanation

**Likelihood: HIGH**

**Requirements**:
- Attacker must operate or compromise a validator node
- Byzantine behavior within BFT tolerance (< 1/3 validators)
- No cryptographic cost (invalid signatures are trivial to generate)

**Ease of Exploitation**:
- Attack is trivial: generate transactions with random signature bytes
- No complex timing or race conditions required
- Persistent effect: batches remain stored until expiration
- Amplification: one malicious batch affects multiple honest nodes
- Hard to detect until prepare phase signature verification

**Within Threat Model**: The Aptos threat model assumes up to 1/3 Byzantine validators. This attack operates within that threshold and exploits the deferred validation design rather than cryptographic or consensus vulnerabilities.

## Recommendation

Implement early signature verification for remote batches to fail fast and prevent resource consumption:

**Option 1: Verify Signatures on Batch Reception**
Add signature verification in `BatchCoordinator::handle_batches_msg()` before persisting batches. Use parallel verification similar to the prepare phase.

**Option 2: Probabilistic Sampling**
Verify a random sample of transaction signatures (e.g., 10%) before accepting batches. This provides statistical protection while maintaining performance.

**Option 3: Batch-Level Penalties**
Track validators that send batches with high invalid signature rates and deprioritize or temporarily reject their subsequent batches.

**Option 4: Rate Limiting**
Implement stricter rate limits on batch acceptance per validator, reducing the impact of resource exhaustion attacks.

The optimal solution combines early signature verification with performance optimizations to minimize latency impact on legitimate batch distribution.

## Proof of Concept

A Byzantine validator can execute this attack by:

1. Creating transactions with random signature bytes instead of valid cryptographic signatures
2. Bundling these transactions into batches using the standard batch creation process
3. Broadcasting batches to honest validators via the Quorum Store protocol
4. Monitoring honest validators consuming quota and storage for invalid batches

The attack succeeds because no validation step checks transaction signatures until the prepare phase, allowing invalid data to consume resources throughout the batch distribution, storage, and gossip phases.

---

## Notes

This vulnerability represents a design flaw in the Quorum Store's deferred validation approach. While per-peer quotas provide some mitigation by limiting damage from a single malicious validator, they do not prevent the fundamental issue: cryptographically invalid data consuming resources on honest nodes. The attack violates the security principle of "fail fast"—invalid inputs should be rejected at the earliest possible point to minimize resource consumption and attack surface.

### Citations

**File:** consensus/src/quorum_store/batch_coordinator.rs (L173-213)
```rust
    pub(crate) async fn handle_batches_msg(
        &mut self,
        author: PeerId,
        batches: Vec<Batch<BatchInfoExt>>,
    ) {
        if let Err(e) = self.ensure_max_limits(&batches) {
            error!("Batch from {}: {}", author, e);
            counters::RECEIVED_BATCH_MAX_LIMIT_FAILED.inc();
            return;
        }

        let Some(batch) = batches.first() else {
            error!("Empty batch received from {}", author.short_str().as_str());
            return;
        };

        // Filter the transactions in the batches. If any transaction is rejected,
        // the message will be dropped, and all batches will be rejected.
        if self.transaction_filter_config.is_enabled() {
            let transaction_filter = &self.transaction_filter_config.batch_transaction_filter();
            for batch in batches.iter() {
                for transaction in batch.txns() {
                    if !transaction_filter.allows_transaction(
                        batch.batch_info().batch_id(),
                        batch.author(),
                        batch.digest(),
                        transaction,
                    ) {
                        error!(
                            "Transaction {}, in batch {}, from {}, was rejected by the filter. Dropping {} batches!",
                            transaction.committed_hash(),
                            batch.batch_info().batch_id(),
                            author.short_str().as_str(),
                            batches.len()
                        );
                        counters::RECEIVED_BATCH_REJECTED_BY_FILTER.inc();
                        return;
                    }
                }
            }
        }
```

**File:** consensus/src/quorum_store/types.rs (L262-290)
```rust
    pub fn verify(&self) -> anyhow::Result<()> {
        ensure!(
            self.payload.author() == self.author(),
            "Payload author doesn't match the info"
        );
        ensure!(
            self.payload.hash() == *self.digest(),
            "Payload hash doesn't match the digest"
        );
        ensure!(
            self.payload.num_txns() as u64 == self.num_txns(),
            "Payload num txns doesn't match batch info"
        );
        ensure!(
            self.payload.num_bytes() as u64 == self.num_bytes(),
            "Payload num bytes doesn't match batch info"
        );
        for txn in self.payload.txns() {
            ensure!(
                txn.gas_unit_price() >= self.gas_bucket_start(),
                "Payload gas unit price doesn't match batch info"
            );
            ensure!(
                !txn.payload().is_encrypted_variant(),
                "Encrypted transaction is not supported yet"
            );
        }
        Ok(())
    }
```

**File:** crates/aptos-transaction-filters/src/batch_transaction_filter.rs (L29-58)
```rust
    /// Returns true iff the filter allows the transaction in the batch
    pub fn allows_transaction(
        &self,
        batch_id: BatchId,
        batch_author: PeerId,
        batch_digest: &HashValue,
        signed_transaction: &SignedTransaction,
    ) -> bool {
        // If the filter is empty, allow the transaction by default
        if self.is_empty() {
            return true;
        }

        // Check if any rule matches the batch transaction
        for batch_transaction_rule in &self.batch_transaction_rules {
            if batch_transaction_rule.matches(
                batch_id,
                batch_author,
                batch_digest,
                signed_transaction,
            ) {
                return match batch_transaction_rule {
                    BatchTransactionRule::Allow(_) => true,
                    BatchTransactionRule::Deny(_) => false,
                };
            }
        }

        true // No rules match (allow the batch transaction by default)
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L358-417)
```rust
    pub(crate) fn insert_to_cache(
        &self,
        value: &PersistedValue<BatchInfoExt>,
    ) -> anyhow::Result<bool> {
        let digest = *value.digest();
        let author = value.author();
        let expiration_time = value.expiration();

        {
            // Acquire dashmap internal lock on the entry corresponding to the digest.
            let cache_entry = self.db_cache.entry(digest);

            if let Occupied(entry) = &cache_entry {
                match entry.get().expiration().cmp(&expiration_time) {
                    std::cmp::Ordering::Equal => return Ok(false),
                    std::cmp::Ordering::Greater => {
                        debug!(
                            "QS: already have the digest with higher expiration {}",
                            digest
                        );
                        return Ok(false);
                    },
                    std::cmp::Ordering::Less => {},
                }
            };
            let value_to_be_stored = if self
                .peer_quota
                .entry(author)
                .or_insert(QuotaManager::new(
                    self.db_quota,
                    self.memory_quota,
                    self.batch_quota,
                ))
                .update_quota(value.num_bytes() as usize)?
                == StorageMode::PersistedOnly
            {
                PersistedValue::new(value.batch_info().clone(), None)
            } else {
                value.clone()
            };

            match cache_entry {
                Occupied(entry) => {
                    let (k, prev_value) = entry.replace_entry(value_to_be_stored);
                    debug_assert!(k == digest);
                    self.free_quota(prev_value);
                },
                Vacant(slot) => {
                    slot.insert(value_to_be_stored);
                },
            }
        }

        // Add expiration for the inserted entry, no need to be atomic w. insertion.
        #[allow(clippy::unwrap_used)]
        {
            self.expirations.lock().add_item(digest, expiration_time);
        }
        Ok(true)
    }
```

**File:** consensus/src/quorum_store/batch_store.rs (L501-513)
```rust
                    if !batch_info.is_v2() {
                        let persist_request =
                            persist_request.try_into().expect("Must be a V1 batch");
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch(persist_request)
                            .expect("Could not write to DB");
                    } else {
                        #[allow(clippy::unwrap_in_result)]
                        self.db
                            .save_batch_v2(persist_request)
                            .expect("Could not write to DB")
                    }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L669-680)
```rust
        let sig_verification_start = Instant::now();
        let sig_verified_txns: Vec<SignatureVerifiedTransaction> = SIG_VERIFY_POOL.install(|| {
            let num_txns = input_txns.len();
            input_txns
                .into_par_iter()
                .with_min_len(optimal_min_len(num_txns, 32))
                .map(|t| Transaction::UserTransaction(t).into())
                .collect::<Vec<_>>()
        });
        counters::PREPARE_BLOCK_SIG_VERIFICATION_TIME
            .observe_duration(sig_verification_start.elapsed());
        Ok((Arc::new(sig_verified_txns), block_gas_limit))
```

**File:** types/src/transaction/signature_verified_transaction.rs (L129-138)
```rust
impl From<Transaction> for SignatureVerifiedTransaction {
    fn from(txn: Transaction) -> Self {
        match txn {
            Transaction::UserTransaction(txn) => match txn.verify_signature() {
                Ok(_) => SignatureVerifiedTransaction::Valid(Transaction::UserTransaction(txn)),
                Err(_) => SignatureVerifiedTransaction::Invalid(Transaction::UserTransaction(txn)),
            },
            _ => SignatureVerifiedTransaction::Valid(txn),
        }
    }
```

**File:** aptos-move/aptos-vm/src/aptos_vm.rs (L2881-2884)
```rust
        if let SignatureVerifiedTransaction::Invalid(_) = txn {
            let vm_status = VMStatus::error(StatusCode::INVALID_SIGNATURE, None);
            let discarded_output = discarded_output(vm_status.status_code());
            return Ok((vm_status, discarded_output));
```

**File:** config/src/config/quorum_store_config.rs (L133-135)
```rust
            memory_quota: 120_000_000,
            db_quota: 300_000_000,
            batch_quota: 300_000,
```
