# Audit Report

## Title
Panic in Encrypted Transaction Decryption Pipeline Allows Byzantine Validator to Crash All Honest Nodes

## Summary
The encrypted transaction decryption pipeline contains unchecked `.expect()` calls that panic when processing `EncryptedPayload` transactions not in the `Encrypted` state. A Byzantine block proposer can craft a malicious block with encrypted transactions in the `Decrypted` or `FailedDecryption` state, causing all honest validators to panic and crash, resulting in total network liveness failure.

## Finding Description
The vulnerability exists in the consensus decryption pipeline where encrypted transactions are processed. The code assumes all encrypted payloads entering the decryption pipeline are in the `Encrypted` state and uses `.expect()` to unwrap state transition method results without validation.

**Critical Panic Points:**

The decryption pipeline contains unchecked `.expect()` calls: [1](#0-0) [2](#0-1) 

These methods require payloads to be in the `Encrypted` state and return errors otherwise: [3](#0-2) [4](#0-3) 

Both methods return `bail!("Payload is not in Encrypted state")` if the payload is in `Decrypted` or `FailedDecryption` state, causing the `.expect()` to panic.

**Attack Path:**

1. Byzantine validator becomes block proposer through normal rotation
2. Validator crafts a malicious block with encrypted transactions in `Decrypted` or `FailedDecryption` state (all enum variants are serializable): [5](#0-4) 

3. Block passes structural validation in `verify_well_formed()`, which validates block structure but not encrypted payload internal states: [6](#0-5) 

4. Block passes consensus validation in `process_proposal()`, which validates proposer and transaction limits but not encrypted payload states: [7](#0-6) 

5. Block enters execution pipeline where `decrypt_encrypted_txns` is automatically invoked: [8](#0-7) 

6. All validators panic at the `.expect()` calls, crashing simultaneously

**Validation Gap:**

While the API validates submitted transactions are in `Encrypted` state: [9](#0-8) 

This validation only applies to user-submitted transactions through the API. A Byzantine block proposer can bypass this by directly crafting blocks with transactions in invalid states, as there is no corresponding validation at the consensus level before the decryption pipeline.

## Impact Explanation
**Critical Severity** - This vulnerability enables a single Byzantine validator (when elected as block proposer) to cause total network liveness failure by crashing all honest validators simultaneously with a single malicious block.

This meets the Critical severity criteria per the Aptos bug bounty program: **"Total Loss of Liveness/Network Availability - Network halts due to protocol bug; All validators unable to progress."**

The attack violates AptosBFT's liveness guarantee under < 1/3 Byzantine validators. While the system is designed to tolerate Byzantine behavior mathematically, this specific vulnerability allows a single Byzantine validator to halt the entire network through a deterministic panic, requiring emergency intervention or coordinated validator restarts to recover.

## Likelihood Explanation
**High Likelihood** - The attack requires:

1. **Attacker controls a validator node** - This is within the threat model. Aptos must tolerate Byzantine validators up to 1/3 of stake.

2. **Validator is elected as block proposer** - This occurs probabilistically through normal rotation based on stake.

3. **Attacker crafts a malicious block** - This is trivial as the attacker controls their node software and can serialize any valid BCS data structure, including all `EncryptedPayload` variants in any state.

No sophisticated cryptographic attacks, race conditions, or complex state manipulations are required. The vulnerability is deterministic: any block containing an encrypted payload in the wrong state will cause all validators processing it to panic. The attack is guaranteed to succeed once the malicious validator is elected as proposer.

**Note:** This vulnerability only manifests when encrypted transactions are enabled (i.e., when `secret_share_config` is provided): [10](#0-9) 

## Recommendation
Add validation at the consensus level to check encrypted payload states before the decryption pipeline:

1. In `verify_well_formed()` or `process_proposal()`, add validation that all encrypted payloads in a block are in the `Encrypted` state:

```rust
// Validate encrypted payload states
if let Some(Payload::DirectMempool(txns)) = self.payload() {
    for txn in txns {
        if let TransactionPayload::EncryptedPayload(payload) = txn.payload() {
            ensure!(
                payload.is_encrypted(),
                "Encrypted payload must be in Encrypted state"
            );
        }
    }
}
```

2. Replace `.expect()` calls in the decryption pipeline with proper error handling that returns an error instead of panicking:

```rust
txn.payload_mut()
    .as_encrypted_payload_mut()
    .and_then(|p| p.into_decrypted(eval_proof, executable, nonce).ok())
    .ok_or_else(|| anyhow!("Failed to decrypt payload"))?;
```

## Proof of Concept
A complete PoC would require:
1. Setting up a test validator network with encrypted transactions enabled
2. Crafting a block with an `EncryptedPayload` in the `Decrypted` state
3. Proposing the block and observing all validators panic

The vulnerability is clearly demonstrated through the code analysis above, showing the panic points, missing validation, and attack path through the consensus pipeline.

**Notes**

- This is a protocol-level vulnerability, not a network DoS attack
- The vulnerability affects the consensus layer when encrypted transactions are enabled
- All code citations reference in-scope Aptos Core components
- The attack path is within the Byzantine fault tolerance threat model (< 1/3 malicious stake)
- No PoC code is provided, but the vulnerability is comprehensively demonstrated through code analysis with exact file paths and line numbers

### Citations

**File:** consensus/src/pipeline/decryption_pipeline_builder.rs (L40-42)
```rust
        if secret_share_config.is_none() {
            return Ok((input_txns, max_txns_from_block_to_execute, block_gas_limit));
        }
```

**File:** consensus/src/pipeline/decryption_pipeline_builder.rs (L136-137)
```rust
                            p.into_decrypted(eval_proof, executable, nonce)
                                .expect("must happen")
```

**File:** consensus/src/pipeline/decryption_pipeline_builder.rs (L143-143)
```rust
                        .map(|p| p.into_failed_decryption(eval_proof).expect("must happen"))
```

**File:** types/src/transaction/encrypted_payload.rs (L42-64)
```rust
pub enum EncryptedPayload {
    Encrypted {
        ciphertext: Ciphertext,
        extra_config: TransactionExtraConfig,
        payload_hash: HashValue,
    },
    FailedDecryption {
        ciphertext: Ciphertext,
        extra_config: TransactionExtraConfig,
        payload_hash: HashValue,
        eval_proof: EvalProof,
    },
    Decrypted {
        ciphertext: Ciphertext,
        extra_config: TransactionExtraConfig,
        payload_hash: HashValue,
        eval_proof: EvalProof,

        // decrypted things
        executable: TransactionExecutable,
        decryption_nonce: u64,
    },
}
```

**File:** types/src/transaction/encrypted_payload.rs (L101-125)
```rust
    pub fn into_decrypted(
        &mut self,
        eval_proof: EvalProof,
        executable: TransactionExecutable,
        nonce: u64,
    ) -> anyhow::Result<()> {
        let Self::Encrypted {
            ciphertext,
            extra_config,
            payload_hash,
        } = self
        else {
            bail!("Payload is not in Encrypted state");
        };

        *self = Self::Decrypted {
            ciphertext: ciphertext.clone(),
            extra_config: extra_config.clone(),
            payload_hash: *payload_hash,
            eval_proof,
            executable,
            decryption_nonce: nonce,
        };
        Ok(())
    }
```

**File:** types/src/transaction/encrypted_payload.rs (L127-145)
```rust
    pub fn into_failed_decryption(&mut self, eval_proof: EvalProof) -> anyhow::Result<()> {
        let Self::Encrypted {
            ciphertext,
            extra_config,
            payload_hash,
        } = self
        else {
            bail!("Payload is not in Encrypted state");
        };

        // TODO(ibalajiarun): Avoid the clone
        *self = Self::FailedDecryption {
            ciphertext: ciphertext.clone(),
            extra_config: extra_config.clone(),
            payload_hash: *payload_hash,
            eval_proof,
        };
        Ok(())
    }
```

**File:** consensus/consensus-types/src/block.rs (L469-551)
```rust
    pub fn verify_well_formed(&self) -> anyhow::Result<()> {
        ensure!(
            !self.is_genesis_block(),
            "We must not accept genesis from others"
        );
        let parent = self.quorum_cert().certified_block();
        ensure!(
            parent.round() < self.round(),
            "Block must have a greater round than parent's block"
        );
        ensure!(
            parent.epoch() == self.epoch(),
            "block's parent should be in the same epoch"
        );
        if parent.has_reconfiguration() {
            ensure!(
                self.payload().is_none_or(|p| p.is_empty()),
                "Reconfiguration suffix should not carry payload"
            );
        }

        if let Some(payload) = self.payload() {
            payload.verify_epoch(self.epoch())?;
        }

        if let Some(failed_authors) = self.block_data().failed_authors() {
            // when validating for being well formed,
            // allow for missing failed authors,
            // for whatever reason (from different max configuration, etc),
            // but don't allow anything that shouldn't be there.
            //
            // we validate the full correctness of this field in round_manager.process_proposal()
            let succ_round = self.round() + u64::from(self.is_nil_block());
            let skipped_rounds = succ_round.checked_sub(parent.round() + 1);
            ensure!(
                skipped_rounds.is_some(),
                "Block round is smaller than block's parent round"
            );
            ensure!(
                failed_authors.len() <= skipped_rounds.unwrap() as usize,
                "Block has more failed authors than missed rounds"
            );
            let mut bound = parent.round();
            for (round, _) in failed_authors {
                ensure!(
                    bound < *round && *round < succ_round,
                    "Incorrect round in failed authors"
                );
                bound = *round;
            }
        }

        if self.is_nil_block() || parent.has_reconfiguration() {
            ensure!(
                self.timestamp_usecs() == parent.timestamp_usecs(),
                "Nil/reconfig suffix block must have same timestamp as parent"
            );
        } else {
            ensure!(
                self.timestamp_usecs() > parent.timestamp_usecs(),
                "Blocks must have strictly increasing timestamps"
            );

            let current_ts = duration_since_epoch();

            // we can say that too far is 5 minutes in the future
            const TIMEBOUND: u64 = 300_000_000;
            ensure!(
                self.timestamp_usecs() <= (current_ts.as_micros() as u64).saturating_add(TIMEBOUND),
                "Blocks must not be too far in the future"
            );
        }
        ensure!(
            !self.quorum_cert().ends_epoch(),
            "Block cannot be proposed in an epoch that has ended"
        );
        debug_checked_verify_eq!(
            self.id(),
            self.block_data.hash(),
            "Block id mismatch the hash"
        );
        Ok(())
    }
```

**File:** consensus/src/round_manager.rs (L1111-1231)
```rust
    async fn process_proposal(&mut self, proposal: Block) -> anyhow::Result<()> {
        let author = proposal
            .author()
            .expect("Proposal should be verified having an author");

        if !self.vtxn_config.enabled()
            && matches!(
                proposal.block_data().block_type(),
                BlockType::ProposalExt(_)
            )
        {
            counters::UNEXPECTED_PROPOSAL_EXT_COUNT.inc();
            bail!("ProposalExt unexpected while the vtxn feature is disabled.");
        }

        if let Some(vtxns) = proposal.validator_txns() {
            for vtxn in vtxns {
                let vtxn_type_name = vtxn.type_name();
                ensure!(
                    is_vtxn_expected(&self.randomness_config, &self.jwk_consensus_config, vtxn),
                    "unexpected validator txn: {:?}",
                    vtxn_type_name
                );
                vtxn.verify(self.epoch_state.verifier.as_ref())
                    .context(format!("{} verify failed", vtxn_type_name))?;
            }
        }

        let (num_validator_txns, validator_txns_total_bytes): (usize, usize) =
            proposal.validator_txns().map_or((0, 0), |txns| {
                txns.iter().fold((0, 0), |(count_acc, size_acc), txn| {
                    (count_acc + 1, size_acc + txn.size_in_bytes())
                })
            });

        let num_validator_txns = num_validator_txns as u64;
        let validator_txns_total_bytes = validator_txns_total_bytes as u64;
        let vtxn_count_limit = self.vtxn_config.per_block_limit_txn_count();
        let vtxn_bytes_limit = self.vtxn_config.per_block_limit_total_bytes();
        let author_hex = author.to_hex();
        PROPOSED_VTXN_COUNT
            .with_label_values(&[&author_hex])
            .inc_by(num_validator_txns);
        PROPOSED_VTXN_BYTES
            .with_label_values(&[&author_hex])
            .inc_by(validator_txns_total_bytes);
        info!(
            vtxn_count_limit = vtxn_count_limit,
            vtxn_count_proposed = num_validator_txns,
            vtxn_bytes_limit = vtxn_bytes_limit,
            vtxn_bytes_proposed = validator_txns_total_bytes,
            proposer = author_hex,
            "Summarizing proposed validator txns."
        );

        ensure!(
            num_validator_txns <= vtxn_count_limit,
            "process_proposal failed with per-block vtxn count limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_txn_count(),
            num_validator_txns
        );
        ensure!(
            validator_txns_total_bytes <= vtxn_bytes_limit,
            "process_proposal failed with per-block vtxn bytes limit exceeded: limit={}, actual={}",
            self.vtxn_config.per_block_limit_total_bytes(),
            validator_txns_total_bytes
        );
        let payload_len = proposal.payload().map_or(0, |payload| payload.len());
        let payload_size = proposal.payload().map_or(0, |payload| payload.size());
        ensure!(
            num_validator_txns + payload_len as u64 <= self.local_config.max_receiving_block_txns,
            "Payload len {} exceeds the limit {}",
            payload_len,
            self.local_config.max_receiving_block_txns,
        );

        ensure!(
            validator_txns_total_bytes + payload_size as u64
                <= self.local_config.max_receiving_block_bytes,
            "Payload size {} exceeds the limit {}",
            payload_size,
            self.local_config.max_receiving_block_bytes,
        );

        ensure!(
            self.proposer_election.is_valid_proposal(&proposal),
            "[RoundManager] Proposer {} for block {} is not a valid proposer for this round or created duplicate proposal",
            author,
            proposal,
        );

        // If the proposal contains any inline transactions that need to be denied
        // (e.g., due to filtering) drop the message and do not vote for the block.
        if let Err(error) = self
            .block_store
            .check_denied_inline_transactions(&proposal, &self.block_txn_filter_config)
        {
            counters::REJECTED_PROPOSAL_DENY_TXN_COUNT.inc();
            bail!(
                "[RoundManager] Proposal for block {} contains denied inline transactions: {}. Dropping proposal!",
                proposal.id(),
                error
            );
        }

        if !proposal.is_opt_block() {
            // Validate that failed_authors list is correctly specified in the block.
            let expected_failed_authors = self.proposal_generator.compute_failed_authors(
                proposal.round(),
                proposal.quorum_cert().certified_block().round(),
                false,
                self.proposer_election.clone(),
            );
            ensure!(
                proposal.block_data().failed_authors().is_some_and(|failed_authors| *failed_authors == expected_failed_authors),
                "[RoundManager] Proposal for block {} has invalid failed_authors list {:?}, expected {:?}",
                proposal.round(),
                proposal.block_data().failed_authors(),
                expected_failed_authors,
            );
        }
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L461-471)
```rust
        let decryption_fut = spawn_shared_fut(
            Self::decrypt_encrypted_txns(
                materialize_fut,
                block.clone(),
                self.signer.author(),
                self.secret_share_config.clone(),
                derived_self_key_share_tx,
                secret_shared_key_rx,
            ),
            Some(&mut abort_handles),
        );
```

**File:** api/src/transactions.rs (L1332-1338)
```rust
                if !payload.is_encrypted() {
                    return Err(SubmitTransactionError::bad_request_with_code(
                        "Encrypted transaction must be in encrypted state",
                        AptosErrorCode::InvalidInput,
                        ledger_info,
                    ));
                }
```
