# Audit Report

## Title
Missing Table Element Count Validation During Module Deserialization Allows Resource Exhaustion Attack

## Summary
The Move binary format deserializer fails to validate that table element counts do not exceed `TABLE_INDEX_MAX` (65535) during module deserialization. This allows attackers to craft malicious bytecode with oversized tables, causing memory exhaustion on validator nodes and bypassing intended table size constraints enforced during compilation.

## Finding Description

The Move binary format defines `TableIndex` as a 16-bit unsigned integer (`u16`), which limits addressable table elements to 65536 entries (0-65535). [1](#0-0)  The maximum table index is explicitly defined as 65535. [2](#0-1) 

During module compilation, the `ModuleBuilder` correctly enforces this limit using a `bounds_check` function that validates table lengths against `TableIndex::MAX`. [3](#0-2)  This check is called when adding entries to tables. [4](#0-3) 

**However, this validation is completely absent during module deserialization.** The `Table::load` function deserializes table elements based on byte count without ever validating that the resulting element count remains within the TABLE_INDEX_MAX limit. [5](#0-4)  The function continuously pushes deserialized elements into a vector until all bytes are consumed, with no check on the vector's final length.

The `check_tables` function only validates byte-level table structure (offsets, overlaps, duplicates) but never checks element counts. [6](#0-5) 

After deserialization, `BoundsChecker::verify_module` is called, but it only validates that indices within the module reference valid table positions. [7](#0-6)  The `check_bounds_impl` function checks `idx >= len` to ensure indices don't exceed table length, but does not validate that `len` itself respects TABLE_INDEX_MAX. [8](#0-7) 

**Attack Scenario:**
1. Attacker crafts malicious module bytecode bypassing the official compiler
2. Module contains tables with element counts exceeding 65535 (e.g., 100,000 identifiers)
3. Table byte count remains within `TABLE_SIZE_MAX` (4GB) and transaction size limits (6MB)
4. Module is submitted via transaction to the Aptos network
5. Deserialization loads all elements into memory without validation
6. `BoundsChecker` passes because all referenced indices (0-65535) are valid
7. Elements at indices 65536+ consume memory but are permanently unreachable
8. Repeated submissions exhaust validator memory

This breaks the Resource Limits invariant by allowing modules to bypass the designed 65536-element table limit enforced during compilation.

## Impact Explanation

This vulnerability qualifies as **Medium Severity** under the Aptos bug bounty criteria:

**State Inconsistencies**: Modules with oversized tables pass all validation checks and can be published to the blockchain, creating inconsistent state where data exists but cannot be addressed through the type system's indexing mechanism.

**Resource Exhaustion (DoS Potential)**: An attacker can submit malicious modules to consume validator memory. While limited by transaction size (6MB) and gas costs (~7 units per byte), a 200KB module with 100,000 identifiers is feasible and costs ~1.4M gas units. Multiple such submissions can degrade validator performance.

**Bypassing Intended Limits**: The vulnerability circumvents a fundamental design constraint of the Move binary format. The compiler enforces TABLE_INDEX_MAX, but the deserializer does not, creating an asymmetry that enables protocol-level resource exhaustion.

This does not directly enable fund theft or consensus violations, placing it in the Medium severity category rather than Critical or High.

## Likelihood Explanation

The likelihood is **MODERATE**:

**Attack Requirements:**
- Craft raw Move bytecode bypassing the official compiler
- Understanding of Move binary format specification
- Submit via standard transaction (normal user capability)

**Barriers:**
- Requires technical sophistication to craft valid bytecode with oversized tables
- Gas costs make large-scale attacks expensive
- Legitimate modules compiled normally will not exhibit this issue

**Feasibility:**
- Binary format is documented and tools exist for bytecode manipulation
- No special privileges required beyond normal transaction submission
- Attack can be repeated but with increasing cost

## Recommendation

Add element count validation in the `Table::load` function during deserialization:

```rust
fn load<T>(
    &self,
    binary: &VersionedBinary,
    result: &mut Vec<T>,
    deserializer: impl Fn(&mut VersionedCursor) -> BinaryLoaderResult<T>,
) -> BinaryLoaderResult<()> {
    let start = self.offset as usize;
    let end = start + self.count as usize;
    let mut cursor = binary.new_cursor(start, end);
    while cursor.position() < self.count as u64 {
        result.push(deserializer(&mut cursor)?)
    }
    
    // Add validation after loading
    if result.len() > TABLE_INDEX_MAX as usize {
        return Err(PartialVMError::new(StatusCode::MALFORMED)
            .with_message(format!(
                "Table contains {} elements, exceeding maximum of {}",
                result.len(),
                TABLE_INDEX_MAX
            )));
    }
    
    Ok(())
}
```

Alternatively, add validation in the `check_tables` function to validate element counts match the design constraints enforced during compilation.

## Proof of Concept

A complete proof of concept would require:
1. Crafting a Move module binary with an identifier table containing >65535 entries
2. Ensuring the table byte count remains within limits (each identifier: length prefix + data)
3. Submitting as a module publishing transaction
4. Observing successful deserialization with oversized table in memory

The PoC would demonstrate that while `BoundsChecker::verify_module` passes (all referenced indices 0-65535 are valid), the module contains unreachable elements and consumes excessive memory.

## Notes

This vulnerability highlights an asymmetry between compilation-time and runtime validation. The Move compiler correctly enforces table size constraints through `ModuleBuilder::bounds_check`, but the deserializer implements only structural validation without semantic constraint checking. This creates a trust boundary where malicious actors can craft bytecode that bypasses intended protocol limits by avoiding the compiler entirely.

The issue is distinct from network-level DoS attacks as it exploits a missing validation in protocol logic rather than flooding network resources. The attack vector is through valid transaction submission, making it a protocol-level resource exhaustion vulnerability that falls within scope of the security model.

### Citations

**File:** third_party/move/move-binary-format/src/file_format.rs (L56-56)
```rust
pub type TableIndex = u16;
```

**File:** third_party/move/move-binary-format/src/file_format_common.rs (L43-43)
```rust
pub const TABLE_INDEX_MAX: u64 = 65535;
```

**File:** third_party/move/tools/move-asm/src/module_builder.rs (L905-916)
```rust
    fn bounds_check(&self, value: usize, max: TableIndex, msg: &str) -> Result<TableIndex> {
        if self.options.validate && value >= max as usize {
            Err(anyhow!(
                "exceeded maximal {} table size: {} >= {}",
                msg,
                value,
                max
            ))
        } else {
            Ok(value as TableIndex)
        }
    }
```

**File:** third_party/move/tools/move-asm/src/module_builder.rs (L930-930)
```rust
        let idx = mk_idx(self.bounds_check(table.len(), TableIndex::MAX, msg)?);
```

**File:** third_party/move/move-binary-format/src/deserializer.rs (L59-59)
```rust
            BoundsChecker::verify_module(&module)?;
```

**File:** third_party/move/move-binary-format/src/deserializer.rs (L546-571)
```rust
fn check_tables(tables: &mut Vec<Table>, binary_len: usize) -> BinaryLoaderResult<u32> {
    // there is no real reason to pass a mutable reference but we are sorting next line
    tables.sort_by(|t1, t2| t1.offset.cmp(&t2.offset));

    let mut current_offset: u32 = 0;
    let mut table_types = HashSet::new();
    for table in tables {
        if table.offset != current_offset {
            return Err(PartialVMError::new(StatusCode::BAD_HEADER_TABLE));
        }
        if table.count == 0 {
            return Err(PartialVMError::new(StatusCode::BAD_HEADER_TABLE));
        }
        match current_offset.checked_add(table.count) {
            Some(checked_offset) => current_offset = checked_offset,
            None => return Err(PartialVMError::new(StatusCode::BAD_HEADER_TABLE)),
        }
        if !table_types.insert(table.kind) {
            return Err(PartialVMError::new(StatusCode::DUPLICATE_TABLE));
        }
        if current_offset as usize > binary_len {
            return Err(PartialVMError::new(StatusCode::BAD_HEADER_TABLE));
        }
    }
    Ok(current_offset)
}
```

**File:** third_party/move/move-binary-format/src/deserializer.rs (L573-589)
```rust
impl Table {
    /// Generic function to deserialize a table into a vector of given type.
    fn load<T>(
        &self,
        binary: &VersionedBinary,
        result: &mut Vec<T>,
        deserializer: impl Fn(&mut VersionedCursor) -> BinaryLoaderResult<T>,
    ) -> BinaryLoaderResult<()> {
        let start = self.offset as usize;
        let end = start + self.count as usize;
        let mut cursor = binary.new_cursor(start, end);
        while cursor.position() < self.count as u64 {
            result.push(deserializer(&mut cursor)?)
        }
        Ok(())
    }
}
```

**File:** third_party/move/move-binary-format/src/check_bounds.rs (L883-899)
```rust
fn check_bounds_impl<T, I>(pool: &[T], idx: I) -> PartialVMResult<()>
where
    I: ModuleIndex,
{
    let idx = idx.into_index();
    let len = pool.len();
    if idx >= len {
        Err(bounds_error(
            StatusCode::INDEX_OUT_OF_BOUNDS,
            I::KIND,
            idx as TableIndex,
            len,
        ))
    } else {
        Ok(())
    }
}
```
