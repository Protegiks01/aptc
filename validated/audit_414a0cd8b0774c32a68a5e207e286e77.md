# Audit Report

## Title
Race Condition in Ledger Database Pruner Progress Updates Leads to Storage Inconsistency

## Summary
The `write_pruner_progress()` function in `LedgerDb` writes pruner progress to 8 separate databases sequentially without synchronization. Concurrent pruner worker threads can interleave with these writes, creating inconsistent pruner progress across databases during fast sync operations.

## Finding Description

The vulnerability exists in the `write_pruner_progress()` function which performs 8 sequential write operations to different databases without atomic transaction guarantees or locking. [1](#0-0) 

Each sub-database receives individual writes to its pruner progress metadata key. For example, the event database write: [2](#0-1) 

Meanwhile, pruner worker threads run continuously in separate background threads, spawned when the database opens: [3](#0-2) 

These workers execute sub-pruners that write to the same database keys. For example, `EventStorePruner::prune()` writes to `DbMetadataKey::EventPrunerProgress`: [4](#0-3) 

**The Race Condition Flow:**

When fast sync completes, `finalize_state_snapshot()` calls `save_min_readable_version()`: [5](#0-4) 

This in turn calls `write_pruner_progress()`: [6](#0-5) 

Concurrently, pruner workers are activated after each transaction commit: [7](#0-6) 

The sub-pruners execute in parallel using Rayon: [8](#0-7) 

**Race Scenario:**
1. Thread A (fast sync finalization) starts writing version V1 to all 8 databases sequentially
2. Thread A writes V1 to event_db.EventPrunerProgress
3. Thread B (pruner worker) executes EventStorePruner::prune() and writes version V2 to event_db.EventPrunerProgress (overwrites V1)
4. Thread A resumes and continues writing V1 to the remaining 7 databases

**Result:** event_db has version V2 while other databases have version V1 - inconsistent state.

## Impact Explanation

This vulnerability causes **storage inconsistency** requiring manual intervention, qualifying as **MEDIUM severity** under the Aptos bug bounty program:

1. **Storage Inconsistency**: Different databases maintain conflicting pruner progress values
2. **Data Availability Issues**: Historical queries may fail inconsistently depending on which database tracks the request
3. **Pruning Anomalies**: Some databases may prune too aggressively (potential data loss) or insufficiently (storage bloat)
4. **Operational Complications**: Node operators may encounter unexpected behavior when accessing historical ledger data

This aligns with the "State inconsistencies requiring manual intervention" category (MEDIUM severity, up to $10,000). While significant, it does not cause direct fund loss, consensus violations, or network-wide liveness failures that would elevate it to HIGH or CRITICAL severity.

## Likelihood Explanation

**Likelihood: HIGH**

The vulnerability triggers during routine node operations:

1. **Common Operation**: Fast sync is the primary bootstrap mechanism for new nodes
2. **No Attacker Required**: Natural race condition between concurrent threads
3. **Enabled by Default**: Pruner workers are initialized when AptosDB opens if pruning is enabled in configuration: [9](#0-8) 

4. **Wide Race Window**: Fast sync duration provides significant opportunity for the race to manifest
5. **Active Triggers**: Transaction commits during fast sync continuously activate pruner workers

The vulnerability requires no special privileges, malicious input, or complex preconditions - it's an inherent concurrency defect in normal execution paths.

## Recommendation

Implement atomic pruner progress updates using one of these approaches:

**Option 1: Single atomic batch**
```rust
pub(crate) fn write_pruner_progress(&self, version: Version) -> Result<()> {
    let mut batch = SchemaBatch::new();
    
    // Collect all writes in a single batch
    self.event_db.add_pruner_progress_to_batch(&mut batch, version)?;
    self.persisted_auxiliary_info_db.add_pruner_progress_to_batch(&mut batch, version)?;
    // ... other databases
    
    // Atomic write across all databases
    self.write_batch_atomically(batch)
}
```

**Option 2: Pause pruner workers during write**
```rust
pub(crate) fn write_pruner_progress(&self, version: Version) -> Result<()> {
    // Acquire lock to prevent concurrent pruner operations
    let _pruner_lock = self.pruner_update_lock.lock();
    
    // Perform sequential writes
    self.event_db.write_pruner_progress(version)?;
    // ... other databases
    
    Ok(())
}
```

**Option 3: Coordinate with pruner manager**
Temporarily pause pruner workers before calling `write_pruner_progress()` and resume after completion.

## Proof of Concept

The race condition can be demonstrated by:

1. Starting a node with pruning enabled
2. Initiating fast sync
3. Monitoring pruner progress values across all 8 sub-databases during `finalize_state_snapshot()`
4. Observing inconsistent values when pruner worker threads interleave with the sequential writes

A minimal reproduction would require instrumenting the code with logging or sleeps to widen the race window, as the actual occurrence depends on thread scheduling. The vulnerability is architecturally present in the sequential, non-atomic write pattern combined with concurrent pruner worker execution.

---

**Notes:**
- This vulnerability affects both sharded and non-sharded database configurations
- In sharded mode, each database is a separate RocksDB instance, making the race more severe
- In non-sharded mode, databases share a RocksDB instance but use different column families, and individual puts are still non-atomic across the 8 calls
- The severity is classified as MEDIUM (not HIGH) because it causes storage inconsistency requiring intervention but does not directly compromise funds, consensus, or network liveness

### Citations

**File:** storage/aptosdb/src/ledger_db/mod.rs (L373-388)
```rust
    pub(crate) fn write_pruner_progress(&self, version: Version) -> Result<()> {
        info!("Fast sync is done, writing pruner progress {version} for all ledger sub pruners.");
        self.event_db.write_pruner_progress(version)?;
        self.persisted_auxiliary_info_db
            .write_pruner_progress(version)?;
        self.transaction_accumulator_db
            .write_pruner_progress(version)?;
        self.transaction_auxiliary_data_db
            .write_pruner_progress(version)?;
        self.transaction_db.write_pruner_progress(version)?;
        self.transaction_info_db.write_pruner_progress(version)?;
        self.write_set_db.write_pruner_progress(version)?;
        self.ledger_metadata_db.write_pruner_progress(version)?;

        Ok(())
    }
```

**File:** storage/aptosdb/src/ledger_db/event_db.rs (L47-52)
```rust
    pub(super) fn write_pruner_progress(&self, version: Version) -> Result<()> {
        self.db.put::<DbMetadataSchema>(
            &DbMetadataKey::EventPrunerProgress,
            &DbMetadataValue::Version(version),
        )
    }
```

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L81-84)
```rust
        let worker_thread = std::thread::Builder::new()
            .name(format!("{name}_pruner"))
            .spawn(move || inner_cloned.work())
            .expect("Creating pruner thread should succeed.");
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs (L66-69)
```rust
        batch.put::<DbMetadataSchema>(
            &DbMetadataKey::EventPrunerProgress,
            &DbMetadataValue::Version(target_version),
        )?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L225-225)
```rust
            self.ledger_pruner.save_min_readable_version(version)?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L628-629)
```rust
            self.ledger_pruner
                .maybe_set_pruner_target_db_version(version);
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L80-89)
```rust
    fn save_min_readable_version(&self, min_readable_version: Version) -> Result<()> {
        self.min_readable_version
            .store(min_readable_version, Ordering::SeqCst);

        PRUNER_VERSIONS
            .with_label_values(&["ledger_pruner", "min_readable"])
            .set(min_readable_version as i64);

        self.ledger_db.write_pruner_progress(min_readable_version)
    }
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs (L113-121)
```rust
        let pruner_worker = if ledger_pruner_config.enable {
            Some(Self::init_pruner(
                Arc::clone(&ledger_db),
                ledger_pruner_config,
                internal_indexer_db,
            ))
        } else {
            None
        };
```

**File:** storage/aptosdb/src/pruner/ledger_pruner/mod.rs (L78-84)
```rust
            THREAD_MANAGER.get_background_pool().install(|| {
                self.sub_pruners.par_iter().try_for_each(|sub_pruner| {
                    sub_pruner
                        .prune(progress, current_batch_target_version)
                        .map_err(|err| anyhow!("{} failed to prune: {err}", sub_pruner.name()))
                })
            })?;
```
