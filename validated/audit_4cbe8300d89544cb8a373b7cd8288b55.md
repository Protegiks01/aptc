# Audit Report

## Title
Memory Leak in ProofCoordinator: Unbounded Growth of batch_info_to_time HashMap Due to Incomplete Cleanup in expire()

## Summary
The `expire()` function in `ProofCoordinator` fails to remove entries from the `batch_info_to_time` HashMap when batches expire without completing. This creates a memory leak causing unbounded HashMap growth, eventually leading to memory exhaustion and validator node instability.

## Finding Description

The `ProofCoordinator` maintains two parallel HashMap structures to track batches during proof-of-store formation: `batch_info_to_proof` and `batch_info_to_time`. [1](#0-0) 

When a batch is initialized, entries are added to both HashMaps in the `init_proof()` function. [2](#0-1) 

There are two cleanup paths:

**Path 1: Successful proof completion** - When a batch receives enough signatures to form a quorum, the entry is removed from `batch_info_to_time`. [3](#0-2) 

**Path 2: Expiration without completion** - When a batch times out before achieving quorum, the `expire()` function **only removes from `batch_info_to_proof`**, but NOT from `batch_info_to_time`. [4](#0-3) 

This asymmetry creates a memory leak. Every batch that expires without completing leaves a permanent entry in `batch_info_to_time` containing a `BatchInfoExt` key and `Instant` value. Grep search confirms `batch_info_to_time` is only referenced in 4 locations throughout the entire codebase (field definition, initialization, insertion during init, and removal on success), confirming there is no other cleanup path.

**Triggering Conditions:**
- Network partitions preventing signature propagation
- Validator unavailability or slow response times
- Byzantine validators withholding signatures
- Normal operations where some batches naturally fail to achieve quorum within the timeout window

## Impact Explanation

**Severity: Medium to High**

This vulnerability aligns with **High severity** ("Validator Node Slowdowns" - up to $50,000) in the Aptos Bug Bounty program, as it causes progressive memory exhaustion affecting validator performance. It can also be classified as **Medium severity** ("State inconsistencies requiring manual intervention" - up to $10,000).

**Resource Exhaustion Impact:**
- Each leaked entry contains a `BatchInfoExt` structure and an `Instant` timestamp
- Over days/weeks of continuous operation, thousands of entries accumulate
- HashMap growth degrades performance through increased memory pressure
- Eventually leads to OOM conditions requiring node restart

**Operational Impact:**
- Validator nodes experience progressive slowdown
- Memory alerts trigger requiring manual intervention
- Node restarts needed to clear leaked memory
- Reduced consensus participation during recovery

The gradual nature and recoverability through restart justify Medium severity, while the direct impact on validator performance could justify High severity.

## Likelihood Explanation

**Likelihood: High**

This vulnerability will manifest in all production deployments given sufficient time. Batch timeouts are expected operational events, as evidenced by the dedicated `TIMEOUT_BATCHES_COUNT` counter and logging. [5](#0-4) 

The `expire()` function is called every 100ms in the main event loop. [6](#0-5) [7](#0-6) 

**Factors:**
1. Even under optimal conditions, some batches fail to achieve quorum within timeout windows
2. During network stress, batch expiry rates increase significantly
3. No recovery mechanism exists - the leak is permanent until node restart
4. The presence of `TIMEOUT_BATCHES_COUNT` metric indicates timeouts are normal, not exceptional

## Recommendation

Add cleanup of `batch_info_to_time` entries in the `expire()` function. The fix should mirror the removal from `batch_info_to_proof`:

```rust
async fn expire(&mut self) {
    let mut batch_ids = vec![];
    for signed_batch_info_info in self.timeouts.expire() {
        // Add this line to prevent memory leak
        self.batch_info_to_time.remove(&signed_batch_info_info);
        
        if let Some(state) = self.batch_info_to_proof.remove(&signed_batch_info_info) {
            // ... rest of the function
        }
    }
    // ... rest of the function
}
```

This ensures both HashMaps maintain consistency and prevents unbounded memory growth.

## Proof of Concept

While a full PoC would require running a validator node over extended time, the vulnerability is evident from code inspection:

1. Deploy a validator node running this code
2. Monitor memory usage of the consensus process over days/weeks
3. Observe progressive growth in heap memory corresponding to `batch_info_to_time` entries
4. Correlate growth rate with `TIMEOUT_BATCHES_COUNT` metric
5. Eventually observe OOM conditions or severe performance degradation

The asymmetric cleanup is structurally visible: `expire()` removes from `batch_info_to_proof` but has no corresponding removal from `batch_info_to_time`, while `add_signature()` removes from `batch_info_to_time` only on successful completion.

## Notes

This is a **VALID VULNERABILITY** affecting the Aptos consensus layer. The memory leak occurs during normal operations and will affect all validator nodes over time. The bug is confirmed through direct code inspection showing asymmetric cleanup between parallel data structures. The presence of timeout metrics and dedicated timeout handling code confirms that batch expiration is an expected operational scenario, not an edge case.

### Citations

**File:** consensus/src/quorum_store/proof_coordinator.rs (L233-235)
```rust
    batch_info_to_proof: HashMap<BatchInfoExt, IncrementalProofState>,
    // to record the batch creation time
    batch_info_to_time: HashMap<BatchInfoExt, Instant>,
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L290-304)
```rust
            self.batch_info_to_proof.insert(
                signed_batch_info.batch_info().clone(),
                IncrementalProofState::new_batch_info_ext(signed_batch_info.batch_info().clone()),
            );
        } else {
            self.batch_info_to_proof.insert(
                signed_batch_info.batch_info().clone(),
                IncrementalProofState::new_batch_info(
                    signed_batch_info.batch_info().info().clone(),
                ),
            );
        }
        self.batch_info_to_time
            .entry(signed_batch_info.batch_info().clone())
            .or_insert(Instant::now());
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L338-346)
```rust
                let duration = self
                    .batch_info_to_time
                    .remove(signed_batch_info.batch_info())
                    .ok_or(
                        // Batch created without recording the time!
                        SignedBatchInfoError::NoTimeStamps,
                    )?
                    .elapsed();
                counters::BATCH_TO_POS_DURATION.observe_duration(duration);
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L369-402)
```rust
    async fn expire(&mut self) {
        let mut batch_ids = vec![];
        for signed_batch_info_info in self.timeouts.expire() {
            if let Some(state) = self.batch_info_to_proof.remove(&signed_batch_info_info) {
                if !state.completed {
                    batch_ids.push(signed_batch_info_info.batch_id());
                }
                Self::update_counters_on_expire(&state);

                // We skip metrics if the proof did not complete and did not get a self vote, as it
                // is considered a proof that was re-inited due to a very late vote.
                if !state.completed && !state.self_voted {
                    continue;
                }

                if !state.completed {
                    counters::TIMEOUT_BATCHES_COUNT.inc();
                    info!(
                        LogSchema::new(LogEvent::IncrementalProofExpired),
                        digest = signed_batch_info_info.digest(),
                        self_voted = state.self_voted,
                    );
                }
            }
        }
        if self
            .batch_generator_cmd_tx
            .send(BatchGeneratorCommand::ProofExpiration(batch_ids))
            .await
            .is_err()
        {
            warn!("Failed to send proof expiration to batch generator");
        }
    }
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L410-410)
```rust
        let mut interval = time::interval(Duration::from_millis(100));
```

**File:** consensus/src/quorum_store/proof_coordinator.rs (L506-507)
```rust
                _ = interval.tick() => {
                    monitor!("proof_coordinator_handle_tick", self.expire().await);
```
