# Audit Report

## Title
Unbounded Memory Growth in State Sync Driver Due to Unbounded Consensus Notification Channel

## Summary
The state sync driver uses an unbounded channel to receive consensus notifications while using bounded channels for downstream handlers (mempool and storage service). When the driver blocks waiting to forward notifications to these bounded channels, consensus continues queuing notifications in the unbounded channel, causing unbounded memory growth and eventual node crash.

## Finding Description

The vulnerability stems from an asymmetric channel design in the state sync driver. The consensus notification channel is unbounded [1](#0-0) , allowing consensus to send notifications without blocking. However, downstream channels are bounded: the mempool notification channel has a configurable size (default 100) [2](#0-1) , and the storage service notification channel has a fixed size of 1 [3](#0-2) .

When the state sync driver processes a consensus commit notification [4](#0-3) , it must forward the notification to both the storage service and mempool [5](#0-4) . These `.await` calls block if the bounded channels are full.

While the state sync driver is blocked, it cannot process new messages from its event loop [6](#0-5) . Meanwhile, consensus continues committing blocks and sending notifications through the unbounded channel [7](#0-6) , which are queued immediately. This process repeats, causing the unbounded channel to grow without limit until the node exhausts memory and crashes.

## Impact Explanation

This vulnerability qualifies as **High Severity** per Aptos bug bounty criteria under "Validator Node Slowdowns" - specifically resource exhaustion through DoS. The impact includes:

1. **Memory Pressure**: As the unbounded queue grows, memory consumption increases, degrading node performance
2. **Node Crashes**: Eventually leads to out-of-memory crashes requiring node restart
3. **Network Availability**: Affects both validator and full node availability, potentially causing cascading failures if multiple nodes are affected simultaneously
4. **Degraded Performance**: During high transaction throughput periods, affected nodes become unresponsive

This meets the High Severity criteria because it causes significant performance degradation affecting consensus and enables DoS through resource exhaustion.

## Likelihood Explanation

**Likelihood: Medium to High**

The vulnerability can be triggered in realistic operational scenarios:

1. **High Transaction Throughput**: During sustained high transaction volume, the mempool channel (size 100) can fill up when mempool processing falls behind
2. **Disk I/O Bottlenecks**: The storage service channel (size 1) fills immediately when storage operations slow due to disk contention
3. **Cascading Effect**: Once blocked, each new block commitment accelerates memory growth
4. **Consensus Observer Nodes**: Full nodes running consensus observer are particularly vulnerable as they process commit notifications from network peers

The vulnerability does not require privileged access and can occur naturally under heavy load or be triggered indirectly through legitimate high-volume transaction submission.

## Recommendation

Replace the unbounded consensus notification channel with a bounded channel. The channel size should be carefully chosen to provide backpressure to consensus when state sync falls behind, while being large enough to handle normal operation bursts.

Modify `new_consensus_notifier_listener_pair()` to accept a maximum queue size parameter:

```rust
pub fn new_consensus_notifier_listener_pair(
    timeout_ms: u64,
    max_pending_notifications: usize,
) -> (ConsensusNotifier, ConsensusNotificationListener) {
    let (notification_sender, notification_receiver) = mpsc::channel(max_pending_notifications);
    // ... rest of implementation
}
```

Additionally, consider implementing channel monitoring and alerting to detect when the queue is approaching capacity, allowing operators to take corrective action before nodes crash.

## Proof of Concept

A complete PoC would require setting up a test environment with:
1. A validator or full node with consensus observer enabled
2. High transaction throughput to saturate mempool processing
3. Disk I/O throttling to slow storage service operations
4. Memory monitoring to observe unbounded growth

The vulnerability can be observed by monitoring the memory usage of the state sync driver process during sustained heavy load conditions where the storage service or mempool channels remain full.

## Notes

The vulnerability is confirmed through code analysis across multiple files in the state-sync component. The unbounded channel design choice [1](#0-0)  combined with bounded downstream channels creates a memory safety issue that can be exploited under high load conditions. The storage service channel's intentionally small size (1) [8](#0-7)  makes this vulnerability particularly likely to trigger in production environments.

### Citations

**File:** state-sync/inter-component/consensus-notifications/src/lib.rs (L62-62)
```rust
    let (notification_sender, notification_receiver) = mpsc::unbounded();
```

**File:** state-sync/inter-component/consensus-notifications/src/lib.rs (L108-113)
```rust
        // Send the notification to state sync
        if let Err(error) = self
            .notification_sender
            .clone()
            .send(commit_notification)
            .await
```

**File:** state-sync/inter-component/mempool-notifications/src/lib.rs (L52-53)
```rust
    let (notification_sender, notification_receiver) =
        mpsc::channel(max_pending_mempool_notifications as usize);
```

**File:** state-sync/inter-component/storage-service-notifications/src/lib.rs (L17-20)
```rust
// Note: we limit the queue depth to 1 because it doesn't make sense for the storage service
// to execute for every notification (because it reads the latest version in the DB). Thus,
// if there are X pending notifications, the first one will refresh using the latest DB and
// the next X-1 will execute with an unchanged DB (thus, becoming a no-op and wasting the CPU).
```

**File:** state-sync/inter-component/storage-service-notifications/src/lib.rs (L21-21)
```rust
const STORAGE_SERVICE_NOTIFICATION_CHANNEL_SIZE: usize = 1;
```

**File:** state-sync/state-sync-driver/src/driver.rs (L222-238)
```rust
            ::futures::select! {
                notification = self.client_notification_listener.select_next_some() => {
                    self.handle_client_notification(notification).await;
                },
                notification = self.commit_notification_listener.select_next_some() => {
                    self.handle_snapshot_commit_notification(notification).await;
                }
                notification = self.consensus_notification_handler.select_next_some() => {
                    self.handle_consensus_or_observer_notification(notification).await;
                }
                notification = self.error_notification_listener.select_next_some() => {
                    self.handle_error_notification(notification).await;
                }
                _ = progress_check_interval.select_next_some() => {
                    self.drive_progress().await;
                }
            }
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L97-104)
```rust
        storage_service_notification_handler
            .notify_storage_service_of_committed_transactions(latest_synced_version)
            .await?;

        // Notify mempool of the committed transactions
        mempool_notification_handler
            .notify_mempool_of_committed_transactions(transactions, blockchain_timestamp_usecs)
            .await?;
```
