# Audit Report

## Title
TOCTOU Race Condition in State Sync Driver Causes Incorrect Rejection of Valid Consensus Sync Requests Leading to Validator Panics

## Summary
The state-sync driver performs two non-atomic reads of `latest_pre_committed_version` and `latest_committed_version` from separate data sources without synchronization, creating a TOCTOU race condition. This causes valid consensus sync requests to be incorrectly rejected during epoch transitions, triggering validator node panics with no recovery mechanism.

## Finding Description

The vulnerability exists in the state-sync driver's handling of consensus sync target notifications. The `handle_consensus_sync_target_notification` function fetches the pre-committed and committed versions through two separate, non-atomic function calls: [1](#0-0) 

These versions are read from different data sources:
- Pre-committed version from state_store: [2](#0-1) 
- Committed version from metadata_db: [3](#0-2) 

The storage layer explicitly allows concurrent pre-committing and committing with separate locks: [4](#0-3) [5](#0-4) 

**Race Condition Mechanism:**

1. State-sync driver reads `pre_committed_version = 100` from state_store
2. Storage thread executes `pre_commit_ledger`, updating state_store to version 150
3. Storage thread executes `commit_ledger`, updating metadata_db to version 150  
4. State-sync driver reads `committed_version = 150` from metadata_db
5. Driver observes: `pre_committed=100 < committed=150`

The validation logic in `initialize_sync_target_request` then incorrectly rejects the sync request: [6](#0-5) 

When `sync_target=120`, the condition `sync_target_version < latest_committed_version` (120 < 150) evaluates to true, returning an `OldSyncRequest` error even though the sync target is valid.

## Impact Explanation

This qualifies as **High Severity** under Aptos bug bounty criteria for **Validator Node Crashes**:

**Validator Node Panic During Epoch Transitions:**
The consensus EpochManager calls `sync_to_target` with `.expect("Failed to sync to new epoch")`: [7](#0-6) 

When the race condition causes sync request rejection, the validator immediately panics and terminates.

**No Error Recovery Mechanism:**
The execution client's sync implementation contains an unresolved TODO acknowledging missing error handling: [8](#0-7) 

**Potential for Multiple Validator Impact:**
During epoch transitions, all validators call `sync_to_target` simultaneously. If the network is under high load with concurrent commits, multiple validators could hit this race condition concurrently, leading to significant liveness degradation.

## Likelihood Explanation

This vulnerability has **MEDIUM-HIGH likelihood**:

1. **No Synchronization**: The two reads occur without any lock spanning both operations, exposing the race window
2. **Separate Locks**: Pre-commit and commit operations use different locks that don't protect readers: [9](#0-8) 
3. **Realistic Timing**: Storage commits take milliseconds, creating a realistic window for the race
4. **High-Frequency Scenario**: Most likely during epoch transitions when sync_to_target is called while commits are ongoing
5. **Production-Critical Timing**: Triggers during the most critical operational periods (epoch transitions, recovery)

## Recommendation

Implement atomic reading of both versions with a read lock or snapshot mechanism. Options include:

1. **Add a reader lock** that prevents commits during version reads
2. **Read both versions atomically** from a single consistent snapshot
3. **Retry logic** in the epoch manager instead of `.expect()` panic
4. **Relaxed validation** that accounts for stale reads by checking against only one version

Example fix - add synchronization in the driver:
```rust
// Acquire a read snapshot that ensures consistent version reads
let version_snapshot = storage.get_version_snapshot()?;
let latest_pre_committed_version = version_snapshot.pre_committed_version();
let latest_synced_ledger_info = version_snapshot.synced_ledger_info();
```

## Proof of Concept

The race can be demonstrated by:

1. Start validator during epoch transition
2. Monitor `handle_consensus_sync_target_notification` calls
3. Observe concurrent `pre_commit_ledger` and `commit_ledger` operations
4. Trigger timing where driver reads fall between the two commits
5. Observe `OldSyncRequest` error returned for valid sync target
6. Confirm validator panic from `epoch_manager.rs:565`

The vulnerability is inherent to the non-atomic read pattern and doesn't require specific attacker interaction - it occurs naturally under concurrent load conditions.

## Notes

While the report claims CRITICAL severity for "Total Loss of Liveness/Network Availability," the confirmed impact is validator node crashes during epoch transitions. For network-wide liveness loss, multiple validators (>1/3) would need to be affected simultaneously, which is plausible during synchronized epoch transitions but not definitively proven. The severity is conservatively assessed as **HIGH** for individual validator crashes, with potential escalation to CRITICAL if multiple validators are demonstrably affected in production scenarios.

The core technical finding is valid: the TOCTOU race exists, can cause incorrect sync request rejection, and leads to validator panics with no recovery mechanism.

### Citations

**File:** state-sync/state-sync-driver/src/driver.rs (L413-416)
```rust
        let latest_pre_committed_version =
            utils::fetch_pre_committed_version(self.storage.clone())?;
        let latest_synced_ledger_info =
            utils::fetch_latest_synced_ledger_info(self.storage.clone())?;
```

**File:** storage/aptosdb/src/db/aptosdb_reader.rs (L137-140)
```rust
    fn get_pre_committed_version(&self) -> Result<Option<Version>> {
        gauged_api("get_pre_committed_version", || {
            Ok(self.state_store.current_state_locked().version())
        })
```

**File:** storage/aptosdb/src/ledger_db/ledger_metadata_db.rs (L94-97)
```rust
    pub(crate) fn get_latest_ledger_info_option(&self) -> Option<LedgerInfoWithSignatures> {
        let ledger_info_ptr = self.latest_ledger_info.load();
        let ledger_info: &Option<_> = ledger_info_ptr.deref();
        ledger_info.clone()
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L46-47)
```rust
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L85-86)
```rust
            // Pre-committing and committing in concurrency is allowed but not pre-committing at the
            // same time from multiple threads, the same for committing.
```

**File:** state-sync/state-sync-driver/src/notification_handlers.rs (L276-285)
```rust
        if sync_target_version < latest_committed_version
            || sync_target_version < latest_pre_committed_version
        {
            let error = Err(Error::OldSyncRequest(
                sync_target_version,
                latest_pre_committed_version,
                latest_committed_version,
            ));
            self.respond_to_sync_target_notification(sync_target_notification, error.clone())?;
            return error;
```

**File:** consensus/src/epoch_manager.rs (L560-565)
```rust
            .await
            .context(format!(
                "[EpochManager] State sync to new epoch {}",
                ledger_info
            ))
            .expect("Failed to sync to new epoch");
```

**File:** consensus/src/pipeline/execution_client.rs (L669-671)
```rust
        // TODO: handle the state sync error (e.g., re-push the ordered
        // blocks to the buffer manager when it's reset but sync fails).
        self.execution_proxy.sync_to_target(target).await
```

**File:** storage/aptosdb/src/db/mod.rs (L35-37)
```rust
    pre_commit_lock: std::sync::Mutex<()>,
    /// This is just to detect concurrent calls to `commit_ledger()`
    commit_lock: std::sync::Mutex<()>,
```
