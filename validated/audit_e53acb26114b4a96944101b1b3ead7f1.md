# Audit Report

## Title
Premature Stream Termination via Malicious last_index Manipulation in State Sync

## Summary
A malicious peer can cause state sync streams to terminate prematurely by manipulating the `last_index` field in `StateValueChunkWithProof` responses. The data streaming service trusts the peer-provided `last_index` value without validating it matches the actual data received, causing the stream to mark itself complete before missing data can be requested, leaving nodes with incomplete state.

## Finding Description

The vulnerability exists in the state synchronization data streaming service where the stream completion logic operates on unchecked peer input, creating a race condition that bypasses missing data recovery mechanisms.

**Vulnerable Stream Completion Logic:**

The `StateStreamEngine::transform_client_response_into_notification()` function extracts `last_index` directly from the peer response without validation: [1](#0-0) 

The stream is marked complete based on this unchecked value using a comparison against the expected last stream index: [2](#0-1) 

The `bound_by_range` function only ensures the index is within the requested range, but does not validate it against the actual data count: [3](#0-2) 

**Missing Data Detection (Bypassed):**

The system does attempt to detect incomplete responses by comparing actual data received against expected count: [4](#0-3) 

When missing data is detected, a request is created and queued to the front of the pending requests: [5](#0-4) [6](#0-5) 

**The Race Condition:**

The response processing loop exhibits the vulnerability through its ordering: [7](#0-6) 

The missing data request is queued, then the notification is sent which marks the stream complete: [8](#0-7) 

The transform function is called within send_data_notification_to_client: [9](#0-8) 

The loop breaks due to head-of-line blocking: [10](#0-9) 

On the next invocation, the stream completion check prevents any further processing: [11](#0-10) 

**Why Bootstrapper Validation Is Insufficient:**

The `StateValueChunkWithProof` struct contains a TODO comment indicating verification is not yet implemented: [12](#0-11) 

The bootstrapper does validate that `last_index - first_index + 1 == raw_values.len()`: [13](#0-12) 

However, this validation occurs after the data streaming service has already marked the stream complete. The bootstrapper can only reset and retry the entire sync process from scratch: [14](#0-13) 

When the stream is reset, all pending requests are cleared: [15](#0-14) 

**Attack Execution:**

1. Syncing node requests state values with indices 0-99 (100 total states)
2. Malicious peer responds to a request for indices 50-99 with:
   - `first_index = 50`
   - `last_index = 99` (manipulated to match `last_stream_index`)
   - `raw_values` containing only 10 items (indices 50-59)
3. Missing data detection triggers, creating a request for indices 60-99
4. Stream completion check evaluates `99 >= 99`, marking `stream_is_complete = true`
5. Next iteration returns early; missing data request never processed
6. Bootstrapper receives incomplete data, detects mismatch, resets stream
7. Node must restart entire sync; if same malicious peer selected, attack repeats

## Impact Explanation

This vulnerability qualifies as **High Severity** under Aptos bug bounty criteria for "Validator Node Slowdowns":

**Operational Impact:** Nodes attempting to bootstrap or recover from downtime will repeatedly fail state synchronization. Each failed attempt consumes network bandwidth, CPU resources, and storage I/O before detecting the incomplete data at the bootstrapper layer. Nodes must retry the entire sync process multiple times until the malicious peer is eventually blacklisted through the peer scoring mechanism.

**Availability Impact:** This creates a significant barrier to:
- New validators joining the network (cannot complete initial sync)
- Existing validators recovering from downtime (cannot catch up to current state)
- Full nodes performing state snapshots (cannot obtain complete state)

**State Consistency Violation:** While the bootstrapper's validation prevents incomplete state from being committed to storage, the vulnerability violates the design expectation that the data streaming service should deliver complete data chunks. The service incorrectly signals completion, breaking the trust boundary between streaming and storage layers.

**Attack Feasibility:** Requires only a malicious peer with no validator access needed. The attack is deterministic and causes guaranteed failures on every sync attempt where the malicious peer is selected.

## Likelihood Explanation

**Likelihood: HIGH**

**Attacker Requirements:**
- Ability to participate as a peer in the P2P network (low barrier to entry)
- Capability to respond to state sync data requests (standard peer function)
- No special privileges, stake, or validator access required

**Attack Complexity: LOW**
- Single malformed response per sync attempt
- No precise timing requirements
- Deterministic outcome based on simple field manipulation

**Exploitation Frequency:**
The vulnerability triggers on every state sync attempt when a malicious peer is selected to serve data. State synchronization occurs during:
- Initial node bootstrapping
- Validator recovery after downtime  
- Full node state snapshot operations
- Any network partition recovery

The peer selection mechanism will eventually blacklist the malicious peer through repeated `InvalidPayloadData` feedback, but this requires multiple failed attempts first, each consuming significant resources.

## Recommendation

Validate the peer-provided `last_index` against the actual number of state values received before marking the stream complete. The fix should be applied in `StateStreamEngine::transform_client_response_into_notification()`:

```rust
// After extracting last_received_index, validate it matches the data
let expected_last_index = state_values_with_proof.first_index
    .checked_add(state_values_with_proof.raw_values.len() as u64)
    .and_then(|v| v.checked_sub(1))
    .ok_or_else(|| Error::IntegerOverflow("Last index calculation overflowed!".into()))?;

if state_values_with_proof.last_index != expected_last_index {
    return Err(Error::AptosDataClientResponseIsInvalid(format!(
        "Peer-provided last_index ({}) does not match actual data ({})",
        state_values_with_proof.last_index, expected_last_index
    )));
}
```

Alternatively, use the validated `expected_last_index` for all subsequent operations instead of the peer-provided value.

## Proof of Concept

A complete PoC would require setting up a mock malicious peer in the test environment. The test would:
1. Create a state sync stream requesting indices 0-99
2. Mock a peer response with `first_index=50`, `last_index=99`, but only 10 items in `raw_values`
3. Verify that the stream marks itself complete prematurely
4. Verify that the queued missing data request is never processed
5. Verify that the bootstrapper detects the error but cannot recover the missing data

The test should be added to `state-sync/data-streaming-service/src/tests/missing_data.rs` following the pattern of existing tests in that file.

## Notes

This vulnerability represents a trust boundary violation where the data streaming service layer trusts peer-provided metadata without validation. While the bootstrapper layer provides defense-in-depth validation, the premature stream termination in the streaming layer causes unnecessary sync failures and resource waste. The attack does not compromise state integrity due to the bootstrapper's validation, but it significantly degrades node availability and synchronization performance.

### Citations

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L330-330)
```rust
                        state_values_with_proof.last_index
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L334-335)
```rust
                let last_received_index =
                    bound_by_range(last_received_index, request.start_index, request.end_index);
```

**File:** state-sync/data-streaming-service/src/stream_engine.rs (L347-349)
```rust
                if last_received_index >= last_stream_index {
                    self.stream_is_complete = true;
                }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L176-184)
```rust
    pub fn clear_sent_data_requests_queue(&mut self) {
        // Clear all pending data requests
        if let Some(sent_data_requests) = self.sent_data_requests.as_mut() {
            sent_data_requests.clear();
        }

        // Abort all spawned tasks
        self.abort_spawned_tasks();
    }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L446-453)
```rust
        if self.stream_engine.is_stream_complete()
            || self.request_failure_count >= self.streaming_service_config.max_request_retry
            || self.send_failure
        {
            if !self.send_failure && self.stream_end_notification_id.is_none() {
                self.send_end_of_stream_notification().await?;
            }
            return Ok(()); // There's nothing left to do
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L473-478)
```rust
                        match self.request_missing_data(client_request, &client_response.payload) {
                            Ok(missing_data_requested) => {
                                if missing_data_requested {
                                    head_of_line_blocked = true; // We're now head of line blocked on the missing data
                                }
                            },
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L502-503)
```rust
                        self.send_data_notification_to_client(client_request, client_response)
                            .await?;
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L513-516)
```rust
                        // If we're head of line blocked, we should return early
                        if head_of_line_blocked {
                            break;
                        }
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L669-670)
```rust
            self.get_sent_data_requests()?
                .push_front(pending_client_response);
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L775-781)
```rust
        if let Some(data_notification) = self
            .stream_engine
            .transform_client_response_into_notification(
                data_client_request,
                response_payload,
                self.notification_id_generator.clone(),
            )?
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L1122-1125)
```rust
        ResponsePayload::StateValuesWithProof(state_values_with_proof) => {
            // Check if the request was satisfied
            let num_received_state_values = state_values_with_proof.raw_values.len() as u64;
            if num_received_state_values < num_requested_state_values {
```

**File:** state-sync/data-streaming-service/src/data_stream.rs (L1126-1136)
```rust
                let start_index = request
                    .start_index
                    .checked_add(num_received_state_values)
                    .ok_or_else(|| Error::IntegerOverflow("Start index has overflown!".into()))?;
                Ok(Some(DataClientRequest::StateValuesWithProof(
                    StateValuesWithProofRequest {
                        version: request.version,
                        start_index,
                        end_index: request.end_index,
                    },
                )))
```

**File:** types/src/state_store/state_value.rs (L337-353)
```rust
/// TODO(joshlind): add a proof implementation (e.g., verify()) and unit tests
/// for these once we start supporting them.
///
/// A single chunk of all state values at a specific version.
/// Note: this is similar to `StateSnapshotChunk` but all data is included
/// in the struct itself and not behind pointers/handles to file locations.
#[derive(Clone, Debug, Deserialize, Eq, PartialEq, Serialize)]
#[cfg_attr(any(test, feature = "fuzzing"), derive(proptest_derive::Arbitrary))]
pub struct StateValueChunkWithProof {
    pub first_index: u64,     // The first hashed state index in chunk
    pub last_index: u64,      // The last hashed state index in chunk
    pub first_key: HashValue, // The first hashed state key in chunk
    pub last_key: HashValue,  // The last hashed state key in chunk
    pub raw_values: Vec<(StateKey, StateValue)>, // The hashed state key and and raw state value.
    pub proof: SparseMerkleRangeProof, // The proof to ensure the chunk is in the hashed states
    pub root_hash: HashValue, // The root hash of the sparse merkle tree for this chunk
}
```

**File:** state-sync/state-sync-driver/src/bootstrapper.rs (L938-956)
```rust
        let expected_num_state_values = state_value_chunk_with_proof
            .last_index
            .checked_sub(state_value_chunk_with_proof.first_index)
            .and_then(|version| version.checked_add(1)) // expected_num_state_values = last_index - first_index + 1
            .ok_or_else(|| {
                Error::IntegerOverflow("The expected number of state values has overflown!".into())
            })?;
        let num_state_values = state_value_chunk_with_proof.raw_values.len() as u64;
        if expected_num_state_values != num_state_values {
            self.reset_active_stream(Some(NotificationAndFeedback::new(
                notification_id,
                NotificationFeedback::InvalidPayloadData,
            )))
            .await?;
            return Err(Error::VerificationError(format!(
                "The expected number of state values was invalid! Expected: {:?}, received: {:?}",
                expected_num_state_values, num_state_values,
            )));
        }
```
