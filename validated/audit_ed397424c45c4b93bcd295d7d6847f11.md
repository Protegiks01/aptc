# Audit Report

## Title
Memory Exhaustion via Malicious Compressed Mempool Messages Bypassing Rate Limiting

## Summary
A vulnerability exists in the network layer's message decompression that allows attackers to cause excessive memory allocation before application-level rate limiting is applied. The decompression function allocates memory based on an attacker-controlled size header, enabling each malicious message to trigger allocation of up to ~61.875 MiB. With concurrent processing limited only by CPU cores, this can exhaust validator memory and cause node crashes or severe performance degradation.

## Finding Description

The vulnerability arises from the interaction between network message deserialization and the compression decompression implementation. The attack flow is as follows:

**1. Protocol Configuration**: Messages with `ProtocolId::MempoolDirectSend` use `Encoding::CompressedBcs` compression [1](#0-0)  with `CompressionClient::Mempool` [2](#0-1) 

**2. Parallel Deserialization**: The network layer spawns concurrent blocking tasks to deserialize messages, with concurrency defaulting to the number of CPU cores [3](#0-2) . These tasks use `tokio::task::spawn_blocking` [4](#0-3)  and are buffered by `buffer_unordered` or `buffered` [5](#0-4) 

**3. Decompression Path**: The deserialization calls `ProtocolId::from_bytes()` [6](#0-5) , which invokes `aptos_compression::decompress()` with `MAX_APPLICATION_MESSAGE_SIZE` as the maximum [7](#0-6) 

**4. Premature Memory Allocation**: The decompression function reads the claimed decompressed size from the first 4 bytes of the compressed data [8](#0-7) , validates it only against an upper bound [9](#0-8) , then **immediately allocates a buffer of that size** before performing actual decompression [10](#0-9) 

**5. MAX_APPLICATION_MESSAGE_SIZE Calculation**: The maximum decompressed size is calculated as `(MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE` [11](#0-10) , which equals approximately 61.875 MiB [12](#0-11) 

**6. Bypassed Rate Limiting**: The mempool's `shared_mempool_max_concurrent_inbound_syncs` limit [13](#0-12)  is only applied when spawning transaction processing tasks **after** deserialization completes [14](#0-13) 

**Attack Execution**: An attacker can create compressed messages with inflated size headers claiming 60+ MiB decompressed size while the actual compressed payload is only a few KB (e.g., highly compressible data like zeros). The network rate limiter operates on compressed bytes at the socket level, allowing these small messages through while each triggers large memory allocations during decompression.

For a 32-core server, an attacker can trigger 32 concurrent allocations of ~61.875 MiB each, totaling ~1.98 GB of memory consumption before any application-level rate limiting takes effect.

## Impact Explanation

**Severity: High** (per Aptos Bug Bounty category: "Validator node slowdowns")

This vulnerability enables:
- **Memory Exhaustion**: Validators and full nodes can experience out-of-memory conditions leading to degraded performance
- **Node Crashes**: Severe memory pressure can trigger OOM killers, causing validator node crashes
- **Service Degradation**: Excessive memory allocation causes garbage collection pressure and significant performance degradation
- **Network Availability Impact**: If multiple validators are targeted simultaneously, overall network performance and availability degrade

The impact qualifies as **High severity** because it directly causes "Validator node slowdowns" which is explicitly listed in the Aptos Bug Bounty HIGH severity category. While this involves resource exhaustion, it exploits a specific application-level implementation bug (premature memory allocation based on untrusted input) rather than being a simple network flooding attack, distinguishing it from out-of-scope "Network DoS attacks."

## Likelihood Explanation

**Likelihood: High**

The attack is highly feasible because:
- **Low Barrier to Entry**: Requires only network connectivity to send mempool messages (no special privileges or authentication)
- **High Amplification Factor**: Small compressed messages (KB range) trigger large memory allocations (MB range), providing ~6,000-10,000x amplification
- **Concurrent Exploitation**: Default configurations allow dozens of concurrent allocations (equal to CPU cores, typically 8-64)
- **Deterministic Exploitation**: The vulnerability exists in the core message processing path and is always triggered when processing compressed mempool messages
- **Minimal Attack Resources**: Attacker needs minimal bandwidth to exhaust validator memory

An attacker with basic network access can reliably cause memory exhaustion on validators using minimal resources.

## Recommendation

**Fix the premature memory allocation in the decompression function:**

1. **Validate before allocating**: Modify the decompression logic to avoid allocating the full buffer upfront. Instead, use streaming decompression or validate the actual compressed data before allocation.

2. **Add rate limiting earlier in the pipeline**: Apply memory-aware rate limiting before deserialization tasks are spawned, considering the potential decompressed size.

3. **Implement per-peer memory limits**: Track total memory allocated for decompression per peer and enforce limits to prevent a single peer from exhausting resources.

4. **Use bounded memory pools**: Instead of direct allocation, use a bounded memory pool for decompression buffers that limits total concurrent memory usage across all deserialization tasks.

Example conceptual fix for the decompression function:
```rust
// Instead of: let mut raw_data = vec![0u8; decompressed_size];
// Use streaming decompression or validate the compressed data size relative to claimed size
// before allocating memory
```

## Proof of Concept

The vulnerability can be demonstrated by:

1. Creating a compressed message with a size header claiming 60 MiB decompressed size but containing only highly compressible data (e.g., zeros) that compresses to ~2 KB
2. Sending multiple such messages concurrently to a validator node
3. Observing memory allocation spike corresponding to the number of CPU cores Ã— ~61.875 MiB
4. Monitoring for OOM conditions or performance degradation

The attack exploits the fact that memory is allocated based on the size header (attacker-controlled) before the actual decompression validates whether the data truly decompresses to that size.

## Notes

This vulnerability is classified as application-level resource exhaustion through exploitation of a specific implementation bug, not a generic network DoS attack. The distinction is important because:

1. The vulnerability exploits premature memory allocation based on untrusted input (the size header in compressed data)
2. Similar "decompression bomb" vulnerabilities (zip bombs, gzip bombs) are universally treated as application-level security bugs
3. The fix requires changes to the decompression implementation, not network-level defenses
4. It qualifies under the HIGH severity category "Validator node slowdowns" in the Aptos Bug Bounty program

### Citations

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L168-168)
```rust
            ProtocolId::MempoolDirectSend => Encoding::CompressedBcs(USER_INPUT_RECURSION_LIMIT),
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L181-181)
```rust
            ProtocolId::MempoolDirectSend => CompressionClient::Mempool,
```

**File:** network/framework/src/protocols/wire/handshake/v1/mod.rs (L235-240)
```rust
                let raw_bytes = aptos_compression::decompress(
                    &bytes.to_vec(),
                    compression_client,
                    MAX_APPLICATION_MESSAGE_SIZE,
                )
                .map_err(|e| anyhow! {"{:?}", e})?;
```

**File:** config/src/config/network_config.rs (L45-50)
```rust
pub const MAX_MESSAGE_METADATA_SIZE: usize = 128 * 1024; /* 128 KiB: a buffer for metadata that might be added to messages by networking */
pub const MESSAGE_PADDING_SIZE: usize = 2 * 1024 * 1024; /* 2 MiB: a safety buffer to allow messages to get larger during serialization */
pub const MAX_APPLICATION_MESSAGE_SIZE: usize =
    (MAX_MESSAGE_SIZE - MAX_MESSAGE_METADATA_SIZE) - MESSAGE_PADDING_SIZE; /* The message size that applications should check against */
pub const MAX_FRAME_SIZE: usize = 4 * 1024 * 1024; /* 4 MiB large messages will be chunked into multiple frames and streamed */
pub const MAX_MESSAGE_SIZE: usize = 64 * 1024 * 1024; /* 64 MiB */
```

**File:** config/src/config/network_config.rs (L183-183)
```rust
            self.max_parallel_deserialization_tasks = Some(num_cpus::get());
```

**File:** network/framework/src/protocols/network/mod.rs (L218-218)
```rust
            tokio::task::spawn_blocking(move || received_message_to_event(notification))
```

**File:** network/framework/src/protocols/network/mod.rs (L226-232)
```rust
                    .buffer_unordered(max_parallel_deserialization_tasks)
                    .filter_map(|res| future::ready(res.expect("JoinError from spawn blocking"))),
            )
        } else {
            Box::pin(
                data_event_stream
                    .buffered(max_parallel_deserialization_tasks)
```

**File:** network/framework/src/protocols/wire/messaging/v1/mod.rs (L111-112)
```rust
    fn to_message<TMessage: DeserializeOwned>(&self) -> anyhow::Result<TMessage> {
        self.protocol_id().from_bytes(self.data())
```

**File:** crates/aptos-compression/src/lib.rs (L108-108)
```rust
    let mut raw_data = vec![0u8; decompressed_size];
```

**File:** crates/aptos-compression/src/lib.rs (L163-166)
```rust
    let size = (compressed_data[0] as i32)
        | ((compressed_data[1] as i32) << 8)
        | ((compressed_data[2] as i32) << 16)
        | ((compressed_data[3] as i32) << 24);
```

**File:** crates/aptos-compression/src/lib.rs (L174-180)
```rust
    // Ensure that the size is not greater than the max size limit
    let size = size as usize;
    if size > max_size {
        return Err(DecompressionError(format!(
            "Parsed size prefix in buffer is too big: {} > {}",
            size, max_size
        )));
```

**File:** mempool/src/shared_mempool/coordinator.rs (L92-92)
```rust
    let workers_available = smp.config.shared_mempool_max_concurrent_inbound_syncs;
```

**File:** mempool/src/shared_mempool/coordinator.rs (L332-341)
```rust
    bounded_executor
        .spawn(tasks::process_transaction_broadcast(
            smp_clone,
            transactions,
            message_id,
            timeline_state,
            peer,
            task_start_timer,
        ))
        .await;
```
