# Audit Report

## Title
Race Condition in State Merkle Pruner Progress Metadata Allows Inconsistent State Where Pruned Nodes Are Marked as Available

## Summary
A race condition exists between the background pruner worker and state snapshot finalization that can cause the pruner progress metadata to become inconsistent with actual deleted Merkle tree nodes. This allows the system to report data as available when it has been pruned, violating state consistency guarantees and requiring manual intervention to resolve.

## Finding Description

The vulnerability stems from two independent code paths that write to the same database metadata key (`StateMerklePrunerProgress`) without synchronization:

**Path 1: Background Pruner Worker**

The pruner worker runs continuously in a separate thread. [1](#0-0) 

When pruning, it calls `maybe_prune_single_version()` which creates an atomic batch containing both node deletions AND progress metadata updates. [2](#0-1) 

The batch includes deletions of stale nodes and an update to the `StateMerklePrunerProgress` metadata key, written atomically to the database.

**Path 2: State Snapshot Finalization**

During state sync operations, `finalize_state_snapshot()` is called to finalize the snapshot restoration. [3](#0-2) 

This method calls `save_min_readable_version()` on the state merkle pruner. [4](#0-3) 

The `save_min_readable_version()` method performs a **separate, independent write** to the database using `write_pruner_progress()`. [5](#0-4) 

This writes directly to the database without any batching. [6](#0-5) 

**The Race Condition Timeline:**

1. **T1**: Node begins state sync to restore snapshot at version 1200 (long-running operation)
2. **T2**: While state sync is in progress, pruner worker executes `maybe_prune_single_version(1000, 1500)`
   - Creates batch with deletions for stale nodes at versions 1001-1500
   - Adds to batch: `PUT StateMerklePrunerProgress = 1500`
   - Writes batch atomically → Nodes for versions < 1500 are now DELETED
3. **T3**: State sync completes and calls `finalize_state_snapshot(version=1200)`
   - Calls `save_min_readable_version(1200)`
   - Writes: `PUT StateMerklePrunerProgress = 1200` (separate write)
   - **This overwrites the progress from 1500 back to 1200**
4. **Result**: Database state is inconsistent:
   - Progress metadata = 1200 (claims versions ≥1200 are available)
   - Actual Merkle nodes for versions 1200-1499 are DELETED

**No Synchronization Exists:**

The `finalize_state_snapshot` method does not acquire any locks (`commit_lock` or `pre_commit_lock`), and the pruner worker runs independently in a separate thread without coordination. [7](#0-6) 

When attempting to read state at versions 1200-1499, the min_readable_version check would pass, but reading the actual nodes would fail because they were already pruned.

## Impact Explanation

This vulnerability causes **state inconsistency requiring manual intervention**, which aligns with **MEDIUM severity** under the Aptos bug bounty program, potentially escalating to **HIGH severity** depending on operational impact.

**Specific Impacts:**

1. **State Consistency Violation**: The system reports that historical state data is available when it has actually been deleted, breaking the fundamental guarantee that queryable versions can be successfully read.

2. **Failed State Operations**: Any attempt to:
   - Read state at versions 1200-1499
   - Generate state proofs for those versions
   - Perform state sync from those versions
   
   Will fail with node-not-found errors, causing operational failures for validators and fullnodes.

3. **Operational Disruption**: Nodes experiencing this inconsistency cannot serve historical state queries or assist other nodes in state sync operations, degrading network functionality.

4. **Non-Recoverable Without Intervention**: Once the inconsistency occurs, it persists until:
   - Manual database repair
   - Complete re-sync from genesis or a valid snapshot
   - The pruner eventually prunes past the affected range (may not occur if target is already "past" it)

**Note**: While the report claims CRITICAL severity, this does not meet the strict criteria for CRITICAL impact (no direct loss of funds, no consensus safety violation where validators disagree on blocks, no permanent network partition). However, it could escalate to HIGH severity if it causes widespread validator node slowdowns or API crashes.

## Likelihood Explanation

**Likelihood: MEDIUM**

This race condition can occur during normal network operations whenever state snapshot restoration happens concurrently with active pruning:

**Triggering Scenarios:**
- Node performing state sync while pruner is running in the background
- Fast sync bootstrap operations where snapshot download is slower than pruner execution
- Any scenario where state sync takes significant time (minutes) allowing pruner to advance

**Why It's Realistic:**
- State sync operations are long-running (downloading and committing state values)
- The pruner runs continuously in the background on all nodes [8](#0-7) 
- No synchronization mechanism prevents concurrent execution
- The race window is narrow (milliseconds) but state sync duration is long (minutes to hours)

The likelihood is MEDIUM rather than HIGH because:
- State sync operations are less frequent than normal transaction processing
- The timing must align such that pruner advances past the snapshot version during the sync
- Not all nodes will experience this simultaneously

## Recommendation

Implement proper synchronization between the pruner and state snapshot finalization operations. Two potential approaches:

**Option 1: Atomic Progress Updates**
Modify `save_min_readable_version()` to use Compare-And-Swap (CAS) semantics that only updates the progress if the new value is greater than the current value:

```rust
pub fn save_min_readable_version(&self, min_readable_version: Version) -> Result<()> {
    loop {
        let current = self.min_readable_version.load(Ordering::SeqCst);
        if min_readable_version <= current {
            // Don't overwrite with older version
            return Ok(());
        }
        if self.min_readable_version
            .compare_exchange(current, min_readable_version, Ordering::SeqCst, Ordering::SeqCst)
            .is_ok() 
        {
            break;
        }
    }
    
    PRUNER_VERSIONS
        .with_label_values(&[S::name(), "min_readable"])
        .set(min_readable_version as i64);

    self.state_merkle_db
        .write_pruner_progress(&S::progress_metadata_key(None), min_readable_version)
}
```

**Option 2: Locking**
Introduce a pruner lock that both code paths must acquire before modifying pruner progress, ensuring mutual exclusion.

**Option 3: Batch Coordination**
Ensure `finalize_state_snapshot()` includes its progress update in the same batch as other state restoration operations, and coordinate with the pruner to prevent overwrites.

## Proof of Concept

A complete PoC would require:
1. Setting up a node with pruner enabled
2. Initiating a state sync operation
3. Injecting delays to ensure pruner runs during state sync
4. Verifying the progress metadata inconsistency
5. Attempting to read state in the affected range

Due to the concurrent nature and timing requirements, this is best demonstrated through integration testing rather than a simple unit test. The vulnerability is evident from the code structure analysis showing unsynchronized writes to the same metadata key.

## Notes

- The technical race condition is **VALID** and confirmed through code analysis
- The severity assessment should be MEDIUM (state inconsistency requiring manual intervention), potentially HIGH if operational impact is severe
- The claim of "Consensus Divergence" is overstated - this affects state availability, not consensus agreement on blocks
- No PoC is provided, but the code structure clearly demonstrates the vulnerability
- This appears to be a previously unknown issue with no existing mitigations in the codebase

### Citations

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L53-68)
```rust
    fn work(&self) {
        while !self.quit_worker.load(Ordering::SeqCst) {
            let pruner_result = self.pruner.prune(self.batch_size);
            if pruner_result.is_err() {
                sample!(
                    SampleRate::Duration(Duration::from_secs(1)),
                    error!(error = ?pruner_result.err().unwrap(),
                        "Pruner has error.")
                );
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
                continue;
            }
            if !self.pruner.is_pruning_pending() {
                sleep(Duration::from_millis(self.pruning_time_interval_in_ms));
            }
        }
```

**File:** storage/aptosdb/src/pruner/pruner_worker.rs (L81-84)
```rust
        let worker_thread = std::thread::Builder::new()
            .name(format!("{name}_pruner"))
            .spawn(move || inner_cloned.work())
            .expect("Creating pruner thread should succeed.");
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_metadata_pruner.rs (L60-71)
```rust
        let mut batch = SchemaBatch::new();
        indices.into_iter().try_for_each(|index| {
            batch.delete::<JellyfishMerkleNodeSchema>(&index.node_key)?;
            batch.delete::<S>(&index)
        })?;

        batch.put::<DbMetadataSchema>(
            &S::progress_metadata_key(None),
            &DbMetadataValue::Version(target_version_for_this_round),
        )?;

        self.metadata_db.write_schemas(batch)?;
```

**File:** state-sync/state-sync-driver/src/storage_synchronizer.rs (L1129-1136)
```rust
    storage
        .writer
        .finalize_state_snapshot(
            version,
            target_output_with_proof.clone(),
            epoch_change_proofs,
        )
        .map_err(|error| format!("Failed to finalize the state snapshot! Error: {:?}", error))?;
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L125-132)
```rust
    fn finalize_state_snapshot(
        &self,
        version: Version,
        output_with_proof: TransactionOutputListWithProofV2,
        ledger_infos: &[LedgerInfoWithSignatures],
    ) -> Result<()> {
        let (output_with_proof, persisted_aux_info) = output_with_proof.into_parts();
        gauged_api("finalize_state_snapshot", || {
```

**File:** storage/aptosdb/src/db/aptosdb_writer.rs (L225-228)
```rust
            self.ledger_pruner.save_min_readable_version(version)?;
            self.state_store
                .state_merkle_pruner
                .save_min_readable_version(version)?;
```

**File:** storage/aptosdb/src/pruner/state_merkle_pruner/state_merkle_pruner_manager.rs (L74-84)
```rust
    fn save_min_readable_version(&self, min_readable_version: Version) -> Result<()> {
        self.min_readable_version
            .store(min_readable_version, Ordering::SeqCst);

        PRUNER_VERSIONS
            .with_label_values(&[S::name(), "min_readable"])
            .set(min_readable_version as i64);

        self.state_merkle_db
            .write_pruner_progress(&S::progress_metadata_key(None), min_readable_version)
    }
```

**File:** storage/aptosdb/src/state_merkle_db.rs (L568-575)
```rust
    pub(crate) fn write_pruner_progress(
        &self,
        progress_key: &DbMetadataKey,
        version: Version,
    ) -> Result<()> {
        self.state_merkle_metadata_db
            .put::<DbMetadataSchema>(progress_key, &DbMetadataValue::Version(version))
    }
```
