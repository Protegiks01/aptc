# Audit Report

## Title
Race Condition in `send_for_execution()` Causes Validator Panic During Concurrent Root Updates

## Summary
A critical race condition exists in the `send_for_execution()` method where non-atomic read operations on `ordered_root()` allow concurrent threads to observe inconsistent consensus state, causing validators to panic and crash during normal consensus operation.

## Finding Description
The vulnerability exists in `send_for_execution()` where two separate lock acquisitions create a time-of-check to time-of-use (TOCTOU) race condition. [1](#0-0) 

The function performs:
1. **First read lock** (line 323): Checks if `block_to_commit.round() > self.ordered_root().round()`
2. **Lock released**
3. **Second read lock** (line 328): Calls `path_from_ordered_root(block_id_to_commit)`
4. **Lock released**

Each call to `ordered_root()` and `path_from_ordered_root()` acquires a separate read lock on `self.inner` which is immediately released: [2](#0-1) 

Between these two operations, another concurrent thread can acquire a write lock and update the ordered root: [3](#0-2) 

The `path_from_root_to_block()` implementation walks backwards from a block to find the root: [4](#0-3) 

When the root is updated between the two reads, the path calculation fails because it attempts to find a path from a block that is now an **ancestor** of the new root (not a descendant). The algorithm stops when `block.round() <= root_round` (line 529) and then checks if the stopped block equals the root (line 540). When they don't match, it returns `None`.

The `.unwrap_or_default()` on line 329 converts `None` to an empty vector, causing the assertion on line 331 to panic the validator process.

**Exploitation Scenario:**
1. Initial state: `ordered_root` = Block A (round 10)
2. Thread 1 receives finality proof for Block B (round 15)
3. Thread 2 receives finality proof for Block C (round 20)
4. Thread 1: Validates Block B round (15) > root round (10) ✓
5. Thread 2: Validates Block C round (20) > root round (10) ✓
6. Thread 2: Completes execution and updates `ordered_root` to Block C (round 20)
7. Thread 1: Calculates path from **new** root C (round 20) to Block B (round 15)
8. Since Block B (round 15 ≤ 20) is an ancestor, path calculation returns `None`
9. Empty vector causes assertion failure: **Validator crashes**

This race condition is architecturally possible because Aptos consensus uses a multi-threaded tokio runtime: [5](#0-4) 

The `send_for_execution()` method takes `&self` (not `&mut self`), allowing multiple concurrent invocations. These are called from consensus message handlers processing quorum certificates: [6](#0-5) [7](#0-6) 

## Impact Explanation
**High Severity** per Aptos bug bounty criteria:
- **Validator node crash**: The `assert!` macro causes immediate validator process termination when the condition fails
- **Consensus liveness impact**: Reduces the active validator set, potentially approaching the 2/3 threshold needed for consensus progress
- **No recovery without restart**: Requires manual intervention to restart the crashed validator
- **Affects normal operation**: Does not require Byzantine behavior or malicious actors - occurs during legitimate consensus operation

This breaks the **consensus liveness** invariant by removing validators from the network during normal high-throughput operation.

## Likelihood Explanation
**Medium to High Likelihood:**
- Occurs during standard consensus operation when multiple quorum certificates arrive within microseconds of each other
- Network conditions (latency, batching) naturally create concurrent QC processing scenarios
- Higher likelihood during high-throughput periods or network congestion
- No special attacker capabilities required - can be triggered inadvertently through normal network timing
- The race window is small (microseconds) but consensus operates at this timescale with multi-threaded async message processing, making concurrent execution of `send_for_execution()` architecturally possible

## Recommendation
Acquire a single lock for the entire validation and path calculation sequence to ensure atomic read of the ordered root state:

```rust
pub async fn send_for_execution(
    &self,
    finality_proof: WrappedLedgerInfo,
) -> anyhow::Result<()> {
    let block_id_to_commit = finality_proof.commit_info().id();
    let block_to_commit = self
        .get_block(block_id_to_commit)
        .ok_or_else(|| format_err!("Committed block id not found"))?;

    // Acquire lock once for both operations
    let blocks_to_commit = {
        let inner = self.inner.read();
        
        // First make sure that this commit is new
        ensure!(
            block_to_commit.round() > inner.ordered_root().round(),
            "Committed block round lower than root"
        );
        
        // Calculate path while still holding lock
        inner.path_from_ordered_root(block_id_to_commit)
            .ok_or_else(|| format_err!("Failed to compute path from ordered root"))?
    }; // Lock released here
    
    assert!(!blocks_to_commit.is_empty());
    
    // Rest of the function continues...
```

This ensures both the round check and path calculation see a consistent view of the ordered root.

## Proof of Concept
The vulnerability is demonstrated by the code architecture itself - no additional PoC is required as the race condition is inherent in the design where:
1. Multi-threaded tokio runtime enables concurrent execution
2. Two separate read lock acquisitions create a TOCTOU window
3. `send_for_execution()` signature allows concurrent calls via `&self`
4. Path calculation logic returns `None` for ancestor relationships
5. Assertion panics on empty vector

A stress test could trigger this by sending multiple valid quorum certificates simultaneously to a validator node during high-throughput conditions.

## Notes
This vulnerability affects the core consensus liveness guarantee. While the race window is small, the multi-threaded async architecture makes this condition possible during normal operation, particularly under high load. The fix requires ensuring atomicity of the root state observation across both the validation check and the path calculation.

### Citations

**File:** consensus/src/block_storage/block_store.rs (L312-350)
```rust
    pub async fn send_for_execution(
        &self,
        finality_proof: WrappedLedgerInfo,
    ) -> anyhow::Result<()> {
        let block_id_to_commit = finality_proof.commit_info().id();
        let block_to_commit = self
            .get_block(block_id_to_commit)
            .ok_or_else(|| format_err!("Committed block id not found"))?;

        // First make sure that this commit is new.
        ensure!(
            block_to_commit.round() > self.ordered_root().round(),
            "Committed block round lower than root"
        );

        let blocks_to_commit = self
            .path_from_ordered_root(block_id_to_commit)
            .unwrap_or_default();

        assert!(!blocks_to_commit.is_empty());

        let finality_proof_clone = finality_proof.clone();
        self.pending_blocks
            .lock()
            .gc(finality_proof.commit_info().round());

        self.inner.write().update_ordered_root(block_to_commit.id());
        self.inner
            .write()
            .insert_ordered_cert(finality_proof_clone.clone());
        update_counters_for_ordered_blocks(&blocks_to_commit);

        self.execution_client
            .finalize_order(blocks_to_commit, finality_proof.clone())
            .await
            .expect("Failed to persist commit");

        Ok(())
    }
```

**File:** consensus/src/block_storage/block_store.rs (L639-653)
```rust
    fn ordered_root(&self) -> Arc<PipelinedBlock> {
        self.inner.read().ordered_root()
    }

    fn commit_root(&self) -> Arc<PipelinedBlock> {
        self.inner.read().commit_root()
    }

    fn get_quorum_cert_for_block(&self, block_id: HashValue) -> Option<Arc<QuorumCert>> {
        self.inner.read().get_quorum_cert_for_block(&block_id)
    }

    fn path_from_ordered_root(&self, block_id: HashValue) -> Option<Vec<Arc<PipelinedBlock>>> {
        self.inner.read().path_from_ordered_root(block_id)
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L436-439)
```rust
    pub(super) fn update_ordered_root(&mut self, root_id: HashValue) {
        assert!(self.block_exists(&root_id));
        self.ordered_root_id = root_id;
    }
```

**File:** consensus/src/block_storage/block_tree.rs (L519-546)
```rust
    pub(super) fn path_from_root_to_block(
        &self,
        block_id: HashValue,
        root_id: HashValue,
        root_round: u64,
    ) -> Option<Vec<Arc<PipelinedBlock>>> {
        let mut res = vec![];
        let mut cur_block_id = block_id;
        loop {
            match self.get_block(&cur_block_id) {
                Some(ref block) if block.round() <= root_round => {
                    break;
                },
                Some(block) => {
                    cur_block_id = block.parent_id();
                    res.push(block);
                },
                None => return None,
            }
        }
        // At this point cur_block.round() <= self.root.round()
        if cur_block_id != root_id {
            return None;
        }
        // Called `.reverse()` to get the chronically increased order.
        res.reverse();
        Some(res)
    }
```

**File:** crates/aptos-runtimes/src/lib.rs (L40-51)
```rust
    let mut builder = Builder::new_multi_thread();
    builder
        .thread_name_fn(move || {
            let id = atomic_id.fetch_add(1, Ordering::SeqCst);
            format!("{}-{}", thread_name_clone, id)
        })
        .on_thread_start(on_thread_start)
        .disable_lifo_slot()
        // Limit concurrent blocking tasks from spawn_blocking(), in case, for example, too many
        // Rest API calls overwhelm the node.
        .max_blocking_threads(MAX_BLOCKING_THREADS)
        .enable_all();
```

**File:** consensus/src/block_storage/sync_manager.rs (L186-190)
```rust
        if self.ordered_root().round() < qc.commit_info().round() {
            SUCCESSFUL_EXECUTED_WITH_REGULAR_QC.inc();
            self.send_for_execution(qc.into_wrapped_ledger_info())
                .await?;
            if qc.ends_epoch() {
```

**File:** consensus/src/block_storage/sync_manager.rs (L210-220)
```rust
        if self.ordered_root().round() < ordered_cert.ledger_info().ledger_info().round() {
            if let Some(ordered_block) = self.get_block(ordered_cert.commit_info().id()) {
                if !ordered_block.block().is_nil_block() {
                    observe_block(
                        ordered_block.block().timestamp_usecs(),
                        BlockStage::OC_ADDED,
                    );
                }
                SUCCESSFUL_EXECUTED_WITH_ORDER_VOTE_QC.inc();
                self.send_for_execution(ordered_cert.clone()).await?;
            } else {
```
