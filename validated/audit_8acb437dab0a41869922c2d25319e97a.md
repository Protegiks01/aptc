# Audit Report

## Title
Non-Deterministic Layout Validation Causes Consensus Safety Violation in Block Execution

## Summary
The `randomly_check_layout_matches` function uses non-deterministic randomness (`rand::thread_rng()`) during block execution to probabilistically validate Move type layouts. This violates the fundamental consensus requirement that all validators must execute blocks deterministically, creating a latent vulnerability that will cause consensus splits if any layout mismatch bug is ever triggered.

## Finding Description

The vulnerability exists in the layout validation logic within the block executor's transaction output materialization path. The `randomly_check_layout_matches` function performs a critical security check with non-deterministic behavior: [1](#0-0) 

The function uses `rand::thread_rng()` to generate a random number between 0-99, and only performs the actual layout equality check when `random_number == 1` (1% probability). This randomness is evaluated independently on each validator during block execution.

The function is invoked in the consensus-critical path during transaction output materialization via the `resource_writes_to_materialize!` macro: [2](#0-1) 

This macro is used in both parallel and sequential execution paths within the block executor:

**Parallel Execution Path:** [3](#0-2) 

**Sequential Execution Path:** [4](#0-3) 

**Consensus Impact Flow:**

When a layout mismatch exists and is detected, the `PanicError` propagates through the execution stack and is converted to a VMStatus error: [5](#0-4) 

This error is then returned to the consensus layer, causing `execute_and_update_state` to fail: [6](#0-5) 

**Attack Scenario:**

1. A latent bug exists (or is triggered) that causes layout mismatches during delayed field materialization
2. When validators execute the same block:
   - **Validator A**: `random_number = 42` → check skipped → execution succeeds
   - **Validator B**: `random_number = 1` → check performed → layout mismatch detected → `PanicError` returned → block execution fails
   - **Validator C**: `random_number = 78` → check skipped → execution succeeds
3. Result: Validators disagree on whether the block executed successfully, violating consensus safety

## Impact Explanation

This is a **Critical Severity** vulnerability under Aptos bug bounty criteria:

**Consensus Safety Violation (Critical - up to $1,000,000):**
The fundamental requirement of blockchain consensus is deterministic execution. This bug violates the core invariant: "All validators must produce identical execution outcomes for identical blocks." The use of non-deterministic randomness in the consensus path means different validators can have different execution results.

**Non-Recoverable Network Partition:**
When validators disagree on block validity due to non-deterministic errors, the network can split into groups with different ledger states, requiring manual intervention or hardfork to resolve.

**Design Principle Violation:**
Even if no layout mismatch bugs currently exist, having non-deterministic code in the consensus path is categorically wrong and creates a latent vulnerability. It's equivalent to a time bomb that will detonate if any future layout bug is introduced.

## Likelihood Explanation

**Likelihood: Medium (Conditional)**

This is a **logic vulnerability** that violates consensus design principles. While it requires a pre-existing layout mismatch bug to manifest:

1. **Latent Vulnerability**: The non-deterministic code exists in production and will cause consensus splits if ANY layout mismatch bug is ever triggered (now or in the future)

2. **Probabilistic Detection with N Validators**:
   - With 100 validators: ~63% chance at least one detects a mismatch per block
   - With 200 validators: ~87% chance
   - This makes debugging harder as bugs manifest non-deterministically

3. **Exposure Surface**: Any transaction using aggregators, snapshots, or delayed field features exercises this code path

4. **No Attacker Privileges Required**: Any user can submit transactions using delayed field functionality

The likelihood is conditional on layout bugs existing, but the non-determinism itself is a consensus design violation that should not exist regardless of whether it currently causes problems.

## Recommendation

Replace the non-deterministic random sampling with one of these deterministic approaches:

**Option 1: Deterministic Sampling Based on Block/Transaction Data**
```rust
pub fn deterministically_check_layout_matches(
    layout_1: Option<&MoveTypeLayout>,
    layout_2: Option<&MoveTypeLayout>,
    block_id: &HashValue,
    txn_idx: TxnIndex,
) -> Result<(), PanicError> {
    if layout_1.is_some() != layout_2.is_some() {
        return Err(code_invariant_error(format!(
            "Layouts don't match when they are expected to: {:?} and {:?}",
            layout_1, layout_2
        )));
    }
    if layout_1.is_some() {
        // Use deterministic sampling based on block_id and txn_idx
        let hash_value = hash_deterministic(block_id, txn_idx);
        if hash_value % 100 == 1 && layout_1 != layout_2 {
            return Err(code_invariant_error(format!(
                "Layouts don't match when they are expected to: {:?} and {:?}",
                layout_1, layout_2
            )));
        }
    }
    Ok(())
}
```

**Option 2: Always Check in Debug/Testnet, Sample in Production**
Use compile-time flags to always check in test environments while sampling only in production with deterministic seeds.

**Option 3: Remove Sampling Entirely**
If performance allows, always perform the check to ensure correctness.

## Proof of Concept

The vulnerability is demonstrable through code inspection showing non-deterministic behavior in the consensus path. A full exploit PoC would require:

1. Creating a transaction that triggers a layout mismatch bug
2. Running multiple validators with the same block
3. Observing different execution outcomes due to different random values

The existence of `rand::thread_rng()` in the consensus-critical execution path is itself sufficient evidence of the design flaw, as deterministic execution is an absolute requirement for blockchain consensus.

### Citations

**File:** aptos-move/aptos-vm-types/src/change_set.rs (L48-74)
```rust
/// Sporadically checks if the given two input type layouts match.
pub fn randomly_check_layout_matches(
    layout_1: Option<&MoveTypeLayout>,
    layout_2: Option<&MoveTypeLayout>,
) -> Result<(), PanicError> {
    if layout_1.is_some() != layout_2.is_some() {
        return Err(code_invariant_error(format!(
            "Layouts don't match when they are expected to: {:?} and {:?}",
            layout_1, layout_2
        )));
    }
    if layout_1.is_some() {
        // Checking if 2 layouts are equal is a recursive operation and is expensive.
        // We generally call this `randomly_check_layout_matches` function when we know
        // that the layouts are supposed to match. As an optimization, we only randomly
        // check if the layouts are matching.
        let mut rng = rand::thread_rng();
        let random_number: u32 = rng.gen_range(0, 100);
        if random_number == 1 && layout_1 != layout_2 {
            return Err(code_invariant_error(format!(
                "Layouts don't match when they are expected to: {:?} and {:?}",
                layout_1, layout_2
            )));
        }
    }
    Ok(())
}
```

**File:** aptos-move/block-executor/src/executor_utilities.rs (L57-80)
```rust
macro_rules! resource_writes_to_materialize {
    ($writes:expr, $outputs:expr, $data_source:expr, $($txn_idx:expr),*) => {{
	$outputs
        .reads_needing_delayed_field_exchange($($txn_idx),*)
        .into_iter()
	    .map(|(key, metadata, layout)| -> Result<_, PanicError> {
	        let (value, existing_layout) = $data_source.fetch_exchanged_data(&key, $($txn_idx),*)?;
            randomly_check_layout_matches(Some(&existing_layout), Some(layout.as_ref()))?;
            let new_value = TriompheArc::new(TransactionWrite::from_state_value(Some(
                StateValue::new_with_metadata(
                    value.bytes().cloned().unwrap_or_else(Bytes::new),
                    metadata,
                ))
            ));
            Ok((key, new_value, layout))
        })
        .chain(
	        $writes.into_iter().filter_map(|(key, (value, maybe_layout))| {
		        maybe_layout.map(|layout| {
                    (!value.is_deletion()).then_some(Ok((key, value, layout)))
                }).flatten()
            })
        )
        .collect::<Result<Vec<_>, _>>()
```

**File:** aptos-move/block-executor/src/executor.rs (L1131-1208)
```rust
    fn materialize_txn_commit(
        &self,
        txn_idx: TxnIndex,
        scheduler: SchedulerWrapper,
        environment: &AptosEnvironment,
        shared_sync_params: &SharedSyncParams<T, E, S>,
    ) -> Result<(), PanicError> {
        let last_input_output = shared_sync_params.last_input_output;

        // Do a final validation for safety as a part of (parallel) post-processing.
        // Delayed fields are already validated in the sequential commit hook.
        if !Self::validate(
            txn_idx,
            last_input_output,
            shared_sync_params.global_module_cache,
            shared_sync_params.versioned_cache,
            // Module cache is not versioned (published at commit), so validation after
            // commit might observe later publishes (higher txn index) and be incorrect.
            // Hence, we skip the paranoid module validation after commit.
            // TODO(BlockSTMv2): Do the additional checking in sequential commit hook,
            // when modules have been published. Update the comment here as skipping
            // in V2 is needed for a different, code cache implementation related reason.
            true,
        ) {
            return Err(code_invariant_error(format!(
                "Final Validation in post-processing failed for txn {}",
                txn_idx
            )));
        }

        let parallel_state = ParallelState::<T>::new(
            shared_sync_params.versioned_cache,
            scheduler,
            shared_sync_params.start_shared_counter,
            shared_sync_params.delayed_field_id_counter,
            0,
            // Incarnation does not matter here (no re-execution & interrupts)
            // TODO(BlockSTMv2): we could still provide the latest incarnation.
        );
        let latest_view = LatestView::new(
            shared_sync_params.base_view,
            shared_sync_params.global_module_cache,
            environment.runtime_environment(),
            ViewState::Sync(parallel_state),
            txn_idx,
        );

        let finalized_groups = groups_to_finalize!(last_input_output, txn_idx)
            .map(|((group_key, metadata_op), is_read_needing_exchange)| {
                let (finalized_group, group_size) = shared_sync_params
                    .versioned_cache
                    .group_data()
                    .finalize_group(&group_key, txn_idx)?;

                map_finalized_group::<T>(
                    group_key,
                    finalized_group,
                    group_size,
                    metadata_op,
                    is_read_needing_exchange,
                )
            })
            .collect::<Result<Vec<_>, _>>()?;
        let materialized_finalized_groups =
            map_id_to_values_in_group_writes(finalized_groups, &latest_view)?;

        let serialized_groups =
            serialize_groups::<T>(materialized_finalized_groups).map_err(|e| {
                code_invariant_error(format!("Panic error in serializing groups {e:?}"))
            })?;

        let resource_write_set = last_input_output.resource_write_set(txn_idx)?;
        let resource_writes_to_materialize = resource_writes_to_materialize!(
            resource_write_set,
            last_input_output,
            last_input_output,
            txn_idx
        )?;
```

**File:** aptos-move/block-executor/src/executor.rs (L2444-2460)
```rust
                        let resource_writes_to_materialize = resource_writes_to_materialize!(
                            resource_write_set,
                            output_before_guard,
                            unsync_map,
                        )?;
                        // Replace delayed field id with values in resource write set and read set.
                        let materialized_resource_write_set = map_id_to_values_in_write_set(
                            resource_writes_to_materialize,
                            &latest_view,
                        )?;

                        // Replace delayed field id with values in events
                        let materialized_events = map_id_to_values_events(
                            Box::new(output_before_guard.get_events().into_iter()),
                            &latest_view,
                        )?;
                        // Output before guard holds a read lock, drop before incorporating materialized
```

**File:** aptos-move/aptos-vm/src/block_executor/mod.rs (L577-583)
```rust
            Err(BlockExecutionError::FatalBlockExecutorError(PanicError::CodeInvariantError(
                err_msg,
            ))) => Err(VMStatus::Error {
                status_code: StatusCode::DELAYED_FIELD_OR_BLOCKSTM_CODE_INVARIANT_ERROR,
                sub_status: None,
                message: Some(err_msg),
            }),
```

**File:** consensus/src/pipeline/pipeline_builder.rs (L856-868)
```rust
        let start = Instant::now();
        tokio::task::spawn_blocking(move || {
            executor
                .execute_and_update_state(
                    (block.id(), txns, auxiliary_info).into(),
                    block.parent_id(),
                    onchain_execution_config,
                )
                .map_err(anyhow::Error::from)
        })
        .await
        .expect("spawn blocking failed")?;
        Ok(start.elapsed())
```
