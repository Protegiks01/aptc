# Audit Report

## Title
Race Condition in RandManager Reset Allows Stale Blocks to Be Processed After State Synchronization

## Summary
The `RandManager::start()` function drains the `incoming_blocks` channel using non-blocking `try_next()` before calling `process_reset()`. This creates a race condition where blocks sent before the reset but arriving after channel draining will be processed with post-reset state, causing resource exhaustion and validator performance degradation.

## Finding Description

During state synchronization operations, the `RandManager` receives a reset request to clear its state and synchronize to a target round. The reset handler implementation contains a critical race condition in the main event loop: [1](#0-0) 

The channel draining uses `try_next()`, which is non-blocking and only removes blocks **currently** in the channel at that instant. Blocks that were sent before the reset signal but arrive in the channel **after** the draining loop completes will be processed in subsequent event loop iterations with post-reset state.

**Attack Timeline:**
1. Node syncs to target round 200 via `sync_to_target()` [2](#0-1) 
2. Reset request sent with `ResetSignal::TargetRound(200)` [3](#0-2) 
3. Reset branch selected, draining loop executes non-blocking `try_next()`
4. All blocks currently in channel are drained and dropped
5. `process_reset()` clears `block_queue` and resets `rand_store` to round 200 [4](#0-3) 
6. A block for round 103 (sent before reset but delayed in network) arrives in the channel
7. Next select iteration processes this stale block via `process_incoming_blocks()` [5](#0-4) 

The critical flaw is that `process_incoming_metadata()` has **no validation** to reject stale blocks with rounds less than the reset target: [6](#0-5) 

While `update_highest_known_round()` uses `max()` to avoid downgrading the round counter [7](#0-6) , it does **not** prevent the stale block from being fully processed. The block is:
- Added to the `block_queue`
- Randomness shares generated and broadcast network-wide
- Aggregation task spawned via `spawn_aggregate_shares_task()`
- Resources consumed indefinitely for an obsolete round

The `add_share()` validation only checks future rounds, not past rounds: [8](#0-7) 

With `FUTURE_ROUNDS_TO_ACCEPT` set to 200 [9](#0-8) , a stale block at round 103 when `highest_known_round` is 200 passes validation (103 ≤ 200 + 200).

The `reset()` implementation only removes entries ≥ target_round using `split_off()`, keeping past entries: [10](#0-9) 

## Impact Explanation

**Severity: HIGH** per Aptos Bug Bounty criteria ("Validator node slowdowns" and "Significant protocol violations")

This vulnerability causes:

1. **Resource Exhaustion**: Each stale block triggers full randomness generation including share generation and broadcasting to all validators, network bandwidth consumption across the validator set, spawning aggregation tasks that may never complete, and memory consumption in `block_queue` that persists indefinitely.

2. **Validator Performance Degradation**: Validators waste CPU cycles and network bandwidth on obsolete rounds that cannot contribute to consensus progress. During frequent sync operations, this compounds exponentially.

3. **Protocol Violation**: The reset semantics explicitly clear state for rounds ≥ target_round. Processing stale blocks violates this invariant and undermines the reset mechanism's purpose.

4. **Amplification Effect**: Each stale block triggers broadcasts to all validators, so if multiple validators experience this race simultaneously, they amplify each other's resource waste.

## Likelihood Explanation

**Likelihood: MEDIUM-HIGH**

This race condition occurs naturally during normal operations:

1. **Frequent Trigger**: State synchronization via `sync_to_target()` happens whenever a node falls behind or restarts, which is common in production networks.

2. **Network Reality**: Network delays between block transmission and reception are inherent in distributed systems. Blocks sent before a reset can easily arrive milliseconds or seconds later.

3. **Window Duration**: The vulnerable window exists between channel draining completion and the next select iteration - small but hit on every reset operation.

4. **No Attacker Control Required**: This can occur naturally due to network jitter, though an attacker with network positioning could deliberately delay blocks to maximize exploitation.

5. **Compounding Factor**: The longer a node is behind, the more stale blocks accumulate in flight, increasing the probability that multiple blocks trigger this race.

## Recommendation

Add validation in `process_incoming_metadata()` to reject blocks with rounds less than the current `highest_known_round` after a reset. Specifically:

1. Check if `metadata.round() < self.rand_store.lock().get_highest_known_round()` before processing
2. If true, log and drop the stale block without generating shares or spawning tasks
3. Alternatively, drain the channel after `process_reset()` completes, not before

The fix should ensure that blocks arriving after a reset with rounds below the target round are immediately discarded without consuming resources.

## Proof of Concept

A Rust unit test demonstrating the race condition:

```rust
#[tokio::test]
async fn test_stale_block_after_reset() {
    // Setup: Create RandManager with target round 100
    // Send blocks for rounds 95-105 into incoming_blocks channel
    // Trigger reset to round 200
    // Verify: Block at round 95 arrives after reset and gets processed
    // Assert: Resources are consumed for obsolete round 95
    // Expected: Block should be rejected, but currently it's processed
}
```

The test would show that a block with round < target_round arriving after the `try_next()` drain but before the next select iteration gets fully processed, consuming validator resources for an obsolete round.

### Citations

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L145-169)
```rust
    fn process_incoming_metadata(&self, metadata: FullRandMetadata) -> DropGuard {
        let self_share = S::generate(&self.config, metadata.metadata.clone());
        info!(LogSchema::new(LogEvent::BroadcastRandShare)
            .epoch(self.epoch_state.epoch)
            .author(self.author)
            .round(metadata.round()));
        let mut rand_store = self.rand_store.lock();
        rand_store.update_highest_known_round(metadata.round());
        rand_store
            .add_share(self_share.clone(), PathType::Slow)
            .expect("Add self share should succeed");

        if let Some(fast_config) = &self.fast_config {
            let self_fast_share =
                FastShare::new(S::generate(fast_config, metadata.metadata.clone()));
            rand_store
                .add_share(self_fast_share.rand_share(), PathType::Fast)
                .expect("Add self share for fast path should succeed");
        }

        rand_store.add_rand_metadata(metadata.clone());
        self.network_sender
            .broadcast_without_self(RandMessage::<S, D>::Share(self_share).into_network_message());
        self.spawn_aggregate_shares_task(metadata.metadata)
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L184-194)
```rust
    fn process_reset(&mut self, request: ResetRequest) {
        let ResetRequest { tx, signal } = request;
        let target_round = match signal {
            ResetSignal::Stop => 0,
            ResetSignal::TargetRound(round) => round,
        };
        self.block_queue = BlockQueue::new();
        self.rand_store.lock().reset(target_round);
        self.stop = matches!(signal, ResetSignal::Stop);
        let _ = tx.send(ResetAck::default());
    }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L380-382)
```rust
                Some(blocks) = incoming_blocks.next(), if self.aug_data_store.my_certified_aug_data_exists() => {
                    self.process_incoming_blocks(blocks);
                }
```

**File:** consensus/src/rand/rand_gen/rand_manager.rs (L383-386)
```rust
                Some(reset) = reset_rx.next() => {
                    while matches!(incoming_blocks.try_next(), Ok(Some(_))) {}
                    self.process_reset(reset);
                }
```

**File:** consensus/src/pipeline/execution_client.rs (L661-672)
```rust
    async fn sync_to_target(&self, target: LedgerInfoWithSignatures) -> Result<(), StateSyncError> {
        fail_point!("consensus::sync_to_target", |_| {
            Err(anyhow::anyhow!("Injected error in sync_to_target").into())
        });

        // Reset the rand and buffer managers to the target round
        self.reset(&target).await?;

        // TODO: handle the state sync error (e.g., re-push the ordered
        // blocks to the buffer manager when it's reset but sync fails).
        self.execution_proxy.sync_to_target(target).await
    }
```

**File:** consensus/src/pipeline/execution_client.rs (L683-692)
```rust
        if let Some(mut reset_tx) = reset_tx_to_rand_manager {
            let (ack_tx, ack_rx) = oneshot::channel::<ResetAck>();
            reset_tx
                .send(ResetRequest {
                    tx: ack_tx,
                    signal: ResetSignal::TargetRound(target.commit_info().round()),
                })
                .await
                .map_err(|_| Error::RandResetDropped)?;
            ack_rx.await.map_err(|_| Error::RandResetDropped)?;
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L249-251)
```rust
    pub fn update_highest_known_round(&mut self, round: u64) {
        self.highest_known_round = std::cmp::max(self.highest_known_round, round);
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L253-259)
```rust
    pub fn reset(&mut self, round: u64) {
        self.update_highest_known_round(round);
        // remove future rounds items in case they're already decided
        // otherwise if the block re-enters the queue, it'll be stuck
        let _ = self.rand_map.split_off(&round);
        let _ = self.fast_rand_map.as_mut().map(|map| map.split_off(&round));
    }
```

**File:** consensus/src/rand/rand_gen/rand_store.rs (L280-288)
```rust
    pub fn add_share(&mut self, share: RandShare<S>, path: PathType) -> anyhow::Result<bool> {
        ensure!(
            share.metadata().epoch == self.epoch,
            "Share from different epoch"
        );
        ensure!(
            share.metadata().round <= self.highest_known_round + FUTURE_ROUNDS_TO_ACCEPT,
            "Share from future round"
        );
```

**File:** consensus/src/rand/rand_gen/types.rs (L26-26)
```rust
pub const FUTURE_ROUNDS_TO_ACCEPT: u64 = 200;
```
