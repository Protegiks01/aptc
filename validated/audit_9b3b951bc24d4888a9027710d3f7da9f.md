# Audit Report

## Title
Player ID Spoofing in Weighted Decryption Key Shares Causes Consensus Liveness Failure

## Summary
A critical authentication bypass exists in the weighted batch encryption scheme used by Aptos consensus for encrypted transaction decryption. The Player ID field in `WeightedBIBEDecryptionKeyShare` is not verified during share validation, allowing a malicious validator to forge Player IDs. This causes incorrect Lagrange interpolation during reconstruction, producing an invalid decryption key and preventing the network from decrypting transactions, resulting in total consensus liveness failure.

## Finding Description

The vulnerability exists due to a disconnect between what is cryptographically verified during share validation and what is trusted during secret reconstruction.

**Verification Phase (No Player ID Check):**

The verification function ignores the Player ID from the decryption key share tuple and only uses the verification key's own Player ID. In `WeightedBIBEVerificationKey::verify_decryption_key_share()`, the verification creates a new tuple with `self.weighted_player` instead of using the Player ID from the share (`dk_share.0`), effectively ignoring any Player ID in the incoming share. [1](#0-0) 

The comment on line 163 explicitly marks the player field as "arbitrary", confirming it is not used for verification purposes. [2](#0-1) 

**Type Definition (Unprotected Tuple):**

The `WeightedBIBEDecryptionKeyShare` is defined as a simple tuple `(Player, Vec<BIBEDecryptionKeyShareValue>)` where the Player ID can be arbitrarily modified. [3](#0-2) 

**Consensus Integration (Trusted Without Validation):**

When validators receive shares from peers, the `SecretShare::verify()` method uses the `author` field to select the verification key but never validates that the Player ID inside the `share` field matches the author. [4](#0-3) 

The verification key is selected based on the author's index, not the Player ID in the share tuple. [5](#0-4) 

**Reconstruction Phase (Trusts Forged Player ID):**

During reconstruction, the algorithm extracts the Player ID directly from the share tuple and uses it to compute virtual player mappings. The `Reconstructable` implementation for weighted configs iterates over shares and extracts the player from each tuple. [6](#0-5) 

The forged Player ID is used to call `get_virtual_player(player, pos)`, which maps it to virtual players based on the weighted configuration. [7](#0-6) 

**Lagrange Coefficient Computation (Uses Wrong Indices):**

The underlying Shamir reconstruction extracts Player IDs via `p.get_id()` and uses them as indices for Lagrange coefficient computation. These indices are then used to compute Lagrange coefficients from the evaluation domain. [8](#0-7) 

**Liveness Impact:**

When reconstruction fails due to incorrect Player IDs, the error is logged but no decryption key is sent through the decision channel. [9](#0-8) 

The decryption pipeline blocks indefinitely waiting for the secret shared key that never arrives. [10](#0-9) 

**Attack Scenario:**

1. Malicious Validator A derives a legitimate decryption key share for a digest
2. Before broadcasting, Validator A modifies the share tuple from `(PlayerA, [signatures])` to `(PlayerB, [signatures])` where PlayerB is a different validator's Player ID
3. Other validators receive this share in a `SecretShare` message with `author = ValidatorA`
4. Verification succeeds because it uses ValidatorA's verification key (selected by `author` field) and only checks the cryptographic signatures, ignoring the Player ID
5. During reconstruction, the forged PlayerB ID is used to compute virtual players and Lagrange coefficients
6. Wrong coefficients are multiplied with share values, producing an invalid decryption key
7. Reconstruction fails and no decryption key is sent through the pipeline
8. All validators block indefinitely waiting for the decryption key
9. Consensus cannot progress - **total network liveness failure**

## Impact Explanation

This vulnerability qualifies as **Critical Severity** under Aptos bug bounty criteria for "Total Loss of Liveness/Network Availability". 

A single Byzantine validator (within the standard < 1/3 Byzantine fault tolerance model) can prevent the entire network from decrypting encrypted transactions by providing shares with forged Player IDs. Since the consensus pipeline waits indefinitely for successful decryption of encrypted transactions, this causes complete consensus stall with no automatic recovery mechanism.

The vulnerability breaks the fundamental cryptographic assumption that Shamir secret sharing reconstruction uses authenticated share indices. The mismatch between the verified identity (via `author` field) and the reconstructed identity (via Player ID in share tuple) allows an attacker to cause reconstruction failure while bypassing all validation checks.

## Likelihood Explanation

**Likelihood: High**

- **Attacker Requirements**: Only requires one malicious validator within the Byzantine threshold (< 1/3 of stake), which is the standard threat model for BFT systems
- **Complexity**: Trivial - simply modify the Player ID field in a tuple before broadcasting the share
- **Detection Difficulty**: The attack produces cryptographically valid shares that pass all verification checks; only detected when reconstruction fails, at which point consensus has already stalled
- **Impact Scope**: A single attacker can cause total network liveness failure affecting all validators and users

## Recommendation

Add explicit validation that the Player ID in the decryption key share matches the expected player for the verification key:

1. In `WeightedBIBEVerificationKey::verify_decryption_key_share()`, add a check before verification:
   ```rust
   ensure!(
       dk_share.0 == self.weighted_player,
       "Player ID in share does not match verification key"
   );
   ```

2. In `SecretShare::verify()`, add validation after getting the verification key:
   ```rust
   ensure!(
       self.share().player() == config.verification_keys[index].player(),
       "Player ID in share does not match author's player ID"
   );
   ```

3. Consider making `WeightedBIBEDecryptionKeyShare` an opaque struct rather than a tuple to prevent arbitrary field modification.

## Proof of Concept

The vulnerability can be demonstrated by:

1. Having a validator derive a legitimate share using `derive_decryption_key_share()`
2. Modifying the Player ID in the resulting tuple before broadcasting
3. Observing that the share passes verification at receiving validators
4. Observing that reconstruction fails when threshold shares are collected
5. Observing that the consensus pipeline blocks indefinitely waiting for the decryption key

A concrete implementation would require access to a test network with multiple validators and the ability to modify the share broadcasting logic to forge Player IDs.

## Notes

This vulnerability is particularly severe because:
- It exploits a subtle disconnect between two separate code paths (verification vs reconstruction)
- The attack is undetectable until reconstruction fails
- There is no automatic recovery mechanism - the network remains stalled
- It only requires a single Byzantine validator, well within the BFT threat model
- The fix is straightforward: add Player ID validation during share verification

### Citations

**File:** crates/aptos-batch-encryption/src/schemes/fptx_weighted.rs (L38-44)
```rust
pub type WeightedBIBEDecryptionKeyShare = (Player, Vec<BIBEDecryptionKeyShareValue>);

impl DecryptionKeyShare for WeightedBIBEDecryptionKeyShare {
    fn player(&self) -> Player {
        self.0
    }
}
```

**File:** crates/aptos-batch-encryption/src/schemes/fptx_weighted.rs (L149-169)
```rust
    pub fn verify_decryption_key_share(
        &self,
        digest: &Digest,
        dk_share: &WeightedBIBEDecryptionKeyShare,
    ) -> Result<()> {
        (self.vks_g2.len() == dk_share.1.len())
            .then_some(())
            .ok_or(BatchEncryptionError::DecryptionKeyVerifyError)?;

        self.vks_g2
            .iter()
            .map(|vk_g2| BIBEVerificationKey {
                mpk_g2: self.mpk_g2,
                vk_g2: *vk_g2,
                player: self.weighted_player, // arbitrary
            })
            .zip(&dk_share.1)
            .try_for_each(|(vk, dk_share)| {
                vk.verify_decryption_key_share(digest, &(self.weighted_player, dk_share.clone()))
            })
    }
```

**File:** types/src/secret_sharing.rs (L75-82)
```rust
    pub fn verify(&self, config: &SecretShareConfig) -> anyhow::Result<()> {
        let index = config.get_id(self.author());
        let decryption_key_share = self.share().clone();
        // TODO(ibalajiarun): Check index out of bounds
        config.verification_keys[index]
            .verify_decryption_key_share(&self.metadata.digest, &decryption_key_share)?;
        Ok(())
    }
```

**File:** crates/aptos-crypto/src/weighted_config.rs (L423-450)
```rust
    fn reconstruct(
        sc: &WeightedConfigArkworks<F>,
        shares: &[ShamirShare<Self::ShareValue>],
    ) -> anyhow::Result<Self> {
        let mut flattened_shares = Vec::with_capacity(sc.get_total_weight());

        // println!();
        for (player, sub_shares) in shares {
            // println!(
            //     "Flattening {} share(s) for player {player}",
            //     sub_shares.len()
            // );
            for (pos, share) in sub_shares.iter().enumerate() {
                let virtual_player = sc.get_virtual_player(player, pos);

                // println!(
                //     " + Adding share {pos} as virtual player {virtual_player}: {:?}",
                //     share
                // );
                // TODO(Performance): Avoiding the cloning here might be nice
                let tuple = (virtual_player, share.clone());
                flattened_shares.push(tuple);
            }
        }
        flattened_shares.truncate(sc.get_threshold_weight());

        SK::reconstruct(sc.get_threshold_config(), &flattened_shares)
    }
```

**File:** crates/aptos-crypto/src/arkworks/shamir.rs (L320-329)
```rust
            let (roots_of_unity_indices, bases): (Vec<usize>, Vec<Self::ShareValue>) = shares
                [..sc.t]
                .iter()
                .map(|(p, g_y)| (p.get_id(), g_y))
                .collect();

            let lagrange_coeffs = sc.lagrange_for_subset(&roots_of_unity_indices);

            Ok(T::weighted_sum(&bases, &lagrange_coeffs))
        }
```

**File:** consensus/src/rand/secret_sharing/secret_share_store.rs (L56-69)
```rust
            let maybe_key = SecretShare::aggregate(self.shares.values(), &dec_config);
            match maybe_key {
                Ok(key) => {
                    let dec_key = SecretSharedKey::new(metadata, key);
                    let _ = decision_tx.unbounded_send(dec_key);
                },
                Err(e) => {
                    warn!(
                        epoch = metadata.epoch,
                        round = metadata.round,
                        "Aggregation error: {e}"
                    );
                },
            }
```

**File:** consensus/src/pipeline/decryption_pipeline_builder.rs (L115-119)
```rust
        let maybe_decryption_key = secret_shared_key_rx
            .await
            .expect("decryption key should be available");
        // TODO(ibalajiarun): account for the case where decryption key is not available
        let decryption_key = maybe_decryption_key.expect("decryption key should be available");
```
