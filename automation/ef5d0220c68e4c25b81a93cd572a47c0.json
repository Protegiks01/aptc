[
  {
    "question": "[File: config/src/config/mempool_config.rs] [Struct: MempoolConfig] Can system_transaction_timeout_secs=600 be too short for complex governance proposals, causing them to expire before execution? (High)",
    "url": "https://deepwiki.com/search/-you-are-an-elite-aptos-blockc_ee301da8-e38f-4a40-ab89-4506b9663dd0?mode=deep",
    "timestamp": "2026-01-26 22:38:08.446588",
    "report_generated": false
  },
  {
    "question": "[File: config/src/config/mempool_config.rs] [Struct: MempoolConfig] Can capacity_per_user limit prevent legitimate high-volume users (like exchanges) from operating normally? (Medium)",
    "url": "https://deepwiki.com/search/-you-are-an-elite-aptos-blockc_78c2f6eb-7dc6-4ef4-8839-480212675709?mode=deep",
    "timestamp": "2026-01-26 22:38:21.274325",
    "report_generated": false
  },
  {
    "question": "[File: config/src/config/mempool_config.rs] [Struct: MempoolConfig] Can usecase_stats_num_blocks_to_track and usecase_stats_num_top_to_track be manipulated to hide attack patterns in statistics? (Low)",
    "url": "https://deepwiki.com/search/-you-are-an-elite-aptos-blockc_6b4fecf5-8f76-4a10-a18a-8e0d686e1957?mode=deep",
    "timestamp": "2026-01-26 22:38:35.041282",
    "report_generated": false
  },
  {
    "question": "[File: config/src/config/mempool_config.rs] [Struct: MempoolConfig] Can mempool_snapshot_interval_secs be set very low to generate so many log entries that legitimate security events are buried? (Low)",
    "url": "https://deepwiki.com/search/-you-are-an-elite-aptos-blockc_94010fc0-7202-452e-87b7-840eed741d14?mode=deep",
    "timestamp": "2026-01-26 22:38:49.787588",
    "report_generated": false
  },
  {
    "question": "[File: config/src/config/mempool_config.rs] [Function: optimize()] Does reducing max_broadcasts_per_peer to 2 for validators (line 202) make them more vulnerable to censorship by a small number of peers? (High)",
    "url": "https://deepwiki.com/search/-you-are-an-elite-aptos-blockc_79ac68b9-9d0b-4b60-a0ab-d7a546738d64?mode=deep",
    "timestamp": "2026-01-26 22:39:04.453839",
    "report_generated": false
  },
  {
    "question": "[File: config/src/config/mempool_config.rs] [Function: optimize()] Does setting default_failovers=0 for VFNs (line 225) eliminate their resilience to primary peer failures? (High)",
    "url": "https://deepwiki.com/search/-you-are-an-elite-aptos-blockc_752fb9d4-934a-470d-9b48-4445c7ca7b5c?mode=deep",
    "timestamp": "2026-01-26 22:39:20.556637",
    "report_generated": false
  },
  {
    "question": "[File: config/src/config/mempool_config.rs] [Function: optimize()] Does setting num_sender_buckets=1 for both validators and VFNs eliminate parallelism benefits that could improve performance? (Medium)",
    "url": "https://deepwiki.com/search/-you-are-an-elite-aptos-blockc_70195116-7d27-4423-ab58-fbd3094a3a0e?mode=deep",
    "timestamp": "2026-01-26 22:39:37.748457",
    "report_generated": false
  },
  {
    "question": "[File: config/src/config/mempool_config.rs] [Struct: MempoolConfig] Can setting\n\n### Citations\n\n**File:** config/src/config/mempool_config.rs (L1-355)\n```rust\n// Copyright © Aptos Foundation\n// Parts of the project are originally copyright © Meta Platforms, Inc.\n// SPDX-License-Identifier: Apache-2.0\n\nuse crate::config::{\n    config_optimizer::ConfigOptimizer, config_sanitizer::ConfigSanitizer,\n    node_config_loader::NodeType, Error, NodeConfig, MAX_APPLICATION_MESSAGE_SIZE,\n};\nuse aptos_global_constants::DEFAULT_BUCKETS;\nuse aptos_types::chain_id::ChainId;\nuse serde::{Deserialize, Serialize};\nuse serde_yaml::Value;\n\n#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]\n#[serde(default, deny_unknown_fields)]\npub struct LoadBalancingThresholdConfig {\n    /// PFN load balances the traffic to multiple upstream FNs. The PFN calculates the average mempool traffic in TPS received since\n    /// the last peer udpate. If the average received mempool traffic is greater than this threshold, then the below limits are used\n    /// to decide the number of upstream peers to forward the mempool traffic.\n    pub avg_mempool_traffic_threshold_in_tps: u64,\n    /// Suppose the smallest ping latency amongst the connected upstream peers is `x`. If the average received mempool traffic is\n    /// greater than `avg_mempool_traffic_threshold_in_tps`, then the PFN will forward mempool traffic to only those upstream peers\n    /// with ping latency less than `x + latency_slack_between_top_upstream_peers`.\n    pub latency_slack_between_top_upstream_peers: u64,\n    /// If the average received mempool traffic is greater than avg_mempool_traffic_threshold_in_tps, then PFNs will forward to at most\n    /// `max_number_of_upstream_peers` upstream FNs.\n    pub max_number_of_upstream_peers: u8,\n}\n\nimpl Default for LoadBalancingThresholdConfig {\n    fn default() -> LoadBalancingThresholdConfig {\n        LoadBalancingThresholdConfig {\n            avg_mempool_traffic_threshold_in_tps: 0,\n            latency_slack_between_top_upstream_peers: 50,\n            max_number_of_upstream_peers: 1,\n        }\n    }\n}\n\n#[derive(Clone, Debug, Deserialize, PartialEq, Eq, Serialize)]\n#[serde(default, deny_unknown_fields)]\npub struct MempoolConfig {\n    /// Maximum number of transactions allowed in the Mempool\n    pub capacity: usize,\n    /// Maximum number of bytes allowed in the Mempool\n    pub capacity_bytes: usize,\n    /// Maximum number of sequence number based transactions allowed in the Mempool per user\n    pub capacity_per_user: usize,\n    /// Number of failover peers to broadcast to when the primary network is alive\n    pub default_failovers: usize,\n    /// Whether or not to enable intelligent peer prioritization\n    pub enable_intelligent_peer_prioritization: bool,\n    /// The maximum number of broadcasts sent to a single peer that are pending a response ACK at any point.\n    pub max_broadcasts_per_peer: usize,\n    /// Maximum number of inbound network messages to the Mempool application\n    pub max_network_channel_size: usize,\n    /// The maximum amount of time a node can be out of sync before being considered unhealthy\n    pub max_sync_lag_before_unhealthy_secs: usize,\n    /// The interval to take a snapshot of the mempool to logs, only used when trace logging is enabled\n    pub mempool_snapshot_interval_secs: u64,\n    /// The maximum amount of time to wait for an ACK of Mempool submission to an upstream node.\n    pub shared_mempool_ack_timeout_ms: u64,\n    /// The amount of time to backoff between retries of Mempool submission to an upstream node.\n    pub shared_mempool_backoff_interval_ms: u64,\n    /// Maximum number of transactions to batch for a Mempool submission to an upstream node.\n    pub shared_mempool_batch_size: usize,\n    /// Maximum number of bytes to batch for a Mempool submission to an upstream node.\n    pub shared_mempool_max_batch_bytes: u64,\n    /// Maximum Mempool inbound message workers.  Controls concurrency of Mempool consumption.\n    pub shared_mempool_max_concurrent_inbound_syncs: usize,\n    /// Interval to broadcast to upstream nodes.\n    pub shared_mempool_tick_interval_ms: u64,\n    /// Interval to update peers in shared mempool.\n    pub shared_mempool_peer_update_interval_ms: u64,\n    /// Interval to update peer priorities in shared mempool (seconds).\n    pub shared_mempool_priority_update_interval_secs: u64,\n    /// The amount of time to wait after transaction insertion to broadcast to a failover peer.\n    pub shared_mempool_failover_delay_ms: u64,\n    /// Number of seconds until the transaction will be removed from the Mempool ignoring if the transaction has expired.\n    ///\n    /// This ensures that the Mempool isn't just full of non-expiring transactions that are way off into the future.\n    pub system_transaction_timeout_secs: u64,\n    /// Interval to garbage collect and remove transactions that have expired from the Mempool.\n    pub system_transaction_gc_interval_ms: u64,\n    /// Gas unit price buckets for broadcasting to upstream nodes.\n    ///\n    /// Overriding this won't make much of a difference if the upstream nodes don't match.\n    pub broadcast_buckets: Vec<u64>,\n    pub eager_expire_threshold_ms: Option<u64>,\n    pub eager_expire_time_ms: u64,\n    /// Uses the BroadcastTransactionsRequestWithReadyTime instead of BroadcastTransactionsRequest when sending\n    /// mempool transactions to upstream nodes.\n    pub include_ready_time_in_broadcast: bool,\n    pub usecase_stats_num_blocks_to_track: usize,\n    pub usecase_stats_num_top_to_track: usize,\n    /// We divide the transactions into buckets based on hash of the sender address.\n    /// This is the number of sender buckets we use.\n    pub num_sender_buckets: u8,\n    /// Load balancing configuration for the mempool. This is used only by PFNs.\n    pub load_balancing_thresholds: Vec<LoadBalancingThresholdConfig>,\n    /// When the load is low, PFNs send all the mempool traffic to only one upstream FN. When the load increases suddenly, PFNs will take\n    /// up to 10 minutes (shared_mempool_priority_update_interval_secs) to enable the load balancing. If this flag is enabled,\n    /// then the PFNs will always do load balancing irrespective of the load.\n    pub enable_max_load_balancing_at_any_load: bool,\n    /// Maximum number of orderless transactions allowed in the Mempool per user\n    pub orderless_txn_capacity_per_user: usize,\n}\n\nimpl Default for MempoolConfig {\n    fn default() -> MempoolConfig {\n        MempoolConfig {\n            shared_mempool_tick_interval_ms: 10,\n            shared_mempool_backoff_interval_ms: 30_000,\n            shared_mempool_batch_size: 300,\n            shared_mempool_max_batch_bytes: MAX_APPLICATION_MESSAGE_SIZE as u64,\n            shared_mempool_ack_timeout_ms: 2_000,\n            shared_mempool_max_concurrent_inbound_syncs: 4,\n            max_broadcasts_per_peer: 20,\n            max_sync_lag_before_unhealthy_secs: 30, // 30 seconds\n            max_network_channel_size: 1024,\n            mempool_snapshot_interval_secs: 180,\n            capacity: 2_000_000,\n            capacity_bytes: 2 * 1024 * 1024 * 1024,\n            capacity_per_user: 100,\n            default_failovers: 1,\n            enable_intelligent_peer_prioritization: true,\n            shared_mempool_peer_update_interval_ms: 1_000,\n            shared_mempool_priority_update_interval_secs: 600, // 10 minutes (frequent reprioritization is expensive)\n            shared_mempool_failover_delay_ms: 500,\n            system_transaction_timeout_secs: 600,\n            system_transaction_gc_interval_ms: 60_000,\n            broadcast_buckets: DEFAULT_BUCKETS.to_vec(),\n            eager_expire_threshold_ms: Some(15_000),\n            eager_expire_time_ms: 6_000,\n            include_ready_time_in_broadcast: false,\n            usecase_stats_num_blocks_to_track: 40,\n            usecase_stats_num_top_to_track: 5,\n            num_sender_buckets: 4,\n            load_balancing_thresholds: vec![\n                LoadBalancingThresholdConfig {\n                    avg_mempool_traffic_threshold_in_tps: 500,\n                    latency_slack_between_top_upstream_peers: 50,\n                    max_number_of_upstream_peers: 2,\n                },\n                LoadBalancingThresholdConfig {\n                    avg_mempool_traffic_threshold_in_tps: 1000,\n                    latency_slack_between_top_upstream_peers: 50,\n                    max_number_of_upstream_peers: 3,\n                },\n                LoadBalancingThresholdConfig {\n                    avg_mempool_traffic_threshold_in_tps: 1500,\n                    latency_slack_between_top_upstream_peers: 75,\n                    max_number_of_upstream_peers: 4,\n                },\n                LoadBalancingThresholdConfig {\n                    avg_mempool_traffic_threshold_in_tps: 2500,\n                    latency_slack_between_top_upstream_peers: 100,\n                    max_number_of_upstream_peers: 5,\n                },\n                LoadBalancingThresholdConfig {\n                    avg_mempool_traffic_threshold_in_tps: 3500,\n                    latency_slack_between_top_upstream_peers: 125,\n                    max_number_of_upstream_peers: 6,\n                },\n                LoadBalancingThresholdConfig {\n                    avg_mempool_traffic_threshold_in_tps: 4500,\n                    latency_slack_between_top_upstream_peers: 150,\n                    max_number_of_upstream_peers: 7,\n                },\n            ],\n            enable_max_load_balancing_at_any_load: false,\n            orderless_txn_capacity_per_user: 1000,\n        }\n    }\n}\n\nimpl ConfigSanitizer for MempoolConfig {\n    fn sanitize(\n        _node_config: &NodeConfig,\n        _node_type: NodeType,\n        _chain_id: Option<ChainId>,\n    ) -> Result<(), Error> {\n        Ok(()) // TODO: add reasonable verifications\n    }\n}\n\nimpl ConfigOptimizer for MempoolConfig {\n    fn optimize(\n        node_config: &mut NodeConfig,\n        local_config_yaml: &Value,\n        node_type: NodeType,\n        _chain_id: Option<ChainId>,\n    ) -> Result<bool, Error> {\n        let mempool_config = &mut node_config.mempool;\n        let local_mempool_config_yaml = &local_config_yaml[",
    "url": "https://deepwiki.com/search/-you-are-an-elite-aptos-blockc_2f516162-ee39-482f-a248-aa6e3668d44e?mode=deep",
    "timestamp": "2026-01-26 22:39:57.255305",
    "report_generated": false
  }
]