[
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Integer overflow] In the version comparison at line 60 'if index.stale_since_version > target_version', can an attacker manipulate versions to cause integer overflow or wraparound, leading to incorrect pruning decisions that delete active state values and cause permanent state corruption? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Off-by-one error] Does the condition 'index.stale_since_version > target_version' at line 60 correctly handle boundary cases, or could an off-by-one error cause premature deletion of state values at exactly target_version, leading to loss of valid blockchain state? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: new()] [Version validation] When comparing 'metadata_progress' at line 28 with the shard's local progress at line 30-34, can negative versions or Version::MAX values cause undefined behavior or incorrect catch-up logic that corrupts the pruning state? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Version monotonicity] If current_progress >= target_version is passed to prune() at line 47-51, does the function handle this gracefully, or will it incorrectly iterate and delete state, causing data loss? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: new()] [Catch-up attack] During initialization at line 42 'myself.prune(progress, metadata_progress)', if an attacker forces metadata_progress to be manipulated (e.g., u64::MAX), can this cause the pruner to delete all historical state in one operation, leading to catastrophic data loss? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Iterator seek vulnerability] At line 57 'iter.seek(&current_progress)', if current_progress points to a non-existent or corrupted version, can this cause the iterator to skip valid stale entries or seek to incorrect positions, leaving unpruned data that grows indefinitely? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Iterator exhaustion] After seeking at line 57, the for loop at line 58 iterates without bounds checking - can a malicious state cause infinite iteration or excessive memory consumption leading to node crashes? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Iterator ordering assumption] The code assumes StaleStateValueIndexByKeyHashSchema returns entries in stale_since_version order (due to BigEndian encoding) - if this ordering is violated by database corruption or schema changes, can the pruner delete wrong entries or skip stale data? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Iterator error handling] At line 59 'let (index, _) = item?', if the iterator returns corrupted data that fails deserialization, does error propagation properly abort the entire batch, or could partial writes occur causing inconsistent database state? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Seek boundary] When seeking to current_progress at line 57, if current_progress = 0 or current_progress = u64::MAX, can boundary conditions cause the seek to fail silently or position incorrectly, leading to unpruned stale data accumulation? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Atomic commit failure] The batch operations at lines 63-64 delete StaleStateValueIndex and StateValueByKeyHash, followed by metadata update at lines 66-69, and commit at line 71 - if the commit fails after partial deletion, can this leave the database in an inconsistent state with deleted indices but present values, or vice versa? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Batch size limit] The SchemaBatch at line 52 accumulates deletions without size limits - can an attacker force pruning of millions of versions in one call, causing the batch to exceed RocksDB write buffer limits and fail with partial writes that corrupt state? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Write-after-read race] Between reading the iterator at line 58-59 and deleting at lines 63-64, if concurrent writes occur to the same shard (despite pruner isolation), can this create race conditions where active state values are deleted because stale indices are read before updates? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Progress update ordering] The progress metadata is updated at lines 66-69 before verifying all deletions succeeded - if write_schemas at line 71 fails, the progress will be incorrectly advanced, causing the pruner to skip versions on retry and leave stale data permanently? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Metadata consistency] At line 66-69, DbMetadataKey::StateKvShardPrunerProgress is updated to target_version - if this write succeeds but subsequent shard deletions fail during write_schemas, can this create permanent inconsistency where progress metadata claims pruning is complete but stale data remains? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Parallel shard pruning race] Given that StateKvPruner invokes prune() concurrently on all 16 shards via par_iter(), if two shards both access shared metadata or have overlapping key_hash ranges, can race conditions cause double-deletion attempts or missed deletions? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: new()] [Initialization race] At line 42, new() calls prune() during initialization while other threads may be reading from db_shard - can this cause read-after-delete races where queries return inconsistent state snapshots during catch-up? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Struct: StateKvShardPruner] [Shared state mutation] The db_shard field at line 21 is Arc<DB> - if multiple StateKvShardPruner instances share the same Arc (though unlikely), can concurrent prune() calls on the same shard cause interleaved writes that corrupt the database? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Iterator invalidation] If the iterator created at line 54-56 is active while concurrent writes occur to the same shard (from StateStore commits), can iterator invalidation or undefined behavior occur in RocksDB leading to corrupted reads or crashes? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Memory ordering] The function accesses db_shard.iter() and db_shard.write_schemas() without explicit synchronization - can weak memory ordering on certain architectures cause visibility issues where stale data appears to persist after pruning? (Low)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Double deletion vulnerability] At line 64, StateValueByKeyHashSchema is deleted using (index.state_key_hash, index.version) - if the same state_key_hash has multiple versions, can incorrect tuple construction cause deletion of wrong versions, including the latest active state? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Index-value desynchronization] Lines 63-64 delete both the index and the value - if only one deletion succeeds due to DB corruption or partial write failures, can this leave orphaned indices pointing to non-existent values or vice versa, causing query failures? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Wrong schema deletion] If the schema mapping between StaleStateValueIndexByKeyHashSchema (line 63) and StateValueByKeyHashSchema (line 64) is misaligned or key hashing is inconsistent, can this cause deletion of wrong state values unrelated to the stale index? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Active state deletion] The logic assumes all entries with stale_since_version <= target_version are safe to delete - if a state value was marked stale but later reinstated (edge case in state management), can this logic incorrectly delete active state causing funds loss? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Shard mismatch] At line 64, state_key_hash is used to delete from StateValueByKeyHashSchema - if state_key_hash routes to a different shard than self.shard_id (shard routing inconsistency), can this cause deletion attempts on wrong shards leading to data corruption? (High)"
]