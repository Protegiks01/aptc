[
  "[File: aptos-core/ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs] [Function: validate()] [BTreeSet Memory Growth] At line 324, gap_detector is a BTreeSet, can long validation runs cause memory exhaustion if versions are never removed? (Medium)",
  "[File: aptos-core/ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs] [Function: backfill()] [Arc\n\n### Citations\n\n**File:** ecosystem/indexer-grpc/indexer-grpc-file-store-backfiller/src/processor.rs (L1-387)\n```rust\n// Copyright Â© Aptos Foundation\n// SPDX-License-Identifier: Apache-2.0\n\nuse anyhow::{ensure, Context, Result};\nuse aptos_indexer_grpc_utils::{\n    compression_util::StorageFormat, config::IndexerGrpcFileStoreConfig, create_grpc_client,\n    file_store_operator::FileStoreOperator,\n};\nuse aptos_protos::{\n    internal::fullnode::v1::{\n        stream_status::StatusType, transactions_from_node_response::Response,\n        GetTransactionsFromNodeRequest, TransactionsFromNodeResponse,\n    },\n    transaction::v1::Transaction,\n};\nuse futures::StreamExt;\nuse serde::{Deserialize, Serialize};\nuse std::{\n    collections::{BTreeMap, BTreeSet},\n    process::exit,\n    sync::Arc,\n    time::Duration,\n};\nuse tokio::sync::Mutex;\n\n/// Processor tails the data in cache and stores the data in file store.\npub struct Processor {\n    file_store_operator: Box<dyn FileStoreOperator>,\n    chain_id: u64,\n    grpc_stream: Option<tonic::Streaming<TransactionsFromNodeResponse>>,\n    starting_version: u64,\n    progress_file_path: String,\n    ending_version: Option<u64>,\n    validation_mode: bool,\n    backfill_processing_task_count: usize,\n    validating_task_count: usize,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\npub struct ProgressFile {\n    version: u64,\n}\n\nimpl Processor {\n    pub async fn new(\n        fullnode_grpc_address: url::Url,\n        file_store_config: IndexerGrpcFileStoreConfig,\n        chain_id: u64,\n        enable_cache_compression: bool,\n        progress_file_path: String,\n        starting_version: Option<u64>,\n        transactions_count: Option<u64>,\n        validation_mode: bool,\n        backfill_processing_task_count: usize,\n        validating_task_count: usize,\n    ) -> Result<Self> {\n        let _cache_storage_format = if enable_cache_compression {\n            StorageFormat::Lz4CompressedProto\n        } else {\n            StorageFormat::Base64UncompressedProto\n        };\n        if validation_mode {\n            return Ok(Self {\n                file_store_operator: file_store_config.create(),\n                chain_id,\n                grpc_stream: None,\n                starting_version: starting_version.unwrap_or(0),\n                progress_file_path,\n                ending_version: transactions_count.map(|c| starting_version.unwrap_or(0) + c),\n                validation_mode,\n                backfill_processing_task_count,\n                validating_task_count,\n            });\n        }\n\n        let starting_version = starting_version.unwrap_or(0);\n        let expected_end_version = transactions_count.map(|c| starting_version + c);\n        // Resume from the progress file if the file exists. If not, create an empty one.\n        let progress_file: ProgressFile = match std::fs::read(&progress_file_path) {\n            Ok(bytes) => serde_json::from_slice(&bytes).context("
]