[
  "[File: restore.rs] [Function: LoadedChunk::load()] [Signature validation] Line 154 calls epoch_history.verify_ledger_info(&ledger_info) - can an attacker restore from a backup created during a different epoch and bypass validator signature checks? (Critical)",
  "[File: restore.rs] [Function: LoadedChunk::load()] [Transaction proof reuse] Lines 158-168 construct TransactionListWithProof for verification - can an attacker reuse a valid proof from one version range with transactions from a different range? (Critical)",
  "[File: restore.rs] [Function: LoadedChunk::load()] [Proof chain validation] At line 168, verify() is called with ledger_info and first_version, but does this validate the accumulator proof connects to the ledger info correctly, or can fake intermediates be inserted? (Critical)",
  "[File: restore.rs] [Function: TransactionRestoreBatchController::new()] [KV replay validation] Lines 220-230 require kv_only_replay to be specified if replay_from_version is set, but can an attacker bypass this by setting replay_from_version to None and later enabling KV replay? (Medium)",
  "[File: restore.rs] [Function: loaded_chunk_stream()] [Version range overlap] Lines 361-363 filter chunks by target_version and first_version, but can overlapping chunks from different backups be restored, causing duplicate transaction processing? (High)",
  "[File: restore.rs] [Function: loaded_chunk_stream()] [Chunk gap detection] Lines 364-383 scan() validates chunk continuity, but if a chunk is missing in the middle, does the check at lines 367-374 reliably detect this, or can attackers craft skip attacks? (High)",
  "[File: restore.rs] [Function: loaded_chunk_stream()] [Integer overflow in scan] Line 368 checks if chunk.first_version != *last_chunk_last_version + 1, but if last_chunk_last_version is u64::MAX, does this addition overflow and miss gaps? (Medium)",
  "[File: restore.rs] [Function: confirm_or_save_frozen_subtrees()] [Frozen subtree manipulation] Lines 416-419 call restore_handler.confirm_or_save_frozen_subtrees() with range_proof.left_siblings() - can an attacker provide malicious left_siblings to corrupt the accumulator's frozen subtrees? (Critical)",
  "[File: restore.rs] [Function: confirm_or_save_frozen_subtrees()] [Empty stream check] Lines 408-413 get the first chunk from the stream, but if the stream is empty, the error message is generic - could this hide malicious empty backup attacks? (Low)",
  "[File: restore.rs] [Function: save_before_replay_version()] [Replay version bypass] Lines 454-458 calculate first_to_replay as max(replay_from_version, next_expected_version), but can an attacker set replay_from_version < next_expected_version to force re-replay of already executed transactions? (Critical)",
  "[File: restore.rs] [Function: save_before_replay_version()] [Transaction trimming] Lines 476-484 trim transactions exceeding target_version, but if target_version < chunk.last_version, are the TransactionInfo entries also properly trimmed to match? (High)",
  "[File: restore.rs] [Function: save_before_replay_version()] [Drain operation safety] Lines 478-483 use .drain() to remove transactions, but do all five vectors (txns, persisted_aux_info, txn_infos, event_vecs, write_sets) stay synchronized if one drain fails? (High)",
  "[File: restore.rs] [Function: save_before_replay_version()] [Integer underflow] Line 489 calculates num_to_remove = (global_first_version - first_version) as usize - if global_first_version < first_version, does this underflow cause incorrect draining? (High)",
  "[File: restore.rs] [Function: save_before_replay_version()] [Atomic save failure] Lines 508-518 spawn_blocking for save_transactions(), but if this task panics or is cancelled, are partially saved transactions left in inconsistent state? (High)",
  "[File: restore.rs] [Function: save_before_replay_version()] [Version tracking race] Line 520 sets TRANSACTION_SAVE_VERSION metric, but if multiple restore operations run concurrently, can race conditions cause this metric to report incorrect progress? (Low)",
  "[File: restore.rs] [Function: replay_kv()] [State version manipulation] Line 569 calls force_state_version_for_kv_restore(first_version - 1), but can first_version be 0 (genesis), causing underflow and setting state to u64::MAX? (Critical)",
  "[File: restore.rs] [Function: replay_kv()] [KV-only bypass] Lines 576-610 directly save transactions and replay KV without involving chunk_executor - can this bypass important validation in ChunkExecutor that would catch state inconsistencies? (High)",
  "[File: restore.rs] [Function: replay_kv()] [Concurrent chunk processing] Lines 576-610 use buffered_x for concurrent processing, but if chunks are processed out-of-order, can this cause state corruption where later transactions are applied before earlier ones? (Critical)",
  "[File: restore.rs] [Function: replay_kv()] [Offset calculation race] Lines 588-589 update base_version and offset, but these are mutable variables accessed in async context - can race conditions cause incorrect version calculations? (High)",
  "[File: restore.rs] [Function: replay_transactions()] [State reset race] Line 655 calls restore_handler.reset_state_store(), but if another restore operation is running concurrently, can this reset corrupt the other operation's state? (High)",
  "[File: restore.rs] [Function: replay_transactions()] [ChunkExecutor reuse] Lines 657-658 create a single ChunkExecutor instance reused for all chunks - can state accumulation in the executor cause incorrect execution of later chunks? (High)",
  "[File: restore.rs] [Function: replay_transactions()] [Batch size manipulation] Line 63 defines BATCH_SIZE as 10000 (or 2 in tests) - can an attacker modify this at runtime to force tiny batches causing performance DoS, or huge batches causing memory exhaustion? (Medium)",
  "[File: restore.rs] [Function: replay_transactions()] [Enqueue failure handling] Lines 676-688 spawn_blocking for enqueue_chunks(), but if enqueue fails for one chunk, does the stream continue processing later chunks, causing version gaps? (High)",
  "[File: restore.rs] [Function: replay_transactions()] [Update ledger race] Lines 696-707 call update_ledger() in parallel with enqueue_chunks() - can race conditions cause ledger updates to be applied before chunks are fully enqueued? (High)",
  "[File: restore.rs] [Function: replay_transactions()] [Commit ordering] Lines 709-734 commit chunks after update_ledger(), but if commits happen out-of-order due to buffering, can this cause non-sequential version commits breaking atomicity? (Critical)"
]