[
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: poll_next()] [Lock in poll] The poll_next() holds the lock while calling internal_queue.pop() (line 174) - if pop() is slow due to complex queue management, can this block all concurrent push() operations from consensus message senders? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: Sender::clone()] [Clone contention] Every clone() acquires the lock just to increment num_senders (lines 120-122) - in scenarios with frequent sender cloning (e.g., spawning many consensus tasks), can this create a lock contention hotspot? (Low)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Insufficient validation] The only validation is checking receiver_dropped at line 99 - are there other invariants that should be checked, such as maximum total queue size across all keys, to prevent memory exhaustion attacks on validators? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Error propagation] When receiver_dropped is true, the function returns an error (line 99) - but what if the caller ignores this error and continues trying to send consensus messages? Can this cause silent message loss without proper error handling? (High)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Debug assert] The debug_assert at line 100 checks num_senders > 0, but this is only checked in debug builds - in release builds used by validators, can num_senders be 0 while push is called, causing undefined behavior? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: Sender::clone()] [Unchecked increment] The num_senders increment at line 122 has a debug_assert but no runtime check for overflow - can this assumption be violated in release builds leading to state corruption? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Channel leak] If a status_ch is provided but never consumed (e.g., sender crashes), can the oneshot channel leak forever since there's no cleanup mechanism, causing gradual memory leaks in long-running validators? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Struct: SharedState] [Queue growth] The internal_queue can grow to max_capacity per key - if there are many unique keys (e.g., from transient peers), can this cause unbounded memory growth and validator OOM, especially since keys are only GC'd periodically in PerKeyQueue? (High)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: clear()] [Feedback leak] When clear() drains the queue (line 154), all pending feedback channels are dropped without notification - can this cause the feedback channel receivers to leak, waiting indefinitely for notifications that will never come? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Struct: SharedState] [Waker leak] If a waker is registered at line 184 but the sender never sends another message and is never dropped, can the waker remain stored indefinitely, keeping the associated task alive and causing resource leaks? (Low)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Byzantine flooding] A Byzantine validator can spam push() calls with unique keys to create many per-key queues - can this exhaust memory or cause performance degradation in the HashMap used by PerKeyQueue, affecting honest validator message processing? (High)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Selective message drop] If QueueStyle is FIFO and a Byzantine validator floods messages for a specific key (e.g., a critical epoch manager key), can this cause legitimate consensus messages for that key to be dropped (line 102), disrupting epoch transitions? (Critical)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: poll_next()] [Message ordering manipulation] The round-robin polling in PerKeyQueue means messages from different keys are interleaved - can a Byzantine attacker manipulate the ordering by controlling message arrival times to delay processing of critical consensus messages? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Queue style exploitation] If the channel uses KLAST or LIFO queue style, can a Byzantine validator exploit the drop semantics to selectively cause older consensus messages (e.g., votes from previous rounds) to be dropped while newer messages are retained, violating consensus protocol assumptions? (High)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: clear()] [DoS via clear] If clear() can be called externally (e.g., during reconfiguration), can a Byzantine actor trigger frequent clear() operations to repeatedly drain consensus messages, causing loss of liveness? (High)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: poll_next()] [Empty queue with senders] If the queue is empty but num_senders > 0 (line 183), poll_next() returns Pending - but what if all senders are blocked or deadlocked? Will the receiver wait forever, causing the validator to hang on consensus message processing? (High)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Push after stream termination] What happens if stream_terminated is true but receiver_dropped is false (e.g., due to a bug)? Can push() succeed (line 99 only checks receiver_dropped) but the message never be received, causing silent message loss? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: new()] [Zero senders] If the returned Sender from new() (line 254) is immediately dropped without being cloned, the receiver will see num_senders == 0 - does this correctly signal stream end, or will the receiver miss this transition and hang? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: Sender::clone()] [Clone during drop] If a sender is cloned while another sender is being dropped, can the num_senders value be read in an inconsistent state (e.g., seeing the old value before decrement but after the decrement lock is released), causing miscounting? (Low)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: poll_next()] [Multiple receivers] The code assumes a single receiver, but Arc<Mutex<SharedState>> could theoretically allow multiple receiver clones - what happens if two receivers call poll_next() concurrently? Can this cause duplicate message delivery or skipped messages in consensus processing? (Critical)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Feedback channel already closed] If the status_ch oneshot::Sender is already closed before push_with_feedback() is called, and the message is dropped (line 107), does the send() fail silently? Can this cause the caller to never know their message was dropped? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: clear()] [Clear during poll] If clear() is called (line 154) while poll_next() is executing (specifically after checking the queue is not empty but before popping), can the pop() return None unexpectedly, causing poll logic to behave incorrectly? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: push_with_feedback()] [Waker wake during push] If waker.wake() at line 110 synchronously calls the receiver's poll_next() on the same thread, can this cause recursive lock acquisition or unexpected reentrancy into the channel code? (Low)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: poll_next()] [Async cancellation] If poll_next() is cancelled (e.g., via tokio::select!) after setting the waker at line 184 but before returning Pending, can this leave a stale waker in SharedState that will never be cleared, causing wake() to be called on a cancelled task? (Medium)",
  "[File: aptos-core/crates/channel/src/aptos_channel.rs] [Function: Sender::drop()] [Drop order] If multiple senders are dropped in quick succession on different threads, can the order of num_senders decrements vs. waker.wake() calls cause some drops to not wake the receiver, leading to missed stream termination notifications? (Low)"
]