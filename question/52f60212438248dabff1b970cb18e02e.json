[
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Deduplication Cache Poisoning] If attacker processes malicious raw_image_uri first (e.g., SSRF or malicious content), subsequent legitimate assets with same raw_image_uri will inherit the poisoned cdn_image_uri via deduplication at line 188? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: upsert()] [Panic on DB Failure] The upsert() method at line 377-383 calls panic!() on database commit failure - can attacker intentionally cause DB errors (connection exhaustion, deadlocks) to crash all worker processes, causing service outage? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Silent Failure Accumulation] Multiple operations (JSON parsing, GCS uploads, image optimization) silently fail with log warnings but processing continues - can accumulated silent failures leave database in inconsistent state where asset appears processed but has no valid content? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Unwrap Panic in URIParser] URIParser.parse() failures are caught with unwrap_or_else() at lines 118-122, 219-223, 312-316, but what if URIParser itself panics on malformed input instead of returning Err? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [GCS Client Panic] Arc<GCSClient> is shared across workers - if GCS client encounters internal error and panics in write_json_to_gcs() or write_image_to_gcs(), does it poison the Arc and crash all workers? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Database Connection Exhaustion] Each Worker holds a PooledConnection for entire lifetime (line 34) - if workers get stuck in long-running operations, can this exhaust the connection pool and cause deadlock or denial of service? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: new()] [Integer Overflow in Version] Last_transaction_version is stored as i64 at line 41, but blockchain version is monotonically increasing - can version overflow lead to negative values or wraparound causing incorrect ordering in database? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Stale Transaction Version] Last_transaction_version passed to upsert() at line 378 is set once in constructor at line 56 - if worker processes slowly, can this version become stale and overwrite newer updates from faster workers? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: new()] [Timestamp Manipulation] Last_transaction_timestamp is NaiveDateTime without timezone at line 42 - can timezone confusion or DST transitions cause incorrect timestamp comparisons or ordering in database queries? (Low)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: upsert()] [Missing Version Conflict Resolution] Multiple upserts at lines 88, 97, 165, 189, 209, 272, 296, 361, 370 all use same last_transaction_version - if they execute out of order due to async operations, can newer data be overwritten by older? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Version Replay Attack] If attacker can replay old pubsub messages with outdated last_transaction_version, can they force crawler to revert to old NFT metadata, effectively censoring or manipulating NFT content? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: log_info/log_warn/log_error()] [Sensitive Data Logging] All logging functions at lines 393-429 log full asset_uri and pubsub_message - can these contain sensitive data (API keys, tokens, PII) that gets exposed in logs? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: log_warn()] [Error Object Information Leak] The log_warn() at line 405-416 logs full error details with debug formatting - can internal error messages expose stack traces, file paths, or system information to log aggregators? (Low)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: log_error()] [Resource Exhaustion via Logs] If attacker can trigger many errors (e.g., by submitting invalid URIs), excessive logging at line 418-429 could fill disk or overwhelm log aggregation system, causing DoS? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Timing Side Channel] Processing time varies significantly based on URI validity, blacklist status, deduplication - can attacker use timing measurements to enumerate blacklisted domains or infer cached content? (Low)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: new()] [Parser Config Injection] Parser_config is wrapped in Arc and shared - if any field is mutable or contains untrusted input, can configuration be poisoned to affect all workers (e.g., modify cdn_prefix to redirect to attacker domain)? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: new()] [IPFS Prefix Manipulation] The parser_config.ipfs_prefix at line 114 is prepended to URIs - can attacker control or inject into this config to redirect all IPFS fetches to malicious gateway? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: new()] [Auth Key Exposure] The ipfs_auth_key from parser_config at line 116 is passed to URIParser - if this gets logged or leaked, can attacker use it to access private IPFS content or impersonate the crawler? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: new()] [Bucket Name Injection] The parser_config.bucket at lines 143, 249, 343 is used for GCS operations - can malicious bucket name cause path traversal or access to unintended storage buckets? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: new()] [Max File Size Bypass] The max_file_size_bytes from config at lines 127, 232, 324 limits download size, but is this enforced before or after decompression? Can attacker use compression to bypass size limits? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: new()] [Image Quality Injection] The image_quality parameter at line 233 affects output file size - can attacker manipulate config to set quality=100 and cause excessive GCS storage consumption or bandwidth costs? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Struct: Worker] [Missing Sync Trait] Worker struct fields at lines 32-44 include PooledConnection and String - is Worker properly Send+Sync for concurrent access, or can data races occur if Worker is used from multiple threads? (Medium)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Shared GCS Client Race] The Arc<GCSClient> at line 36 is shared across workers - are GCS uploads properly serialized, or can concurrent writes to same GCS path cause data corruption or partial uploads? (High)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Model State Mutation] The self.model is mutated throughout parse() method at lines 84, 96, 136-137, 160, 188, etc. - if parse() is called concurrently (shouldn't happen but no guard), can this cause data corruption? (Low)",
  "[File: aptos-core/ecosystem/nft-metadata-crawler/src/parser/worker.rs] [Function: parse()] [Database Transaction Isolation] Multiple upsert() calls throughout parse() are not wrapped in a single transaction - if worker crashes mid-parse, can database be left in partially updated inconsistent state? (Medium)"
]