[
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Function: pack_into_validation_index()] [Bit shift overflow] When shifting wave << 32, can values near u32::MAX cause the shifted value to exceed u64::MAX when OR'd with idx? (Low)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Field: execution_idx] [SeqCst fetch_add] Is SeqCst memory ordering necessary for all fetch_add operations on execution_idx, or can weaker ordering be used while maintaining correctness? (Low)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Field: validation_idx] [SeqCst compare_exchange] Does using SeqCst for compare_exchange provide stronger guarantees than needed, or is it required to prevent validation races? (Low)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Field: done_marker] [SeqCst swap] When swapping done_marker with SeqCst ordering, can relaxing to Acquire/Release ordering cause threads to miss the done signal? (High)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Field: has_halted] [Relaxed load] Is Relaxed ordering safe for has_halted loads, or can compiler/CPU reordering cause threads to observe stale values and miss the halt? (High)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Function: wake_dependencies_after_execution()] [Fetch_min ordering] Does fetch_min with SeqCst ordering synchronize properly with fetch_add in try_execute_next_version, or can races cause execution_idx to be inconsistent? (High)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Struct: Scheduler] [Multiple RwLocks] When holding multiple RwLocks on txn_status entries (e.g., in wait_for_dependency), can lock acquisition ordering differ across threads and cause deadlock? (Critical)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Type: DependencyCondvar] [Arc reference counting] Can Arc reference count overflow if a transaction has more than 2^32 dependencies, causing memory corruption? (Low)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Field: txn_dependency] [Mutex contention] Can high contention on txn_dependency mutexes cause priority inversion where high-priority transactions are blocked by low-priority ones? (Medium)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Field: txn_status] [RwLock fairness] Do RwLocks provide fairness guarantees, or can write-heavy workloads starve readers, preventing validations from ever acquiring read locks? (Medium)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Type: CachePadded] [False sharing] Despite cache padding, can false sharing still occur if CPU cache lines are larger than the padding size (e.g., 128 bytes on some systems)? (Low)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Function: suspend()] [Invalid status error] When suspend() returns PanicError for unexpected status, does the error propagation properly halt execution, or can errors be swallowed? (High)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Function: resume()] [Unexpected status error] If resume() is called on non-Suspended/non-Halted status, does the PanicError prevent state corruption, or can the error be caught and ignored? (High)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Function: set_executed_status()] [Incarnation mismatch error] When incarnation doesn't match, does the PanicError prevent double-execution, or can concurrent operations proceed despite the error? (Critical)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Function: set_aborted_status()] [Status mismatch error] If status is not Aborting with expected incarnation, does the error prevent abort finalization, or can partial state updates occur before the error? (High)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Function: wait_for_dependency()] [Index bounds error] Does the index validation error prevent invalid dependencies, or can the error be bypassed through integer overflow? (High)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Function: prepare_for_block_epilogue()] [Unsafe invariant violation] If safely_finished is false or status is not ExecutionHalted, does the error prevent epilogue execution, or can it be ignored in release builds? (Critical)",
  "[File: aptos-core/aptos-move/block-executor/src/scheduler.rs] [Test: scheduler_halt()] [Double halt check] Does the test verify that second halt() call returns false, confirming has_halted flag works correctly? (Low)",
  "[File: aptos-core/aptos-move/block-executor/\n\n### Citations\n\n**File:** aptos-move/block-executor/src/scheduler.rs (L1-1137)\n```rust\n// Copyright © Aptos Foundation\n// Parts of the project are originally copyright © Meta Platforms, Inc.\n// SPDX-License-Identifier: Apache-2.0\n\nuse crate::explicit_sync_wrapper::ExplicitSyncWrapper;\nuse aptos_infallible::Mutex;\nuse aptos_mvhashmap::types::{Incarnation, TxnIndex};\nuse aptos_types::error::{code_invariant_error, PanicError};\nuse concurrent_queue::{ConcurrentQueue, PopError};\nuse crossbeam::utils::CachePadded;\nuse parking_lot::{RwLock, RwLockUpgradableReadGuard};\nuse std::{\n    cmp::{max, min},\n    sync::{\n        atomic::{AtomicBool, AtomicU32, AtomicU64, Ordering},\n        Arc, Condvar,\n    },\n};\n\nconst TXN_IDX_MASK: u64 = (1 << 32) - 1;\n\npub type Wave = u32;\n\n#[derive(Debug)]\npub struct ArmedLock {\n    // Last bit:   1 -> unlocked; 0 -> locked\n    // Second bit: 1 -> there's work; 0 -> no work\n    locked: AtomicU64,\n}\n\nimpl ArmedLock {\n    pub fn new() -> Self {\n        Self {\n            locked: AtomicU64::new(3),\n        }\n    }\n\n    // try_lock succeeds when the lock is unlocked and armed (there is work to do).\n    pub fn try_lock(&self) -> bool {\n        self.locked\n            .compare_exchange_weak(3, 0, Ordering::Acquire, Ordering::Relaxed)\n            .is_ok()\n    }\n\n    pub fn unlock(&self) {\n        self.locked.fetch_or(1, Ordering::Release);\n    }\n\n    pub fn arm(&self) {\n        self.locked.fetch_or(2, Ordering::Release);\n    }\n}\n\n#[derive(Debug)]\npub enum DependencyStatus {\n    // The dependency is not resolved yet.\n    Unresolved,\n    // The dependency is resolved.\n    Resolved,\n    // The parallel execution is halted.\n    ExecutionHalted,\n}\ntype DependencyCondvar = Arc<(Mutex<DependencyStatus>, Condvar)>;\n\n// Return value of the function wait_for_dependency\n#[derive(Debug)]\npub enum DependencyResult {\n    Dependency(DependencyCondvar),\n    Resolved,\n    ExecutionHalted,\n}\n\n/// Two types of execution tasks: Execution and Wakeup.\n/// Execution is a normal execution task, Wakeup is a task that just wakes up a suspended execution.\n/// See explanations for the ExecutionStatus below.\n#[derive(Debug, Clone)]\npub enum ExecutionTaskType {\n    Execution,\n    Wakeup(DependencyCondvar),\n}\n\n/// Task type that the parallel execution workers get from the scheduler.\n#[derive(Debug)]\npub enum SchedulerTask {\n    /// Execution task with a version of the transaction, and whether it's waking up an already\n    /// executing worker (suspended / waiting on a dependency).\n    ExecutionTask(TxnIndex, Incarnation, ExecutionTaskType),\n    /// Validation task with a version of the transaction, and the validation wave information.\n    ValidationTask(TxnIndex, Incarnation, Wave),\n    /// Retry holds no task (similar None if we wrapped tasks in Option)\n    Retry,\n    /// Done implies that there are no more tasks and the scheduler is done.\n    Done,\n}\n\n/////////////////////////////// Explanation for ExecutionStatus ///////////////////////////////\n/// All possible execution status for each transaction. In the explanation below, we abbreviate\n/// 'execution status' as 'status'. Each status contains the latest incarnation number,\n/// where incarnation = i means it is the i-th execution instance of the transaction.\n///\n/// 'Ready' means that the corresponding incarnation should be executed and the scheduler\n/// must eventually create a corresponding execution task. The scheduler ensures that exactly one\n/// execution task gets created, changing the status to 'Executing' in the process. 'Ready' status\n/// contains an ExecutionTaskType, which is either Execution or Wakeup. If it is Execution, then\n/// the scheduler creates an execution task for the corresponding incarnation. If it is Wakeup,\n/// a dependency condition variable is set in ExecutionTaskType::Wakeup(DependencyCondvar): an execution\n/// of a prior incarnation is waiting on it with a read dependency resolved (when dependency was\n/// encountered, the status changed to Suspended, and suspended changed to Ready when the dependency\n/// finished its execution). In this case the caller need not create a new execution task, but\n/// just notify the suspended execution via the dependency condition variable.\n///\n/// 'Executing' status of an incarnation turns into 'Executed' if the execution task finishes, or\n/// if a dependency is encountered, it becomes 'Ready(incarnation)' once the\n/// dependency is resolved. An 'Executed' status allows creation of validation tasks for the\n/// corresponding incarnation, and a validation failure leads to an abort. The scheduler ensures\n/// that there is exactly one abort, changing the status to 'Aborting' in the process. Once the\n/// thread that successfully aborted performs everything that's required, it sets the status\n/// to 'Ready(incarnation + 1)', allowing the scheduler to create an execution\n/// task for the next incarnation of the transaction.\n///\n/// 'ExecutionHalted' is a transaction status marking that parallel execution is halted, due to\n/// reasons such as module r/w intersection or exceeding per-block gas limit. It is safe to ignore\n/// this status during the transaction invariant checks, e.g., suspend(), resume(), set_executed_status().\n///\n/// Status transition diagram:\n/// Ready(i)                                                                               ---\n///    |  try_incarnate (incarnate successfully)                                             |\n///    |                                                                                     |\n///    ↓         suspend (waiting on dependency)                resume                       |\n/// Executing(i) -----------------------------> Suspended(i) ------------> Ready(i)          |\n///    |                                                                                     | halt_transaction_execution\n///    |  finish_execution                                                                   |-----------------> ExecutionHalted\n///    ↓                                                                                     |\n/// Executed(i) (pending for (re)validations) ---------------------------> Committed(i)      |\n///    |                                                                                     |\n///    |  try_abort (abort successfully)                                                     |\n///    ↓                finish_abort                                                         |\n/// Aborting(i) ---------------------------------------------------------> Ready(i+1)      ---\n///\n#[derive(Debug)]\nenum ExecutionStatus {\n    Ready(Incarnation, ExecutionTaskType),\n    Executing(Incarnation, ExecutionTaskType),\n    Suspended(Incarnation, DependencyCondvar),\n    Executed(Incarnation),\n    // TODO[agg_v2](cleanup): rename to Finalized or ReadyToCommit / CommitReady?\n    // it gets committed later, without scheduler tracking.\n    Committed(Incarnation),\n    Aborting(Incarnation),\n    // The bool in ExecutionHalted tracks an useful invariant for the block epilogue txn\n    // when the block is cut, and the final execution of the epilogue txn occurs at\n    // some idx < num_txns. In this case, it must be ensured that any control flow that\n    // started to apply changes to the shared data structures was completed despite\n    // a concurrent halt (which must be invoked due to block cutting).\n    // - in case of Aborting, finish_abort must be called (after estimates are marked).\n    // - in case of Executing, finish_execution must be called, which happens after\n    // the caller records the input/output (needed to mark outputs as estimates or\n    // clear the prior write-set).\n    //\n    // In particular, [Scheduler::set_aborted_status] & [Scheduler::set_executed_status]\n    // must be called to reset the flag to true. The flag is set to false if when halting,\n    // the txn status is aborting or executing, or if right before applying the outputs\n    // to the shared data structures the txn is already halted.\n    ExecutionHalted(bool),\n}\n\nimpl PartialEq for ExecutionStatus {\n    fn eq(&self, other: &Self) -> bool {\n        use ExecutionStatus::*;\n        match (self, other) {\n            (\n                &Ready(ref a, ExecutionTaskType::Execution),\n                &Ready(ref b, ExecutionTaskType::Execution),\n            )\n            | (\n                &Executing(ref a, ExecutionTaskType::Execution),\n                &Executing(ref b, ExecutionTaskType::Execution),\n            )\n            | (\n                &Ready(ref a, ExecutionTaskType::Wakeup(_)),\n                &Ready(ref b, ExecutionTaskType::Wakeup(_)),\n            )\n            | (\n                &Executing(ref a, ExecutionTaskType::Wakeup(_)),\n                &Executing(ref b, ExecutionTaskType::Wakeup(_)),\n            )\n            | (&Suspended(ref a, _), &Suspended(ref b, _))\n            | (&Executed(ref a), &Executed(ref b))\n            | (&Committed(ref a), &Committed(ref b))\n            | (&Aborting(ref a), &Aborting(ref b)) => a == b,\n            _ => false,\n        }\n    }\n}\n\n/////////////////////////////// Explanation for ValidationStatus ///////////////////////////////\n/// All possible validation status for each transaction. In the explanation below, we abbreviate\n/// 'validation status' as 'status'. Each status contains three wave numbers, each with different\n/// meanings, but in general the concept of 'wave' keeps track of the version number of the validation.\n///\n/// 'max_triggered_wave' records the maximum wave that was triggered at the transaction index, and\n/// will be incremented every time when the validation_idx is decreased. Initialized as 0.\n///\n/// 'maybe_max_validated_wave' records the maximum wave among successful validations of the corresponding\n/// transaction, will be incremented upon successful validation (finish_validation). Initialized as None.\n///\n/// 'required_wave' in addition records the wave that must be successfully validated in order\n/// for the transaction to be committed, required to handle the case of the optimization in\n/// finish_execution when only the transaction itself is validated (if last incarnation\n/// didn't write outside of the previous write-set). Initialized as 0.\n///\n/// Other than ValidationStatus, the 'wave' information is also recorded in 'validation_idx' and 'commit_state'.\n/// Below is the description of the wave meanings and how they are updated. More details can be\n/// found in the definition of 'validation_idx' and 'commit_state'.\n///\n/// In 'validation_idx', the first 32 bits identifies a validation wave while the last 32 bits\n/// contain an index that tracks the minimum of all transaction indices that require validation.\n/// The wave is incremented whenever the validation_idx is reduced due to transactions requiring\n/// validation, in particular, after aborts and executions that write outside of the write set of\n/// the same transaction's previous incarnation.\n///\n/// In 'commit_state', the first element records the next transaction to commit, and the\n/// second element records the lower bound on the wave of a validation that must be successful\n/// in order to commit the next transaction. The wave is updated in try_commit, upon seeing an\n/// executed txn with higher max_triggered_wave. Note that the wave is *not* updated with the\n/// required_wave of the txn that is being committed.\n///\n///\n/////////////////////////////// Algorithm Description for Updating Waves ///////////////////////////////\n/// In the following, 'update' means taking the maximum.\n/// (1) Upon decreasing validation_idx, increment validation_idx.wave and update txn's\n/// max_triggered_wave <- validation_idx.wave;\n/// (2) Upon finishing execution of txn that is below validation_idx, update txn's\n/// required_wave <- validation_idx.wave; (otherwise, the last triggered wave is below and will validate).\n/// (3) Upon validating a txn successfully, update txn's maybe_max_validated_wave <- validation_idx.wave;\n/// (4) Upon trying to commit an executed txn, update commit_state.wave <- txn's max_triggered_wave.\n/// (5) If txn's maybe_max_validated_wave >= max(commit_state.wave, txn's required_wave), can commit the txn.\n///\n/// Remark: commit_state.wave is updated only with max_triggered_wave but not required_wave. This is\n/// because max_triggered_wave implies that this wave of validations was required for all higher transactions\n/// (and is set as a part of decrease_validation_idx), while required_wave is set for the transaction only\n/// (when a validation task is returned to the caller). Moreover, the code is structured in a way that\n/// decrease_validation_idx is always called for txn_idx + 1 (e.g. when aborting, there is no need to validate\n/// the transaction before re-execution, and in finish_execution, even if there is a need to validate txn_idx,\n/// it is returned to the caller directly, which is done so as an optimization and also for uniformity).\n#[derive(Debug)]\nstruct ValidationStatus {\n    max_triggered_wave: Wave,\n    required_wave: Wave,\n    maybe_max_validated_wave: Option<Wave>,\n}\n\nimpl ValidationStatus {\n    pub fn new() -> Self {\n        ValidationStatus {\n            max_triggered_wave: 0,\n            required_wave: 0,\n            maybe_max_validated_wave: None,\n        }\n    }\n}\n\npub trait TWaitForDependency {\n    fn wait_for_dependency(\n        &self,\n        txn_idx: TxnIndex,\n        dep_txn_idx: TxnIndex,\n    ) -> Result<DependencyResult, PanicError>;\n}\n\npub struct Scheduler {\n    /// Number of txns to execute, immutable.\n    num_txns: TxnIndex,\n\n    /// An index i maps to indices of other transactions that depend on transaction i, i.e. they\n    /// should be re-executed once transaction i's next incarnation finishes.\n    txn_dependency: Vec<CachePadded<Mutex<Vec<TxnIndex>>>>,\n    /// An index i maps to the most up-to-date status of transaction i.\n    txn_status: Vec<CachePadded<(RwLock<ExecutionStatus>, RwLock<ValidationStatus>)>>,\n\n    /// Next transaction to commit, and sweeping lower bound on the wave of a validation that must\n    /// be successful in order to commit the next transaction.\n    commit_state: CachePadded<ExplicitSyncWrapper<(TxnIndex, Wave)>>,\n\n    // Note: with each thread reading both counters when deciding the next task, and being able\n    // to choose either execution or validation task, separately padding these indices may increase\n    // (real) cache invalidation traffic more than combat false sharing. Hence, currently we\n    // don't pad separately, but instead put them in between two padded members (same cache line).\n    // TODO: investigate the trade-off. Re-consider if we change task assignment logic (i.e. make\n    // validation/execution preferences stick to the worker threads).\n    /// A shared index that tracks the minimum of all transaction indices that require execution.\n    /// The threads increment the index and attempt to create an execution task for the corresponding\n    /// transaction, if the status of the txn is 'Ready'. This implements a counting-based\n    /// concurrent ordered set. It is reduced as necessary when transactions become ready to be\n    /// executed, in particular, when execution finishes and dependencies are resolved.\n    execution_idx: AtomicU32,\n    /// The first 32 bits identifies a validation wave while the last 32 bits contain an index\n    /// that tracks the minimum of all transaction indices that require validation.\n    /// The threads increment this index and attempt to create a validation task for the\n    /// corresponding transaction (if the status of the txn is 'Executed'), associated with the\n    /// observed wave in the first 32 bits. Each validation wave represents the sequence of\n    /// validations that must happen due to the fixed serialization order of transactions.\n    /// The index is reduced as necessary when transactions require validation, in particular,\n    /// after aborts and executions that write outside of the write set of the same transaction's\n    /// previous incarnation. This also creates a new wave of validations, identified by the\n    /// monotonically increasing index stored in the first 32 bits.\n    validation_idx: AtomicU64,\n\n    /// Shared marker that is set when a thread detects that all txns can be committed.\n    done_marker: CachePadded<AtomicBool>,\n\n    has_halted: CachePadded<AtomicBool>,\n\n    queueing_commits_lock: CachePadded<ArmedLock>,\n\n    commit_queue: ConcurrentQueue<u32>,\n}\n\n/// Public Interfaces for the Scheduler\nimpl Scheduler {\n    pub fn new(num_txns: TxnIndex) -> Self {\n        // Empty block should early return and not create a scheduler.\n        assert!(num_txns > 0,"
]