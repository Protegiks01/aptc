[
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs] [Function: save_min_readable_version()] [Write Ordering] The function updates AtomicVersion, metrics, and then writes to DB - if the DB write fails, the in-memory version and metrics already reflect the new value - can this cause nodes to reject valid historical queries after a failed save? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/ledger_pruner_manager.rs] [Function: new()] [Initialization] If ledger_pruner_config.enable is true but pruner initialization fails, does the constructor panic or return an error? Can a malformed config cause all validator nodes to crash simultaneously during startup? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs] [Function: prune()] [Hash Collision] The pruner deletes transaction_by_hash indices using txn.hash() - if two transactions somehow have the same hash (due to hash collision or implementation bug), can pruning one transaction make the other unretrievable even if it's recent? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs] [Function: get_pruning_candidate_transactions()] [Iterator Safety] The function iterates TransactionSchema from start to end - if concurrent writes are happening, can the iterator see partial transactions or skip transactions, causing incorrect pruning decisions? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs] [Function: get_pruning_candidate_transactions()] [Memory Safety] The function pre-allocates Vec with capacity (end - start) - if end - start is very large due to delayed pruning, can this cause OOM and crash the validator node? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs] [Function: prune()] [Batch Consistency] The function creates one batch for ledger DB and potentially another for indexer DB - if one batch succeeds and the other fails, can this cause data inconsistency between main DB and indexer? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/transaction_pruner.rs] [Function: new()] [Catch-up Logic] During initialization, the pruner calls prune(progress, metadata_progress) to catch up - if this range is huge, can this block node startup for extended periods, causing validator downtime? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs] [Function: prune()] [Conditional Batching] The pruner conditionally uses separate batches for indexer vs main DB based on indexer.event_enabled() - can this flag change mid-pruning, causing some events to be deleted from main DB but not indexer (or vice versa)? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs] [Function: prune()] [Panic on Expect] The function calls expect_indexer_db() which panics if indexer is not enabled - can a race condition where indexer is disabled during pruning cause the entire node to crash? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/ledger_pruner/event_store_pruner.rs] [Function: prune()] [Write Ordering] Event indices are pruned first, then events themselves - if the node crashes between these operations, can this cause dangling event entries without indices, breaking event queries? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/mod.rs] [Function: prune()] [Shard Parallel Execution] Shard pruners run in parallel via rayon - if one shard is much slower than others, can this cause unbalanced pruning where some shards lag behind, eventually causing that shard to run out of disk space? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/mod.rs] [Function: prune()] [Shard Failure] If one shard_pruner.prune() fails, the entire batch fails - but have other shards already committed? Can this cause shards to become out-of-sync in terms of pruning progress? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/mod.rs] [Function: new()] [Shard Configuration] The number of shards is read from state_kv_db.num_shards() - if this value changes between node restarts (due to config change), can the pruner fail to initialize or prune incorrect shards? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/mod.rs] [Function: new()] [Empty Shard Pruners] When sharding is disabled, shard_pruners is an empty Vec - can this cause issues in the parallel iteration code that expects at least some work to do? (Low)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Iterator Seek] The iterator seeks to current_progress - if current_progress doesn't exist in the index, does seek go to the next higher key? Can this cause data before current_progress to be skipped and never pruned? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Deletion Order] The code deletes StaleStateValueIndexByKeyHashSchema before StateValueByKeyHashSchema - if the first succeeds but second fails, can this cause orphaned state values without indices? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: prune()] [Version Comparison] Uses index.stale_since_version > target_version to break - is this comparison correct, or should it be >= to include the target_version itself? Can off-by-one errors cause one extra version to remain unpruned? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_shard_pruner.rs] [Function: new()] [Progress Initialization] Calls get_or_initialize_subpruner_progress() which may initialize progress to metadata_progress if not found - if metadata_progress is incorrect, can this cause the shard to skip pruning a large range of data? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs] [Function: prune()] [No-Op in Sharded Mode] When sharding is enabled, the metadata pruner iterates shards but doesn't delete anything - is this intentional? Can this cause the metadata DB to accumulate stale index entries indefinitely? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_kv_pruner/state_kv_metadata_pruner.rs] [Function: prune()] [Serial Shard Iteration] The comment says 'can be done in parallel if bottleneck' - if one shard has corrupted data causing slow iteration, can this block all state KV pruning and cause storage to fill up? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs] [Function: prune()] [Version Increment Logic] The pruner may prune single versions or jump to target - if maybe_prune_single_version returns None, it jumps directly to target_version - can this cause versions in between to be skipped and never pruned? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs] [Function: prune()] [Shard Coordination] If metadata pruner succeeds but prune_shards() fails, is progress rolled back? Can this cause metadata and shards to become desynchronized in terms of which versions are pruned? (Critical)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs] [Function: get_stale_node_indices()] [Limit Parameter] The function takes a limit parameter for batch size - if caller provides usize::MAX, can this cause the function to try loading millions of indices into memory and OOM? (High)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs] [Function: get_stale_node_indices()] [Iterator Seek] Seeks to a StaleNodeIndex with empty_path NodeKey - is this guaranteed to find the first index for the version, or could it miss indices due to key ordering? (Medium)",
  "[File: aptos-core/storage/aptosdb/src/pruner/state_merkle_pruner/mod.rs] [Function: get_stale_node_indices()] [Next Version Tracking] Returns next_version from the last seen index - if iterator ends before reaching limit, next_version might be beyond target - can this cause confusion in the caller about where to resume? (Low)"
]