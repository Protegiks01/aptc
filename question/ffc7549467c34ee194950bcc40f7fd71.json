[
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: MAX_RETRY_TIME_SECONDS] [Resource exhaustion] Can an attacker hosting malicious NFT metadata URIs exploit the 2-second exponential backoff retry timeout to cause the crawler to waste excessive resources on failing requests, leading to DoS of the metadata indexing service? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: MAX_HEAD_REQUEST_RETRY_SECONDS] [Timeout manipulation] Is the 15-second HEAD request timeout sufficient to prevent slowloris-style attacks where malicious NFT metadata servers send responses byte-by-byte to tie up crawler connections and exhaust connection pools? (Low)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: MAX_JSON_REQUEST_RETRY_SECONDS] [Denial of service] Can attackers create NFT collections pointing to servers that delay JSON responses for exactly 29 seconds (just under the 30-second timeout) to maximize resource consumption and prevent legitimate metadata from being processed? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: MAX_IMAGE_REQUEST_RETRY_SECONDS] [Resource exhaustion] Does the 90-second image download timeout create opportunities for attackers to deploy NFTs with slow-responding image servers that monopolize crawler workers and prevent processing of legitimate NFT metadata? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: MAX_ASSET_UPLOAD_RETRY_SECONDS] [Service degradation] Can malicious actors exploit the 180-second upload timeout by creating NFTs with metadata URIs that respond slowly, causing the crawler to allocate upload workers for extended periods and degrading service availability? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_NUM_PARSE_RETRIES] [Amplification attack] Can an attacker create NFT collections with URIs that return HTTP 500 errors consistently to force the crawler to retry 3 times per URI, amplifying the attack surface by 3x and exhausting retry budgets? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_NUM_PARSE_RETRIES] [State pollution] If retry count tracking is stored in the database, can an attacker flood the system with failing URIs to pollute the parsed_asset_uris table with entries at max retry count, causing database bloat and query performance degradation? (Low)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_FILE_SIZE_BYTES] [Size limit bypass] Can attackers craft malicious HTTP responses with incorrect Content-Length headers that report file sizes under 15MB but actually stream gigabytes of data, bypassing the size check and causing memory exhaustion? (High)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_FILE_SIZE_BYTES] [Compression bomb] Does the 15MB file size limit apply before or after decompression? Can attackers upload highly compressed JSON or image files that expand to massive sizes when decompressed, causing memory exhaustion attacks? (High)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_FILE_SIZE_BYTES] [Memory allocation] When downloading a 15MB file, does the implementation allocate the entire buffer in memory at once? Can attackers flood the service with thousands of 15MB requests simultaneously to exhaust available RAM? (High)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_IMAGE_QUALITY] [Quality manipulation] Can the 100% image quality setting be exploited to create excessively large output files when processing images with transparency, wasting storage resources in GCS and increasing CDN costs? (Low)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_IMAGE_DIMENSIONS] [Integer overflow] When calculating new dimensions from the 4096px maximum, can integer overflow occur in the resize calculation for extremely large source images, leading to incorrect memory allocation and potential buffer overflows? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_IMAGE_DIMENSIONS] [Pixel bomb attack] Can attackers create valid images with dimensions of 4096x4096 (16.7 million pixels) that consume excessive memory during RGBA8 conversion and Gaussian filter operations, causing OOM crashes? (High)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_IMAGE_DIMENSIONS] [CPU exhaustion] Does the Gaussian filter resize operation on 4096x4096 images consume excessive CPU time? Can attackers flood the crawler with maximum-dimension images to monopolize CPU resources and prevent processing of legitimate NFTs? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: IPFS_AUTH_KEY] [Authentication bypass] Can attackers inspect network traffic or logs to discover the pinataGatewayToken query parameter name and attempt to brute force or steal the actual auth token value used by the crawler? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: IPFS_AUTH_KEY] [Query parameter injection] Can malicious NFT creators craft IPFS URIs that already contain the pinataGatewayToken parameter with a malicious value, causing the URI parser to append a duplicate parameter and potentially bypass authentication? (Low)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: IPFS_AUTH_KEY] [Token leakage] When constructing IPFS URIs with the pinataGatewayToken appended, are these URIs logged or exposed in metrics? Can attackers extract the authentication token from logs or monitoring systems? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: MAX_RETRY_TIME_SECONDS] [Inflexible configuration] Since MAX_RETRY_TIME_SECONDS is a compile-time constant at 2 seconds, can this rigid timeout cause legitimate but slow IPFS nodes to be permanently marked as failing, causing data loss for valid NFT metadata? (Low)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_FILE_SIZE_BYTES] [Configuration override] If ParserConfig allows overriding DEFAULT_MAX_FILE_SIZE_BYTES through YAML configuration, can a misconfigured deployment set this to u32::MAX (4GB), allowing memory exhaustion attacks? (High)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_IMAGE_QUALITY] [Quality bypass] If users can override the default image quality through configuration, can setting image_quality to 0 or 255 cause undefined behavior in the JPEG encoder, potentially leading to crashes or corrupted image uploads? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constants: Multiple timeouts] [Race condition] Since MAX_RETRY_TIME_SECONDS (2s) is much shorter than MAX_JSON_REQUEST_RETRY_SECONDS (30s), can race conditions occur where the retry backoff gives up before the request timeout expires, causing inconsistent retry behavior? (Low)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constants: Multiple timeouts] [Cascading failures] If MAX_ASSET_UPLOAD_RETRY_SECONDS (180s) is hit while MAX_IMAGE_REQUEST_RETRY_SECONDS (90s) is still active, can this cause worker threads to deadlock or accumulate in a blocked state, degrading overall service throughput? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_NUM_PARSE_RETRIES] [Retry count manipulation] Since json_parser_retry_count, image_optimizer_retry_count, and animation_optimizer_retry_count are stored in PostgreSQL, can concurrent workers race to increment these counters, bypassing the 3-retry limit? (Medium)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: MAX_RETRY_TIME_SECONDS] [Connection exhaustion] Does using MAX_RETRY_TIME_SECONDS as the database connection retry timeout create situations where all database connections in the pool become exhausted retrying failed queries, causing service outage? (High)",
  "[File: ecosystem/nft-metadata-crawler/src/utils/constants.rs] [Constant: DEFAULT_MAX_FILE_SIZE_BYTES] [MIME type confusion] When checking file size limits, does the implementation properly validate Content-Type headers? Can attackers serve executable malware disguised as JSON or images to bypass size checks and upload malicious content to GCS? (High)"
]